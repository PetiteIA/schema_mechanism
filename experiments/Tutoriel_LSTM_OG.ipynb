{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d20bccf-5d48-45ae-b5a4-51ffc6c80706",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/experiments/Tutoriel_LSTM_OG.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ef9bd-c217-4fab-b06e-84fa9b5eb67c",
   "metadata": {},
   "source": [
    "# TUTOREL LSTM PAR OLIVIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf92b4-2d7e-42cd-b526-6515bc4914cf",
   "metadata": {},
   "source": [
    "# Préparons l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9ff90728-b73f-4bad-bff7-e624ed0bb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from ipywidgets import Button, HBox,VBox, Output\n",
    "from IPython.display import display\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02414e4b-2baf-4727-b50f-be5788ca833f",
   "metadata": {},
   "source": [
    "Les actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6b9ef85f-6a1a-427b-80e4-aa0642469267",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORWARD = 2\n",
    "TURN_LEFT = 3\n",
    "TURN_RIGHT = 4\n",
    "FEEL_FRONT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15c9fb-c769-433e-a221-c280c316163b",
   "metadata": {},
   "source": [
    "Le Small Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7caf41c6-80d2-43ed-86c0-0a185117cdd4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "FEELING = 2\n",
    "BUMPING = 3\n",
    "\n",
    "class SmallLoop():\n",
    "    def __init__(self, poX, poY, direction):\n",
    "        self.grid = np.array([\n",
    "                [1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1],\n",
    "                [1, 0, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1]\n",
    "        ])\n",
    "        self.maze = self.grid.copy()\n",
    "        self.poX = poX\n",
    "        self.poY = poY\n",
    "        self.direction = direction\n",
    "        self.cmap = ListedColormap(['white', 'green', 'yellow', 'red'])\n",
    "        self.norm = BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], self.cmap.N)\n",
    "\n",
    "    def outcome(self, action):\n",
    "        # print('before:', self.agent_position.strPosition(), action_dcit[action])\n",
    "        self.maze[:,:] = self.grid\n",
    "        result = 0\n",
    "        \n",
    "        if action == FORWARD:  # move forward\n",
    "            # print('the action is move forward')\n",
    "            # print(str(self.position.pointX)+': '+ str(self.position.pointY)+ ' ' +self.direction, action)\n",
    "        \n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX][self.poY - 1] == 0:\n",
    "                    self.poY -= 1\n",
    "                else:\n",
    "                    self.maze[self.poX][self.poY - 1] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX + 1][self.poY] == 0:\n",
    "                    self.poX += 1\n",
    "                else:\n",
    "                    self.maze[self.poX + 1][self.poY] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX][self.poY + 1] == 0:\n",
    "                    self.poY += 1\n",
    "                else:\n",
    "                    self.maze[self.poX][self.poY + 1] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX - 1][self.poY] == 0:\n",
    "                    self.poX -= 1\n",
    "                else:\n",
    "                    self.maze[self.poX - 1][self.poY] = BUMPING\n",
    "                    result = 1\n",
    "            # print(str(self.position.pointX)+': '+ str(self.position.pointY)+ ' ' +self.direction, action)\n",
    "        elif action == TURN_RIGHT:\n",
    "            if self.direction == LEFT:\n",
    "                self.direction = UP\n",
    "            elif self.direction == DOWN:\n",
    "                self.direction = LEFT\n",
    "            elif self.direction == RIGHT:\n",
    "                self.direction = DOWN\n",
    "            elif self.direction == UP:\n",
    "                self.direction = RIGHT\n",
    "        elif action == TURN_LEFT:\n",
    "            if self.direction == LEFT:\n",
    "                self.direction = DOWN\n",
    "            elif self.direction == DOWN:\n",
    "                self.direction = RIGHT\n",
    "            elif self.direction == RIGHT:\n",
    "                self.direction = UP\n",
    "            elif self.direction == UP:\n",
    "                self.direction = LEFT\n",
    "        elif action == FEEL_FRONT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "        elif action == FEEL_LEFT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "        elif action == FEEL_RIGHT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "        print(f\"Line: {self.poX}, Column: {self.poY}, direction: {self.direction}\")\n",
    "        # return self.position,\n",
    "\n",
    "        return result  \n",
    "    \n",
    "    def display(self):\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            # ax.set_xticks([])\n",
    "            # ax.set_yticks([])\n",
    "            # ax.axis('off')\n",
    "            # ax.imshow(self.maze, cmap='Greens', vmin=0, vmax=2)\n",
    "            ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "            if self.direction == LEFT:\n",
    "                # Y is column and X is line\n",
    "                plt.scatter(self.poY, self.poX, s=200, marker='<')\n",
    "            elif self.direction == DOWN:\n",
    "                plt.scatter(self.poY, self.poX, s=200, marker='v')\n",
    "            elif self.direction == RIGHT:\n",
    "                plt.scatter(self.poY, self.poX, s=200, marker='>')\n",
    "            else: # UP\n",
    "                plt.scatter(self.poY, self.poX, s=200, marker='^')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fa51e9c7-cfcb-480c-b7ea-138291a1d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_loop = SmallLoop(1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ee7240d7-136e-4e33-83b6-828c0be99962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7a8033f6a944eb81d8f1c9445f389f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "small_loop.display()\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeb933a-7fff-4c8c-9778-6aa188a3c115",
   "metadata": {},
   "source": [
    "# Enregistrons des données d'expérience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "254a8aab-d653-4ac5-91f5-0a11abcbf44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions, outcomes = [], []\n",
    "step = 0\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49051c-be45-45b1-b48a-7008887057cf",
   "metadata": {},
   "source": [
    "On génère des données d'experience en piochant des actions aléatoirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4a2531bc-0c9f-4430-b5c9-0fe54a5e81fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50\n",
      "Line: 1, Column: 1, direction: 0\n",
      "[5, 2, 5, 4, 5, 2, 2, 2, 3, 2, 3, 3, 5, 2, 3, 5, 3, 4, 5, 3, 2, 5, 4, 3, 4, 3, 3, 2, 5, 3, 3, 3, 4, 4, 4, 4, 4, 3, 2, 2, 5, 2, 2, 4, 2, 3, 2, 3, 4, 5, 2]\n",
      "[1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Step: {step}\")\n",
    "step += 1\n",
    "\n",
    "# action = step % 4\n",
    "action = np.random.choice([FORWARD, TURN_LEFT, TURN_RIGHT, FEEL_FRONT])\n",
    "outcome = small_loop.outcome(action)\n",
    "small_loop.display()\n",
    "actions.append(action)\n",
    "outcomes.append(outcome)\n",
    "\n",
    "print(actions)\n",
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75651c12-304d-431c-906d-49bb256302e3",
   "metadata": {},
   "source": [
    "# Créons le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e7f416ec-dd0c-460c-b062-80090c1ac232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataSetRNN(Dataset):\n",
    "    def __init__(self, actions:list, outcomes:list, dim_out:int, context_lenght:int, tokenizer=None):\n",
    "        \"\"\"\n",
    "        Creates a custom dataset\n",
    "\n",
    "        :param actions: list of actions\n",
    "        :param outcomes: list of outcomes\n",
    "        :param context_lenght: the length of the context\n",
    "        :param tokenizer: tokenizer to encode the actions and outcomes\n",
    "        \"\"\"\n",
    "        # Je ne suis pas sur d'y garder\n",
    "        assert context_lenght % 2 != 0, \"context_lenght must be odd\"\n",
    "        assert len(actions) == len(outcomes), \"actions and outcomes must have the same length\"\n",
    "        assert context_lenght <= len(actions) * 2, \"context_lenght must be less than or equal to the length of actions * 2\"\n",
    "        assert context_lenght > 0, \"context_lenght can't be negative or zero\"\n",
    "\n",
    "        self.actions = actions\n",
    "        self.outcomes = outcomes\n",
    "        self.context_lenght = context_lenght\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dim_out = dim_out\n",
    "\n",
    "    def create_x(self, idx):\n",
    "        gap = (self.context_lenght - 1) // 2\n",
    "        x = []\n",
    "        for i in range(idx, idx + gap):\n",
    "            x.append(self.actions[i])\n",
    "            x.append(self.outcomes[i])\n",
    "        x.append(self.actions[idx + gap])\n",
    "        y = self.outcomes[idx + gap]\n",
    "        if self.tokenizer is not None:\n",
    "            x = self.tokenizer.encode(x)\n",
    "            y = self.tokenizer.encode(y)\n",
    "        return x, y\n",
    "        \n",
    "                \n",
    "    def __len__(self):\n",
    "        gap = (self.context_lenght + 1) // 2\n",
    "        return len(self.actions) + 1 - gap\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the item at the index idx\n",
    "\n",
    "        :param idx: index\n",
    "        :return: x, y\n",
    "\n",
    "        Example\n",
    "        --------\n",
    "        actions = [\"a\", \"b\", \"c\", \"d\", \"e\"] \\n\n",
    "        outcomes = [\"1\", \"2\", \"3\", \"4\", \"5\"] \\n\n",
    "        context_lenght = 3 \\n\n",
    "        dataset = CustomDataSet(actions, outcomes, context_lenght) \\n\n",
    "        dataset[0] -> ([\"a\", \"1\", \"b\"], \"2\") \\n\n",
    "        dataset[1] -> ([\"b\", \"2\", \"c\"], \"3\") \\n\n",
    "        dataset[2] -> ([\"c\", \"3\", \"d\"], \"4\") \\n\n",
    "        dataset[3] -> ([\"d\", \"4\", \"e\"], \"5\") \\n\n",
    "        \"\"\"\n",
    "        x = []\n",
    "        x, label = self.create_x(idx)\n",
    "        x = torch.tensor(x, dtype=torch.int)\n",
    "        label = torch.tensor(label)\n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "717e39e2-5485-454c-88d8-a4fc461c7de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([5, 1, 2, 1, 5, 1, 4, 0, 5, 1, 2, 1, 2, 1, 2], dtype=torch.int32), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "data_set = CustomDataSetRNN(actions=actions, outcomes=outcomes, context_lenght=15, dim_out=2)\n",
    "print(data_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ab8b0c51-f1aa-4ec8-b3cd-8b96034c6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader_train = DataLoader(data_set, batch_size=16, shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b927fc6-bfd0-468f-ae66-33ab079c1033",
   "metadata": {},
   "source": [
    "# Créons le LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "261bb9f4-9da7-4038-8cb6-b1aa50e1e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_emb, output_size, num_layers=1, hidden_size=128):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Create an embedding layer to convert token indices to dense vectors\n",
    "        self.embedding = nn.Embedding(num_emb, hidden_size)\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, batch_first=True, dropout=0.5)\n",
    "        \n",
    "        # Define the output fully connected layer\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden_in, mem_in):\n",
    "        # Convert token indices to dense vectors\n",
    "        input_embs = self.embedding(input_seq)\n",
    "\n",
    "        # Pass the embeddings through the LSTM layer\n",
    "        output, (hidden_out, mem_out) = self.lstm(input_embs, (hidden_in, mem_in))\n",
    "                \n",
    "        # Pass the LSTM output through the fully connected layer to get the final output\n",
    "        return self.fc_out(output), hidden_out, mem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "eef2fd6a-fba1-4daf-a58d-9a852bdb5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the hidden layer and number of LSTM layers\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "len_vocab = 4 + 2 # 4 actions + 2 outcomes\n",
    "\n",
    "# Create the LSTM classifier model\n",
    "lstm_classifier = LSTM(num_emb=len_vocab, output_size=2, num_layers=num_layers, hidden_size=hidden_size).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "42a121ba-b701-4f74-b3f3-8c07c9c84254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the optimizer with Adam optimizer\n",
    "optimizer = optim.Adam(lstm_classifier.parameters(), lr=0.01)\n",
    "\n",
    "# Define the loss function as CrossEntropyLoss for classification\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10415d78-2c6b-4c68-ada3-879b1f629e79",
   "metadata": {},
   "source": [
    "# Entrainons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c87716ea-8ece-4125-ab51-bb493cfc2896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0890,  0.6139,  1.9633, -1.2024, -0.1643],\n",
      "        [-2.1183, -0.3616,  0.6788,  1.3540, -0.6551],\n",
      "        [ 0.1680,  1.5553,  1.3136,  0.9990, -1.4621]], requires_grad=True)\n",
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "print(input)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b7fa4958-837a-4b82-b696-903fd62797b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store training and test loss, as well as accuracy\n",
    "training_loss_logger = []\n",
    "test_loss_logger = []\n",
    "training_acc_logger = []\n",
    "test_acc_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "daa52704-1c1f-416f-ada8-1f4cba288a27",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 14984, 8824, 2744, 14364) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[304], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Iterate through training data loader\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, label \u001b[38;5;129;01min\u001b[39;00m data_loader_train:\n\u001b[0;32m     14\u001b[0m     bs \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Initialize hidden and memory states\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1144\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1143\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 14984, 8824, 2744, 14364) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Initialize training and test accuracy\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "\n",
    "# Loop through each epoch\n",
    "for epoch in range(100):    \n",
    "    # Set model to training mode\n",
    "    lstm_classifier.train()\n",
    "    steps = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Iterate through training data loader\n",
    "    for text, label in data_loader_train:\n",
    "        bs = label.shape[0]\n",
    "        \n",
    "\n",
    "        # Initialize hidden and memory states\n",
    "        hidden = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "        memory = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        pred, hidden, memory = lstm_classifier(text, hidden, memory)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(pred[:, -1, :], label)\n",
    "            \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Append training loss to logger\n",
    "        training_loss_logger.append(loss.item())\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        train_acc += (pred[:, -1, :].argmax(1) == label).sum()\n",
    "        steps += bs\n",
    "        print(f\"acc : {train_acc/steps} / {train_acc} / {steps} for epoch {epoch}\")\n",
    "        \n",
    "    # Calculate and append training accuracy for the epoch\n",
    "    print(f\"acc : {train_acc/steps} / {train_acc} / {steps} for epoch {epoch}\")\n",
    "    train_acc = train_acc / steps\n",
    "    training_acc_logger.append(train_acc)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    lstm_classifier.eval()\n",
    "    steps = 0\n",
    "    \n",
    "    # Iterate through test data loader\n",
    "    with torch.no_grad():\n",
    "        for text, label in data_loader_test:\n",
    "            bs = label.shape[0]\n",
    "\n",
    "            # Initialize hidden and memory states\n",
    "            hidden = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "            memory = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            pred, hidden, memory = lstm_classifier(text, hidden, memory)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(pred[:, -1, :], label)\n",
    "            test_loss_logger.append(loss.item())\n",
    "\n",
    "            # Calculate test accuracy\n",
    "            test_acc += (pred[:, -1, :].argmax(1) == label).sum()\n",
    "            steps += bs\n",
    "\n",
    "        # Calculate and append test accuracy for the epoch\n",
    "        test_acc = (test_acc/steps).item()\n",
    "        test_acc_logger.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e628999-696a-4049-8f7e-e260b7342dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
