{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eebb8ac-264e-4c67-92bf-320effd22e69",
   "metadata": {},
   "source": [
    "# AGENT5 en construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48264d7-4120-4cb6-904a-1d7f34f56e26",
   "metadata": {},
   "source": [
    "Dans ce notebook, le simulateur peut avoir des cellules à l'état UNKNWON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b81b5d6-8d74-448c-8dda-c4606449d209",
   "metadata": {},
   "source": [
    "# L'environnement Small Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2af90-1296-4cf0-a57e-8639467016c5",
   "metadata": {},
   "source": [
    "Implémentons une version de l'environnement qui nous permet d'afficher le simulateur interne de l'agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "656da749-2ac1-4a25-83f3-f8a2cdc38b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"sav\"\n",
    "\n",
    "FORWARD = 0\n",
    "FEEL_FRONT = 1\n",
    "FEEL_LEFT = 2\n",
    "FEEL_RIGHT = 3\n",
    "TURN_LEFT = 4\n",
    "TURN_RIGHT = 5\n",
    "\n",
    "ENV_HIGHT = 6\n",
    "ENV_WIDTH = 6\n",
    "SIM_HIGHT = 6\n",
    "SIM_WIDTH = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58ecd7a0-317a-4032-8b5d-fa0321f6432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from ipywidgets import Button, HBox,VBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "EMPTY = 0\n",
    "WALL = 1\n",
    "FEELING_EMPTY = 2\n",
    "FEELING_WALL = 3\n",
    "BUMPING = 4\n",
    "UNKNOWN = 5\n",
    "\n",
    "colors = [\"#b0b0b0\", '#b0b0b0', '#ffffff', '#535865', \"#F93943\"]  # Hidden environment\n",
    "colors = [\"#D6D6D6\", '#5C946E', '#FAE2DB', '#535865', \"#F93943\", \n",
    "          \"#eeeeee\", \"#85A48F\", '#FAE2DB', '#535865', \"#F93943\", '#BAC9E1']  # Simulator\n",
    "agent_color = \"#1976D2\"\n",
    "prediction_error_color = \"#f62dae\"\n",
    "agent_size = 200\n",
    "\n",
    "class SmallLoop():\n",
    "    def __init__(self, position, direction, grid):\n",
    "        self.environment_grid = np.array(grid)\n",
    "        self.display_grid = np.full((SIM_HIGHT, ENV_WIDTH + SIM_WIDTH), WALL, dtype=int)\n",
    "        self.display_grid[0:ENV_HIGHT, 0:ENV_WIDTH] = self.environment_grid[0:6, 0:6]\n",
    "        self.position = np.array(position) \n",
    "        self.direction = direction\n",
    "        self.cmap = ListedColormap(colors)\n",
    "        self.norm = BoundaryNorm(np.arange(-0.5, len(colors) + 0.5, 1.0), self.cmap.N)\n",
    "        self.marker_size = agent_size\n",
    "        self.marker_map = {LEFT: '<', DOWN: 'v', RIGHT: '>', UP: '^'}\n",
    "        self.marker_color = agent_color\n",
    "        self.directions = np.array([\n",
    "            [0, -1],  # Left\n",
    "            [1, 0],   # Down\n",
    "            [0, 1],   # Right\n",
    "            [-1, 0]   # Up\n",
    "            ])\n",
    "\n",
    "    def outcome(self, action):\n",
    "        \"\"\"Update the grid. Return the outcome of the action.\"\"\"\n",
    "        result = 0\n",
    "        self.display_grid[0:6, 0:6] = self.environment_grid\n",
    "\n",
    "        if action == FORWARD:  \n",
    "            target_position = self.position + self.directions[self.direction]\n",
    "            if self.environment_grid[tuple(target_position)] == EMPTY:\n",
    "                self.position[:] = target_position\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(target_position)] = BUMPING\n",
    "        \n",
    "        elif action == TURN_RIGHT:\n",
    "            self.direction = {LEFT: UP, DOWN: LEFT, RIGHT: DOWN, UP: RIGHT}[self.direction]\n",
    "        \n",
    "        elif action == TURN_LEFT:\n",
    "            self.direction = {LEFT: DOWN, DOWN: RIGHT, RIGHT: UP, UP: LEFT}[self.direction]\n",
    "        \n",
    "        elif action == FEEL_FRONT:\n",
    "            feeling_position = self.position + self.directions[self.direction]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_LEFT:\n",
    "            feeling_position = self.position + self.directions[(self.direction + 1) % 4]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_RIGHT:\n",
    "            feeling_position = self.position + self.directions[self.direction - 1]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "\n",
    "        # print(f\"Line: {self.position[0]}, Column: {self.position[1]}, direction: {self.direction}\")\n",
    "        return result  \n",
    "    \n",
    "    def display(self, simulator=None):\n",
    "        \"\"\"Display the grid in the notebook\"\"\"\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            if simulator is not None:\n",
    "                plt.scatter(simulator.position[1] + 6, simulator.position[0], s=self.marker_size, marker=self.marker_map[simulator.direction], \n",
    "                            c=\"#aaaaaa\")\n",
    "                self.display_grid[0:SIM_HIGHT, ENV_WIDTH:(ENV_WIDTH + SIM_WIDTH + 1)] = simulator.display_grid[0:SIM_HIGHT, 0:SIM_WIDTH] + 5\n",
    "            ax.imshow(self.display_grid, cmap=self.cmap, norm=self.norm)\n",
    "            plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "            ax.text(4.5, 0, f\"{step:>3}\", fontsize=12, color='White')\n",
    "            plt.show()\n",
    "    \n",
    "    def save(self, step):\n",
    "        \"\"\"Save the display as a PNG file\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "        ax.imshow(self.display_grid, cmap=self.cmap, norm=self.norm)\n",
    "        plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "        ax.text(4.5, 0, f\"{step:>4}\", fontsize=12, color='White')\n",
    "        plt.savefig(f\"{save_dir}/{step:04}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def clear(self, clear):\n",
    "        \"\"\"Clear the grid display\"\"\"\n",
    "        if clear:\n",
    "            self.display_grid[0:6, 0:6] = self.environment_grid\n",
    "\n",
    "#    def clone(self):\n",
    "#        \"\"\"Return a copy of the environment in its current state\"\"\"\n",
    "#        return SmallLoop(self.position, self.direction, self.environment_grid)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a908d8f-cf04-460a-9f56-32ee67ed3f9e",
   "metadata": {},
   "source": [
    "# Le simulateur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148d08f-9e5d-4bb7-a42d-6178e8a12c98",
   "metadata": {},
   "source": [
    "Le simulateur contient deux méthodes\n",
    "* La méthode `outcome(action)` renvoie l'outcome simulé ou `unknown`.\n",
    "* La méthode `simulate(interaction)` met à jour le simulateur en fonction de l'interaction enactée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "18e2776b-475e-4e48-8907-5411aa9875d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator():\n",
    "    def __init__(self, position, direction, grid):\n",
    "        self.simulation_grid = np.array(grid)\n",
    "        self.display_grid = np.array(grid)\n",
    "        self.initial_position = np.array(position) \n",
    "        self.position = np.array(position) \n",
    "        self.initial_direction = direction\n",
    "        self.direction = direction\n",
    "        self.marker_size = agent_size\n",
    "        self.marker_color = agent_color\n",
    "        self.directions = np.array([\n",
    "            [0, -1],  # Left\n",
    "            [1, 0],   # Down\n",
    "            [0, 1],   # Right\n",
    "            [-1, 0]   # Up\n",
    "            ])\n",
    "    def outcome(self, action):\n",
    "        \"\"\"Update the grid. Return the outcome of the action.\"\"\"\n",
    "        result = EMPTY\n",
    "        self.display_grid[0:6, 0:6] = self.simulation_grid\n",
    "\n",
    "        if action == FORWARD:  \n",
    "            target_position = self.position + self.directions[self.direction]\n",
    "            if self.simulation_grid[tuple(target_position)] == EMPTY:\n",
    "                self.position[:] = target_position\n",
    "            elif self.simulation_grid[tuple(target_position)] == UNKNOWN:\n",
    "                result = UNKNOWN\n",
    "            else:\n",
    "                result = WALL\n",
    "                self.display_grid[tuple(target_position)] = BUMPING\n",
    "        \n",
    "        elif action == TURN_RIGHT:\n",
    "            self.direction = {LEFT: UP, DOWN: LEFT, RIGHT: DOWN, UP: RIGHT}[self.direction]\n",
    "        \n",
    "        elif action == TURN_LEFT:\n",
    "            self.direction = {LEFT: DOWN, DOWN: RIGHT, RIGHT: UP, UP: LEFT}[self.direction]\n",
    "        \n",
    "        elif action == FEEL_FRONT:\n",
    "            feeling_position = self.position + self.directions[self.direction]\n",
    "            if self.simulation_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            elif self.simulation_grid[tuple(feeling_position)] == UNKNOWN:\n",
    "                result = UNKNOWN\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = WALL\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_LEFT:\n",
    "            feeling_position = self.position + self.directions[(self.direction + 1) % 4]\n",
    "            if self.simulation_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            elif self.simulation_grid[tuple(feeling_position)] == UNKNOWN:\n",
    "                result = UNKNOWN\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_RIGHT:\n",
    "            feeling_position = self.position + self.directions[self.direction - 1]\n",
    "            if self.simulation_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            elif self.simulation_grid[tuple(feeling_position)] == UNKNOWN:\n",
    "                result = UNKNOWN\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = WALL\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "\n",
    "        # print(f\"Line: {self.position[0]}, Column: {self.position[1]}, direction: {self.direction}\")\n",
    "        return result  \n",
    "    def simulate(self, i):\n",
    "        \"\"\"Update the grid. Return the outcome of the action.\"\"\"\n",
    "        if i._action == FORWARD:  \n",
    "            target_position = self.position + self.directions[self.direction]\n",
    "            if i._outcome == EMPTY:\n",
    "                self.position[:] = target_position\n",
    "                self.simulation_grid[tuple(self.position)] = EMPTY\n",
    "            else:\n",
    "                self.simulation_grid[tuple(target_position)] = WALL\n",
    "                self.display_grid[tuple(target_position)] = BUMPING\n",
    "        elif i._action == TURN_RIGHT:\n",
    "            self.direction = {LEFT: UP, DOWN: LEFT, RIGHT: DOWN, UP: RIGHT}[self.direction]\n",
    "        elif i._action == TURN_LEFT:\n",
    "            self.direction = {LEFT: DOWN, DOWN: RIGHT, RIGHT: UP, UP: LEFT}[self.direction]\n",
    "        elif i._action == FEEL_FRONT:\n",
    "            feeling_position = self.position + self.directions[self.direction]\n",
    "            if i._outcome == EMPTY:\n",
    "                self.simulation_grid[tuple(feeling_position)] = EMPTY\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                self.simulation_grid[tuple(feeling_position)] = WALL\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        elif i._action == FEEL_LEFT:\n",
    "            feeling_position = self.position + self.directions[(self.direction + 1) % 4]\n",
    "            if i._outcome == EMPTY:\n",
    "                self.simulation_grid[tuple(feeling_position)] = EMPTY\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                self.simulation_grid[tuple(feeling_position)] = WALL\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        elif i._action == FEEL_RIGHT:\n",
    "            feeling_position = self.position + self.directions[self.direction - 1]\n",
    "            if i._outcome == EMPTY:\n",
    "                self.simulation_grid[tuple(feeling_position)] = EMPTY\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                self.simulation_grid[tuple(feeling_position)] = WALL\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Reset the simulator\"\"\"\n",
    "        self.position[:] = self.initial_position\n",
    "        self.direction = self.initial_direction \n",
    "        self.display_grid[:] = np.full((SIM_HIGHT, SIM_WIDTH), EMPTY, dtype=int)\n",
    "\n",
    "    def clone(self):\n",
    "        \"\"\"Return a copy of the simulator in its current state\"\"\"\n",
    "        return Simulator(self.position, self.direction, self.simulation_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db93a7-8c36-4a14-8d83-1fd97777f6d9",
   "metadata": {},
   "source": [
    "# L'agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb1dd589-53a3-4793-9bbf-4a02d2bd1b36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, action, outcome, valence):\n",
    "        self.action = action\n",
    "        self.outcome = outcome\n",
    "        self.valence = valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self.action}{self.outcome}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self.action}{self.outcome}:{self.valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        return self.key() == other.key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125dea66-b78a-44d9-b4d7-a0e0c6f8f191",
   "metadata": {},
   "source": [
    "L'agent est instancié avec un simularteur interne qui lui est passé en argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f99d491-f59d-42ff-a068-853e32649bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, interactions, simulator):\n",
    "        \"\"\" Initialize the dictionary of interactions\"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in interactions}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "        self._actions = [i.action for i in interactions if i.outcome == 0]\n",
    "        self._simulator = simulator\n",
    "        # Initialize the dataframe with all the combinations of two actions\n",
    "        pairs = list(itertools.product(self._actions, repeat=2))  \n",
    "        self._default_df = pd.DataFrame(pairs, columns=['action1', 'action2'])\n",
    "        self._default_df[['outcome1', 'step', 'outcome2', 'valence']] = 0\n",
    "        self._simulation_step = 0\n",
    "        self._s1 = None\n",
    "        self.action_df = self._default_df.copy()\n",
    "        self.selection_df = None\n",
    "        self.simulation = simulator  # Used to display the current state of the simulation\n",
    "        # The dataframe of all possible simulations\n",
    "        simulations = list(itertools.product(range(1,5), range(1,5), range(4), self._actions))\n",
    "        self._simulation_df = pd.DataFrame(simulations, columns=['pre_x', 'pre_y', 'pre_d', 'action'])\n",
    "        self._simulation_df[['outcome', 'post_x', 'post_y', 'post_d']] = -1\n",
    "        self.history_df = pd.DataFrame({'x':[simulator.position[0]],'y':[simulator.position[1]], \n",
    "                                        'd':[simulator.direction], 'action':[0], 'predicted':[0],'outcome':[0]})\n",
    "\n",
    "    def simulate(self): \n",
    "        \"\"\"Compute the next row in action_df. Return True during the simulation and False when the simulation is over\"\"\"\n",
    "        a1, step, a2 = self.action_df.loc[self._simulation_step, ['action1', 'step', 'action2']]\n",
    "        if step == 0:\n",
    "            # Simulate the first action\n",
    "            self._s1 = self._simulator.clone()\n",
    "            o1 = self._s1.outcome(a1)\n",
    "            self.simulation = self._s1\n",
    "            valence = self._interactions[f\"{a1}{o1}\"].valence\n",
    "            # Mark all the rows of this action as 'simulated'\n",
    "            self.action_df.loc[self.action_df['action1'] == a1, 'step'] = 1\n",
    "            self.action_df.loc[self.action_df['action1'] == a1, 'outcome1'] = o1\n",
    "            self.action_df.loc[self.action_df['action1'] == a1, 'valence'] = valence\n",
    "            # Record this simulation\n",
    "            self._simulation_df.loc[(self._simulation_df['pre_x'] == self._simulator.position[0]) &\n",
    "                                     (self._simulation_df['pre_y'] == self._simulator.position[1]) &\n",
    "                                     (self._simulation_df['pre_d'] == self._simulator.direction) &\n",
    "                                     (self._simulation_df['action'] == a1), \n",
    "                                     ['outcome', 'post_x', 'post_y', 'post_d']] = [o1, self._s1.position[0], self._s1.position[1], self._s1.direction]\n",
    "        else:\n",
    "            # Simulate the second action\n",
    "            s2 = self._s1.clone()\n",
    "            o2 = s2.outcome(a2)\n",
    "            valence = self._interactions[f\"{a2}{o2}\"].valence\n",
    "            self.action_df.loc[(self.action_df['action1'] == a1) & (self.action_df['action2'] == a2), 'outcome2'] = o2\n",
    "            self.action_df.loc[(self.action_df['action1'] == a1) & (self.action_df['action2'] == a2), 'valence'] += valence\n",
    "            self.simulation = s2\n",
    "            self._simulation_step += 1\n",
    "            # Record this simulation\n",
    "            self._simulation_df.loc[(self._simulation_df['pre_x'] == self._s1.position[0]) &\n",
    "                                     (self._simulation_df['pre_y'] == self._s1.position[1]) &\n",
    "                                     (self._simulation_df['pre_d'] == self._s1.direction) &\n",
    "                                     (self._simulation_df['action'] == a2), \n",
    "                                     ['outcome', 'post_x', 'post_y', 'post_d']] = [o2, s2.position[0], s2.position[1], s2.direction]\n",
    "        # When all the pairs of action have been simulated or a positive valence has been found, return False to stop the simulation\n",
    "        return self._simulation_step < len(self.action_df) and valence < 0\n",
    "\n",
    "    def assimilate(self, outcome):\n",
    "        \"\"\" Process the received outcome and prepare for the next simulation \"\"\"\n",
    "        # Trace the previous cycle\n",
    "        previous_interaction = self._interactions[f\"{self._intended_interaction.action}{outcome}\"]\n",
    "        prediction_is_correct = self._intended_interaction.outcome == outcome\n",
    "        print(f\"Action: {self._intended_interaction.action}, Predicted: {self._intended_interaction.outcome}, Outcome: {outcome}, \" \n",
    "              f\"Prediction: {prediction_is_correct}, Valence: {previous_interaction.valence})\")\n",
    "        # Trace the history\n",
    "        new_history = pd.DataFrame({'x':[simulator.position[0]],'y':[simulator.position[1]], 'd':[simulator.direction], \n",
    "                                    'action':[self._intended_interaction.action], 'predicted':[self._intended_interaction.outcome] , \n",
    "                                    'outcome':[outcome]})\n",
    "        self.history_df = pd.concat([self.history_df, new_history], ignore_index=True)\n",
    "\n",
    "        if not prediction_is_correct:\n",
    "            self.adjust(outcome)\n",
    "        # Update the simulator\n",
    "        self._simulator.outcome(self._intended_interaction.action)\n",
    "        self.simulation = self._simulator\n",
    "        # Prepare the next simulation\n",
    "        self._simulation_step = 0\n",
    "        self.action_df = self._default_df.copy()\n",
    "\n",
    "    def adjust(self, outcome):\n",
    "        \"\"\"Adjust the simulator\"\"\"\n",
    "        # look for a compatible state in the simulations \n",
    "        filtered_df = self._simulation_df.loc[(self._simulation_df['action'] == self._intended_interaction.action) & \n",
    "                                          (self._simulation_df['outcome'] == outcome)].reset_index(drop=True)\n",
    "        if filtered_df.empty:\n",
    "            print(\"Adjustement failed to find a compatible position\")\n",
    "        else:\n",
    "            # Place the simulator in a compatible state\n",
    "            x, y, direction = filtered_df.loc[0,['pre_x', 'pre_y', 'pre_d']]\n",
    "            self._simulator.position[:] = [x, y]\n",
    "            self._simulator.direction = direction\n",
    "            print(filtered_df)\n",
    "            print(f\"Simulator adjusted to [{x},{y}], {direction}\")\n",
    "            \n",
    "    \n",
    "    def action(self):\n",
    "        \"\"\" Select the next interaction to try to enact \"\"\"\n",
    "        # Sort by descending valence\n",
    "        self.selection_df = self.action_df.sort_values(by=['valence'], ascending=[False]).reset_index(drop=True)\n",
    "        # Return the action that yeilds the highest valence\n",
    "        intended_action, intended_outcome = self.selection_df.loc[0, ['action1', 'outcome1']]\n",
    "        self._intended_interaction = self._interactions[f\"{intended_action}{intended_outcome}\"]\n",
    "        return self._intended_interaction.action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc3d53-873c-41a7-b359-6acef6d6bcb5",
   "metadata": {},
   "source": [
    "# Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fbad721a-46f2-412b-8dd6-7ee0e18e8cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39672278cb445b89b506a10570e836c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciate the small loop environment\n",
    "grid = [[WALL, WALL , WALL , WALL , WALL , WALL],\n",
    "        [WALL, EMPTY, EMPTY, EMPTY, WALL , WALL],\n",
    "        [WALL, EMPTY, WALL , EMPTY, EMPTY, WALL],\n",
    "        [WALL, EMPTY, WALL , WALL , EMPTY, WALL],\n",
    "        [WALL, EMPTY, EMPTY, EMPTY, EMPTY, WALL],\n",
    "        [WALL, WALL , WALL , WALL , WALL , WALL]]\n",
    "e = SmallLoop([1, 1], 0, grid)\n",
    "\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(FORWARD,0,5),\n",
    "    Interaction(FORWARD,1,-10),\n",
    "    Interaction(TURN_LEFT,0,-3),\n",
    "    Interaction(TURN_LEFT,1,-3),\n",
    "    Interaction(TURN_RIGHT,0,-3),\n",
    "    Interaction(TURN_RIGHT,1,-3),\n",
    "    Interaction(FEEL_FRONT,0,-1),\n",
    "    Interaction(FEEL_FRONT,1,-1),\n",
    "    Interaction(FEEL_LEFT,0,-1),\n",
    "    Interaction(FEEL_LEFT,1,-1),\n",
    "    Interaction(FEEL_RIGHT,0,-1),\n",
    "    Interaction(FEEL_RIGHT,1,-1)\n",
    "]\n",
    "grid = [[WALL, WALL , WALL , WALL , WALL , WALL],\n",
    "        [WALL, EMPTY, EMPTY, EMPTY, WALL , WALL],\n",
    "        [WALL, EMPTY, WALL , EMPTY, EMPTY, WALL],\n",
    "        [WALL, EMPTY, WALL , WALL , EMPTY, WALL],\n",
    "        [WALL, EMPTY, EMPTY, EMPTY, EMPTY, WALL],\n",
    "        [WALL, WALL , WALL , WALL , WALL , UNKNOWN]]\n",
    "simulator = Simulator([2, 3], UP, grid)\n",
    "# Unknown grid\n",
    "# np.full((SIM_HIGHT, SIM_WIDTH), UNKNOWN, dtype=int)\n",
    "agent = Agent(interactions, simulator)\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display(agent.simulation)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9b187590-6d57-42ba-966f-cce41f56e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24\n",
      "Action: 4, Predicted: 0, Outcome: 0, Prediction: True, Valence: -3)\n"
     ]
    }
   ],
   "source": [
    "step += 1\n",
    "print(f\"Step {step}\")\n",
    "while agent.simulate():\n",
    "    e.display(agent.simulation)\n",
    "action = agent.action()\n",
    "outcome = e.outcome(action)\n",
    "agent.assimilate(outcome)\n",
    "e.display(agent.simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0be63-2fdd-4b26-a4eb-c7c78db92fbe",
   "metadata": {},
   "source": [
    "La partie gauche représente l'environnement \"réel\" et la partie droite le simulateur interne de l'agent. \n",
    "\n",
    "Dans de nombreuses conditions initiales, l'agent parvient à trouver un état du simulateur qui permet de se synchroniser avec l'environnement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d1974-237a-4bd8-8024-81535b9816d1",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyton 3.12",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
