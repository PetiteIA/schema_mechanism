{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eebb8ac-264e-4c67-92bf-320effd22e69",
   "metadata": {},
   "source": [
    "# AGENT7 (En construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48264d7-4120-4cb6-904a-1d7f34f56e26",
   "metadata": {},
   "source": [
    "Ce notebook utilise un simulateur egocentré."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b81b5d6-8d74-448c-8dda-c4606449d209",
   "metadata": {},
   "source": [
    "# L'environnement Small Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2af90-1296-4cf0-a57e-8639467016c5",
   "metadata": {},
   "source": [
    "Implémentons une version de l'environnement qui nous permet d'afficher le simulateur interne de l'agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656da749-2ac1-4a25-83f3-f8a2cdc38b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"sav\"\n",
    "\n",
    "FORWARD = 0\n",
    "FEEL_FRONT = 1\n",
    "FEEL_LEFT = 2\n",
    "FEEL_RIGHT = 3\n",
    "TURN_LEFT = 4\n",
    "TURN_RIGHT = 5\n",
    "\n",
    "ENV_HIGHT = 6\n",
    "ENV_WIDTH = 6\n",
    "SIM_HIGHT = 3\n",
    "SIM_WIDTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "58ecd7a0-317a-4032-8b5d-fa0321f6432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from ipywidgets import Button, HBox,VBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "EMPTY = 0\n",
    "WALL = 1\n",
    "FEELING_EMPTY = 2\n",
    "FEELING_WALL = 3\n",
    "BUMPING = 4\n",
    "UNKNOWN = 5\n",
    "\n",
    "colors = [\"#b0b0b0\", '#b0b0b0', '#ffffff', '#535865', \"#F93943\"]  # Hidden environment\n",
    "colors = [\"#D6D6D6\", '#5C946E', '#FAE2DB', '#535865', \"#F93943\", \n",
    "          \"#EEEEEE\", \"#85A48F\", '#FAE2DB', '#535865', \"#F93943\", '#BAC9E1']  # Simulator\n",
    "agent_color = \"#1976D2\"\n",
    "prediction_error_color = \"#f62dae\"\n",
    "agent_size = 200\n",
    "\n",
    "class SmallLoop():\n",
    "    def __init__(self, position, direction, grid):\n",
    "        self.environment_grid = np.array(grid)\n",
    "        self.display_grid = np.full((ENV_HIGHT, ENV_WIDTH + SIM_WIDTH), WALL, dtype=int)\n",
    "        self.display_grid[0:self.environment_grid.shape[0], 0:self.environment_grid.shape[1]] = self.environment_grid\n",
    "        self.position = np.array(position) \n",
    "        self.direction = direction\n",
    "        self.cmap = ListedColormap(colors)\n",
    "        self.norm = BoundaryNorm(np.arange(-0.5, len(colors) + 0.5, 1.0), self.cmap.N)\n",
    "        self.marker_size = agent_size\n",
    "        self.marker_map = {LEFT: '<', DOWN: 'v', RIGHT: '>', UP: '^'}\n",
    "        self.marker_color = agent_color\n",
    "        self.directions = np.array([\n",
    "            [0, -1],  # Left\n",
    "            [1, 0],   # Down\n",
    "            [0, 1],   # Right\n",
    "            [-1, 0]   # Up\n",
    "            ])\n",
    "\n",
    "    def outcome(self, action):\n",
    "        \"\"\"Update the grid. Return the outcome of the action.\"\"\"\n",
    "        result = 0\n",
    "        self.display_grid[0:self.environment_grid.shape[0], 0:self.environment_grid.shape[1]] = self.environment_grid\n",
    "\n",
    "        if action == FORWARD:  \n",
    "            target_position = self.position + self.directions[self.direction]\n",
    "            if self.environment_grid[tuple(target_position)] == EMPTY:\n",
    "                self.position[:] = target_position\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(target_position)] = BUMPING\n",
    "        \n",
    "        elif action == TURN_RIGHT:\n",
    "            self.direction = {LEFT: UP, DOWN: LEFT, RIGHT: DOWN, UP: RIGHT}[self.direction]\n",
    "        \n",
    "        elif action == TURN_LEFT:\n",
    "            self.direction = {LEFT: DOWN, DOWN: RIGHT, RIGHT: UP, UP: LEFT}[self.direction]\n",
    "        \n",
    "        elif action == FEEL_FRONT:\n",
    "            feeling_position = self.position + self.directions[self.direction]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_LEFT:\n",
    "            feeling_position = self.position + self.directions[(self.direction + 1) % 4]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_RIGHT:\n",
    "            feeling_position = self.position + self.directions[self.direction - 1]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "\n",
    "        # print(f\"Line: {self.position[0]}, Column: {self.position[1]}, direction: {self.direction}\")\n",
    "        return result  \n",
    "    \n",
    "    def display(self, simulator=None):\n",
    "        \"\"\"Display the grid in the notebook\"\"\"\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            if simulator is not None:\n",
    "                plt.scatter(simulator.position[1] + 6, simulator.position[0], s=self.marker_size, marker=self.marker_map[UP], c=\"#aaaaaa\")\n",
    "                self.display_grid[0:SIM_HIGHT, ENV_WIDTH:(ENV_WIDTH + SIM_WIDTH + 1)] = simulator.display_grid[0:SIM_HIGHT, 0:SIM_WIDTH] + 5\n",
    "            ax.imshow(self.display_grid, cmap=self.cmap, norm=self.norm)\n",
    "            plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "            ax.text(4.5, 0, f\"{step:>3}\", fontsize=12, color='White')\n",
    "            plt.show()\n",
    "    \n",
    "    def save(self, step, img_nb, simulator):\n",
    "        \"\"\"Save the display as a PNG file\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "        ax.imshow(self.display_grid, cmap=self.cmap, norm=self.norm)\n",
    "        plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "        plt.scatter(simulator.position[1] + 6, simulator.position[0], s=simulator.marker_size, marker=self.marker_map[UP], \n",
    "                    c=simulator.marker_color)\n",
    "        ax.text(4.5, 0, f\"{step:>4}\", fontsize=10, color='White')\n",
    "        plt.savefig(f\"{save_dir}/{img_nb:04}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def clear(self, clear):\n",
    "        \"\"\"Clear the grid display\"\"\"\n",
    "        if clear:\n",
    "            self.display_grid[0:6, 0:6] = self.environment_grid\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a908d8f-cf04-460a-9f56-32ee67ed3f9e",
   "metadata": {},
   "source": [
    "# Le simulateur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148d08f-9e5d-4bb7-a42d-6178e8a12c98",
   "metadata": {},
   "source": [
    "Le simulateur implémente plusieurs opérateurs\n",
    "* `spawn(position)` create a wall at this position\n",
    "* `kill(position)` empty the cell at this position\n",
    "* `translate()` translate the simulator memory\n",
    "* `rotate_clockwise()` et `rotate_counterclockwise()` rotate the simulator memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "18e2776b-475e-4e48-8907-5411aa9875d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator():\n",
    "    def __init__(self, grid):\n",
    "        self.init_grid = np.array(grid)\n",
    "        self.simulation_grid = np.array(grid)\n",
    "        self.display_grid = np.array(grid)\n",
    "        self.position = np.array([1, 1]) \n",
    "        self.marker_size = agent_size\n",
    "        self.marker_color = agent_color\n",
    "\n",
    "    def translate(self):\n",
    "        \"\"\"Translate the grid when the agent moves forward\"\"\"\n",
    "        self.simulation_grid[:SIM_HIGHT, :SIM_WIDTH] = np.vstack((np.full((1, self.simulation_grid.shape[1]), UNKNOWN), self.simulation_grid[:-1])) \n",
    "        self.display_grid[:SIM_HIGHT, :SIM_WIDTH] = self.simulation_grid \n",
    "        \n",
    "    def rotate_clockwise(self):\n",
    "        \"\"\"Rotate the grid clockwise when the agent rotates left\"\"\"\n",
    "        self.simulation_grid[:SIM_HIGHT, :SIM_WIDTH] = np.rot90(self.simulation_grid, axes=(1,0))\n",
    "        self.display_grid[:SIM_HIGHT, :SIM_WIDTH] = self.simulation_grid\n",
    "    \n",
    "    def rotate_counterclockwise(self):\n",
    "        \"\"\"Rotate the grid counter-clockwise when the agent rotates right\"\"\"\n",
    "        self.simulation_grid[:SIM_HIGHT, :SIM_WIDTH] = np.rot90(self.simulation_grid)\n",
    "        self.display_grid[:SIM_HIGHT, :SIM_WIDTH] = self.simulation_grid\n",
    "\n",
    "    def bump(self):\n",
    "        \"\"\"Simulate bump when move forward wall\"\"\"\n",
    "        self.spawn()\n",
    "        self.display_grid[tuple(target_position)] = BUMPING\n",
    "        \n",
    "    def kill_front(self):\n",
    "        \"\"\"Delete the wall in front and display feeling empty\"\"\"\n",
    "        feeling_position = self.position + [-1, 0]\n",
    "        self.kill(feeling_position)\n",
    "        self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "        \n",
    "    def kill_left(self):\n",
    "        \"\"\"Delete the wall on the left and display feeling empty\"\"\"\n",
    "        feeling_position = self.position + [0, -1]\n",
    "        self.kill(feeling_position)\n",
    "        self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "        \n",
    "    def kill_right(self):\n",
    "        \"\"\"Delete the wall on the right and display feeling empty\"\"\"\n",
    "        feeling_position = self.position + [0, 1]\n",
    "        self.kill(feeling_position)\n",
    "        self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "\n",
    "    def spawn_front(self):\n",
    "        \"\"\"Delete the wall in front and display feeling empty\"\"\"\n",
    "        feeling_position = self.position + [-1, 0]\n",
    "        self.spawn(feeling_position)\n",
    "        self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "    def spawn_left(self):\n",
    "        \"\"\"Delete the wall on the left and display feeling empty\"\"\"\n",
    "        feeling_position = self.position + [0, -1]\n",
    "        self.spawn(feeling_position)\n",
    "        self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "    def spawn_right(self):\n",
    "        \"\"\"Delete the wall on the right and display feeling empty\"\"\"\n",
    "        feeling_position = self.position + [0, 1]\n",
    "        self.spawn(feeling_position)\n",
    "        self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "     \n",
    "    def spawn(self, position):\n",
    "        \"\"\"Spawn a wall at the position \"\"\"\n",
    "        self.simulation_grid[tuple(position)] = WALL\n",
    "        \n",
    "    def kill(self, position):\n",
    "        \"\"\"Remove a wall at the position \"\"\"\n",
    "        self.simulation_grid[tuple(position)] = EMPTY\n",
    "        \n",
    "    def outcome(self, action):\n",
    "        \"\"\"Update the grid. Return the outcome of the action.\"\"\"\n",
    "        result = EMPTY\n",
    "        self.display_grid[:, :] = self.simulation_grid\n",
    "\n",
    "        if action == FORWARD:  \n",
    "            target_position = self.position + [-1, 0]\n",
    "            if self.simulation_grid[tuple(target_position)] == EMPTY:\n",
    "                self.translate()\n",
    "            elif self.simulation_grid[tuple(target_position)] == WALL:\n",
    "                result = WALL\n",
    "                self.display_grid[tuple(target_position)] = BUMPING\n",
    "            else:\n",
    "                # Reset the simulation\n",
    "                result = UNKNOWN\n",
    "                self.simulation_grid[:SIM_HIGHT, :SIM_WIDTH] = self.init_grid \n",
    "                self.display_grid[:, :] = self.init_grid \n",
    "        \n",
    "        elif action == TURN_RIGHT:\n",
    "            self.rotate_counterclockwise()\n",
    "        \n",
    "        elif action == TURN_LEFT:\n",
    "            self.rotate_clockwise()\n",
    "        \n",
    "        elif action == FEEL_FRONT:\n",
    "            feeling_position = self.position + [-1, 0]\n",
    "            if self.simulation_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            elif self.simulation_grid[tuple(feeling_position)] == UNKNOWN:\n",
    "                result = UNKNOWN\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = WALL\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_LEFT:\n",
    "            feeling_position = self.position + [0, -1]\n",
    "            if self.simulation_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            elif self.simulation_grid[tuple(feeling_position)] == UNKNOWN:\n",
    "                result = UNKNOWN\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_RIGHT:\n",
    "            feeling_position = self.position + [0, 1]\n",
    "            if self.simulation_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            elif self.simulation_grid[tuple(feeling_position)] == UNKNOWN:\n",
    "                result = UNKNOWN\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = WALL\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "\n",
    "        # print(f\"Line: {self.position[0]}, Column: {self.position[1]}, direction: {self.direction}\")\n",
    "        return result  \n",
    "        \n",
    "    def clone(self):\n",
    "        \"\"\"Return a copy of the simulator in its current state\"\"\"\n",
    "        return Simulator(self.simulation_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db93a7-8c36-4a14-8d83-1fd97777f6d9",
   "metadata": {},
   "source": [
    "# L'agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "bb1dd589-53a3-4793-9bbf-4a02d2bd1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, action, outcome, valence):\n",
    "        self.action = action\n",
    "        self.outcome = outcome\n",
    "        self.valence = valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self.action}{self.outcome}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self.action}{self.outcome}:{self.valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        return self.key() == other.key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "8f99d491-f59d-42ff-a068-853e32649bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, interactions, simulator):\n",
    "        \"\"\" Initialize the dictionary of interactions\"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in interactions}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "        self._actions = [i.action for i in interactions if i.outcome == 0]\n",
    "        self._simulator = simulator\n",
    "        # Initialize the dataframe with all the combinations of two actions\n",
    "        pairs = list(itertools.product(self._actions, repeat=2))  \n",
    "        self._default_df = pd.DataFrame(pairs, columns=['action1', 'action2'])\n",
    "        self._default_df[['outcome1', 'step', 'outcome2', 'valence']] = 0\n",
    "        self._simulation_step = 0\n",
    "        self._s1 = None\n",
    "        self.action_df = self._default_df.copy()\n",
    "        self.selection_df = None\n",
    "        self.simulation = simulator  # Used to display the current state of the simulation\n",
    "        # The dataframe of all possible simulations\n",
    "        simulations = list(itertools.product(range(1,5), range(1,5), range(4), self._actions))\n",
    "        self._simulation_df = pd.DataFrame(simulations, columns=['pre_x', 'pre_y', 'pre_d', 'action'])\n",
    "        self._simulation_df[['outcome', 'post_x', 'post_y', 'post_d']] = -1\n",
    "        self.history_df = pd.DataFrame({'x':[simulator.position[0]],'y':[simulator.position[1]], \n",
    "                                        'd':[3], 'action':[0], 'predicted':[0],'outcome':[0]})\n",
    "        self.operators = {f\"{FORWARD}{EMPTY}\":self._simulator.translate,\n",
    "                      f\"{FORWARD}{WALL}\":self._simulator.bump,\n",
    "                      f\"{TURN_LEFT}{EMPTY}\":self._simulator.rotate_clockwise,\n",
    "                      f\"{TURN_RIGHT}{EMPTY}\":self._simulator.rotate_counterclockwise,\n",
    "                      f\"{FEEL_FRONT}{EMPTY}\":self._simulator.kill_front,\n",
    "                      f\"{FEEL_FRONT}{WALL}\":self._simulator.spawn_front,\n",
    "                      f\"{FEEL_LEFT}{EMPTY}\":self._simulator.kill_left,\n",
    "                      f\"{FEEL_LEFT}{WALL}\":self._simulator.spawn_left,\n",
    "                      f\"{FEEL_RIGHT}{EMPTY}\":self._simulator.kill_right,\n",
    "                      f\"{FEEL_RIGHT}{WALL}\":self._simulator.spawn_right}\n",
    "    \n",
    "\n",
    "    def simulate(self): \n",
    "        \"\"\"Compute the next row in action_df. Return True during the simulation and False when the simulation is over\"\"\"\n",
    "        a1, step, a2, o1, valence = self.action_df.loc[self._simulation_step, ['action1', 'step', 'action2', 'outcome1', 'valence']]\n",
    "        if step == 0:\n",
    "            # Simulate the first action\n",
    "            self._s1 = self._simulator.clone()\n",
    "            o1 = self._s1.outcome(a1)\n",
    "            self.simulation = self._s1\n",
    "            valence = self._interactions[f\"{a1}{o1}\"].valence\n",
    "            # Mark all the rows of this action as 'simulated'\n",
    "            self.action_df.loc[self.action_df['action1'] == a1, 'step'] = 1\n",
    "            self.action_df.loc[self.action_df['action1'] == a1, 'outcome1'] = o1\n",
    "            self.action_df.loc[self.action_df['action1'] == a1, 'valence'] = valence\n",
    "            # Record this simulation\n",
    "            self._simulation_df.loc[(self._simulation_df['pre_x'] == self._simulator.position[0]) &\n",
    "                                     (self._simulation_df['pre_y'] == self._simulator.position[1]) &\n",
    "                                     (self._simulation_df['pre_d'] == UP) &\n",
    "                                     (self._simulation_df['action'] == a1), \n",
    "                                     ['outcome', 'post_x', 'post_y', 'post_d']] = [o1, self._s1.position[0], self._s1.position[1], UP]\n",
    "        elif o1 != UNKNOWN:\n",
    "            # Simulate the second action\n",
    "            s2 = self._s1.clone()\n",
    "            o2 = s2.outcome(a2)\n",
    "            valence += self._interactions[f\"{a2}{o2}\"].valence\n",
    "            self.action_df.loc[(self.action_df['action1'] == a1) & (self.action_df['action2'] == a2), 'outcome2'] = o2\n",
    "            self.action_df.loc[(self.action_df['action1'] == a1) & (self.action_df['action2'] == a2), 'valence'] = valence\n",
    "            self.simulation = s2\n",
    "            self._simulation_step += 1\n",
    "            # Record this simulation\n",
    "            self._simulation_df.loc[(self._simulation_df['pre_x'] == self._s1.position[0]) &\n",
    "                                     (self._simulation_df['pre_y'] == self._s1.position[1]) &\n",
    "                                     (self._simulation_df['pre_d'] == UP) &\n",
    "                                     (self._simulation_df['action'] == a2), \n",
    "                                     ['outcome', 'post_x', 'post_y', 'post_d']] = [o2, s2.position[0], s2.position[1], UP]\n",
    "        else:\n",
    "            # Skip the second simulation\n",
    "            self._simulation_step += 1\n",
    "            \n",
    "        # When all the pairs of action have been simulated or a positive valence has been found, return False to stop the simulation\n",
    "        return self._simulation_step < len(self.action_df) and valence <= 0\n",
    "\n",
    "    def assimilate(self, outcome):\n",
    "        \"\"\" Process the received outcome and prepare for the next simulation \"\"\"\n",
    "        # Trace the previous cycle\n",
    "        previous_interaction = self._interactions[f\"{self._intended_interaction.action}{outcome}\"]\n",
    "        prediction_is_correct = self._intended_interaction.outcome == outcome\n",
    "        print(f\"Action: {self._intended_interaction.action}, Predicted: {self._intended_interaction.outcome}, Outcome: {outcome}, \" \n",
    "              f\"Prediction: {prediction_is_correct}, Valence: {previous_interaction.valence})\")\n",
    "        # Trace the history\n",
    "        new_history = pd.DataFrame({'x':[simulator.position[0]],'y':[simulator.position[1]], 'd':[UP], \n",
    "                                    'action':[self._intended_interaction.action], 'predicted':[self._intended_interaction.outcome] , \n",
    "                                    'outcome':[outcome]})\n",
    "        self.history_df = pd.concat([self.history_df, new_history], ignore_index=True)\n",
    "\n",
    "        if self._intended_interaction.outcome == UNKNOWN:\n",
    "            # Update the simulator by applying the operator corresponding to the enacted interaction\n",
    "            self.operators[previous_interaction.key()]()\n",
    "        elif not prediction_is_correct:\n",
    "            # Other unexpected outcome: adjust the simulator\n",
    "            self.adjust(outcome)\n",
    "        # Update the simulator\n",
    "        self._simulator.outcome(self._intended_interaction.action)\n",
    "        self.simulation = self._simulator\n",
    "        # Prepare the next simulation\n",
    "        self._simulation_step = 0\n",
    "        self.action_df = self._default_df.copy()\n",
    "\n",
    "    def adjust(self, outcome):\n",
    "        \"\"\"Adjust the simulator\"\"\"\n",
    "        # look for a compatible state in the simulations \n",
    "        filtered_df = self._simulation_df.loc[(self._simulation_df['action'] == self._intended_interaction.action) & \n",
    "                                          (self._simulation_df['outcome'] == outcome)].reset_index(drop=True)\n",
    "        if filtered_df.empty:\n",
    "            print(\"Adjustement failed to find a compatible position\")\n",
    "        else:\n",
    "            # Place the simulator in a compatible state\n",
    "            x, y, direction = filtered_df.loc[0,['pre_x', 'pre_y', 'pre_d']]\n",
    "            self._simulator.position[:] = [x, y]\n",
    "            self._simulator.direction = direction\n",
    "            print(filtered_df)\n",
    "            print(f\"Simulator adjusted to [{x},{y}], {direction}\")  \n",
    "    \n",
    "    def action(self):\n",
    "        \"\"\" Select the next interaction to try to enact \"\"\"\n",
    "        # Sort by descending valence\n",
    "        self.selection_df = self.action_df.sort_values(by=['valence'], ascending=[False]).reset_index(drop=True)\n",
    "        # Return the action that yeilds the highest valence\n",
    "        intended_action, intended_outcome = self.selection_df.loc[0, ['action1', 'outcome1']]\n",
    "        self._intended_interaction = self._interactions[f\"{intended_action}{intended_outcome}\"]\n",
    "        return self._intended_interaction.action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc3d53-873c-41a7-b359-6acef6d6bcb5",
   "metadata": {},
   "source": [
    "# Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "fbad721a-46f2-412b-8dd6-7ee0e18e8cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c980dfd02445a4a24d86418abc6e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciate the small loop environment\n",
    "grid = [[WALL, WALL , WALL , WALL , WALL , WALL],\n",
    "        [WALL, EMPTY, EMPTY, EMPTY, WALL , WALL],\n",
    "        [WALL, EMPTY, WALL , EMPTY, EMPTY, WALL],\n",
    "        [WALL, EMPTY, WALL , WALL , EMPTY, WALL],\n",
    "        [WALL, EMPTY, EMPTY, EMPTY, EMPTY, WALL],\n",
    "        [WALL, WALL , WALL , WALL , WALL , WALL]]\n",
    "e = SmallLoop([1, 1], 0, grid)\n",
    "\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(FORWARD, EMPTY, 5),\n",
    "    Interaction(FORWARD, WALL, -10),\n",
    "    Interaction(FORWARD, UNKNOWN, -5),\n",
    "    Interaction(TURN_LEFT, EMPTY,-3),\n",
    "    Interaction(TURN_RIGHT, EMPTY, -3),\n",
    "    Interaction(FEEL_FRONT, EMPTY, -1),\n",
    "    Interaction(FEEL_FRONT, WALL, -1),\n",
    "    Interaction(FEEL_FRONT, UNKNOWN, 1),\n",
    "    Interaction(FEEL_LEFT, EMPTY, -1),\n",
    "    Interaction(FEEL_LEFT, WALL, -1),\n",
    "    Interaction(FEEL_LEFT, UNKNOWN, 1),\n",
    "    Interaction(FEEL_RIGHT, EMPTY, -1),\n",
    "    Interaction(FEEL_RIGHT, WALL, -1),\n",
    "    Interaction(FEEL_RIGHT, UNKNOWN, 1),\n",
    "]\n",
    "# Intialize the simulator to UNKNOWN grid\n",
    "simulator_grid = np.full((SIM_HIGHT, SIM_WIDTH), UNKNOWN, dtype=int)\n",
    "simulator = Simulator(simulator_grid)\n",
    "agent = Agent(interactions, simulator)\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0\n",
    "img_nb = 0\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display(agent.simulation)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9b187590-6d57-42ba-966f-cce41f56e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n",
      "Action: 2, Predicted: 5, Outcome: 0, Prediction: False, Valence: -1)\n"
     ]
    }
   ],
   "source": [
    "step += 1\n",
    "img_nb += 1\n",
    "print(f\"Step {step}\")\n",
    "while agent.simulate():\n",
    "    e.display(agent.simulation)\n",
    "    e.save(step, img_nb, agent.simulation)  # Save the image file action = agent.action()\n",
    "    img_nb += 1\n",
    "action = agent.action()\n",
    "outcome = e.outcome(action)\n",
    "# print(agent.action_df)\n",
    "agent.assimilate(outcome)\n",
    "e.display(agent.simulation)\n",
    "e.save(step, img_nb, agent.simulation)  # Save the image file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0be63-2fdd-4b26-a4eb-c7c78db92fbe",
   "metadata": {},
   "source": [
    "La partie gauche représente l'environnement \"réel\" et la partie droite le simulateur interne de l'agent. \n",
    "\n",
    "Lorsque l'agent arrive dans des endroits ou les cellules du simulateur sont UNKNOWN, il sélectionne les interactions FEEL car elles ont une valence positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a640e-430e-47d6-9249-5e9e67083e26",
   "metadata": {},
   "source": [
    "# Créons le film gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5db138ee-3c2d-4d40-80f7-c811b6850207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import os\n",
    "\n",
    "img_dir = f\"./{save_dir}\"\n",
    "all_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "images = [imageio.imread(f) for f in all_files]\n",
    "imageio.mimsave(\"movie.gif\", images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66420c5-428c-4ca8-961f-3733e896ce14",
   "metadata": {},
   "source": [
    "![Agent8 demo](agent8.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182737a-db5c-4a7f-8b2a-6dace7cedcac",
   "metadata": {},
   "source": [
    "# Analyse\n",
    "\n",
    "Nous voudrions que l'agent apprenne par lui même le dictionnaire `operators` qui mémorise la correspondances entre les interactions et les operateurs du simulateur.\n",
    "\n",
    "L'ensemble de toutes les configurations possibles du dictionnaire `operators` correspond à toutes les permutations possibles des 10 interactions, soient 10! = 3 628 800 permutations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc48816-058f-4b1b-98e3-ff5da4dac541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
