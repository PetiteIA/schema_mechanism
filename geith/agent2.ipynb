{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eebb8ac-264e-4c67-92bf-320effd22e69",
   "metadata": {},
   "source": [
    "# AGENT2: L'agent qui simulait longtemps (en construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48264d7-4120-4cb6-904a-1d7f34f56e26",
   "metadata": {},
   "source": [
    "Ce notebook présente un agent qui simule plusieurs cycle à l'avance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b81b5d6-8d74-448c-8dda-c4606449d209",
   "metadata": {},
   "source": [
    "# L'environnement Small Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c49339f-e86c-4e5b-b1d1-7c0cf388e43d",
   "metadata": {},
   "source": [
    "Ajoutons la méthode `clone()` pour permettre de faire plusieurs simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "656da749-2ac1-4a25-83f3-f8a2cdc38b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"sav\"\n",
    "\n",
    "FORWARD = 0\n",
    "FEEL_FRONT = 1\n",
    "FEEL_LEFT = 2    # Not used\n",
    "FEEL_RIGHT = 3   # Not used\n",
    "TURN_LEFT = 4  # Turn 180°\n",
    "TURN_RIGHT = 5   # Not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "id": "58ecd7a0-317a-4032-8b5d-fa0321f6432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from ipywidgets import Button, HBox,VBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "EMPTY = 2\n",
    "WALL = 3\n",
    "FEELING_EMPTY = 4  # 2\n",
    "FEELING_WALL = 5  # 3\n",
    "BUMPING = 6  # 4\n",
    "\n",
    "colors = [\"#ffffff\", \"#dddddd\", \"#b0b0b0\", '#b0b0b0', '#ffffff', '#535865', \"#F93943\"]  # Hidden environment\n",
    "colors = [\"#eeeeee\", \"#85A48F\", \"#D6D6D6\", '#5C946E', '#FAE2DB', '#535865', \"#F93943\"]\n",
    "agent_color = \"#1976D2\"\n",
    "\n",
    "class SmallLoop():\n",
    "    def __init__(self, position, direction):\n",
    "        self.environment_grid = np.array([[WALL, EMPTY, EMPTY, EMPTY, WALL]])\n",
    "        self.display_grid = np.zeros((2, self.environment_grid.shape[1]), dtype=int)\n",
    "        self.display_grid[0, :] = self.environment_grid[0, :]\n",
    "        self.position = np.array(position) \n",
    "        self.direction = direction\n",
    "        self.cmap = ListedColormap(colors)\n",
    "        self.norm = BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5], self.cmap.N)\n",
    "        self.marker_size = 400\n",
    "        self.marker_map = {LEFT: '<', DOWN: 'v', RIGHT: '>', UP: '^'}\n",
    "        self.marker_color = agent_color\n",
    "        self.directions = np.array([\n",
    "            [0, -1],  # Left\n",
    "            [1, 0],   # Down\n",
    "            [0, 1],   # Right\n",
    "            [-1, 0]   # Up\n",
    "            ])\n",
    "\n",
    "    def outcome(self, action):\n",
    "        \"\"\"Update the grid. Return the outcome of the action.\"\"\"\n",
    "        result = 0\n",
    "        # x, y = self.position\n",
    "\n",
    "        if action == FORWARD:  \n",
    "            target_position = self.position + self.directions[self.direction]\n",
    "            if self.environment_grid[tuple(target_position)] == EMPTY:\n",
    "                self.position[:] = target_position\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(target_position)] = BUMPING\n",
    "        \n",
    "        elif action == TURN_RIGHT:\n",
    "            self.direction = {LEFT: UP, DOWN: LEFT, RIGHT: DOWN, UP: RIGHT}[self.direction]\n",
    "        \n",
    "        elif action == TURN_LEFT:\n",
    "            # self.direction = {LEFT: DOWN, DOWN: RIGHT, RIGHT: UP, UP: LEFT}[self.direction]\n",
    "            self.direction = {LEFT: RIGHT, DOWN: UP, RIGHT: LEFT, UP: DOWN}[self.direction]\n",
    "        \n",
    "        elif action == FEEL_FRONT:\n",
    "            feeling_position = self.position + self.directions[self.direction]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_LEFT:\n",
    "            feeling_position = self.position + self.directions[(self.direction + 1) % 4]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_RIGHT:\n",
    "            feeling_position = self.position + self.directions[self.direction - 1]\n",
    "            if self.environment_grid[tuple(feeling_position)] == EMPTY:\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = 1\n",
    "                self.display_grid[tuple(feeling_position)] = FEELING_WALL\n",
    "\n",
    "        # print(f\"Line: {self.position[0]}, Column: {self.position[1]}, direction: {self.direction}\")\n",
    "        return result  \n",
    "    \n",
    "    def display(self, simulator=None):\n",
    "        \"\"\"Display the grid in the notebook\"\"\"\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            if simulator is not None:\n",
    "                plt.scatter(simulator.position[1], 1, s=self.marker_size, marker=self.marker_map[simulator.direction], c=\"#aaaaaa\")\n",
    "                self.display_grid[1, :] = simulator.environment_grid[0, :] - 2\n",
    "            ax.imshow(self.display_grid, cmap=self.cmap, norm=self.norm)\n",
    "            plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "            ax.text(4.5, 0, f\"{step:>3}\", fontsize=12, color='White')\n",
    "            plt.show()\n",
    "    \n",
    "    def save(self, step):\n",
    "        \"\"\"Save the display as a PNG file\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "        ax.imshow(self.display_grid, cmap=self.cmap, norm=self.norm)\n",
    "        plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "        ax.text(4.5, 0, f\"{step:>4}\", fontsize=12, color='White')\n",
    "        plt.savefig(f\"{save_dir}/{step:04}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def clear(self, clear):\n",
    "        \"\"\"Clear the grid display\"\"\"\n",
    "        if clear:\n",
    "            self.display_grid[0, :] = self.environment_grid\n",
    "\n",
    "    def clone(self):\n",
    "        \"\"\"Return a copy of the environment in its current state\"\"\"\n",
    "        return SmallLoop(self.position, self.direction)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db93a7-8c36-4a14-8d83-1fd97777f6d9",
   "metadata": {},
   "source": [
    "# L'agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "id": "bb1dd589-53a3-4793-9bbf-4a02d2bd1b36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, action, outcome, valence):\n",
    "        self.action = action\n",
    "        self.outcome = outcome\n",
    "        self.valence = valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self.action}{self.outcome}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self.action}{self.outcome}:{self.valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        return self.key() == other.key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125dea66-b78a-44d9-b4d7-a0e0c6f8f191",
   "metadata": {},
   "source": [
    "L'agent est instancié avec un simularteur interne qui lui est passé en argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "8f99d491-f59d-42ff-a068-853e32649bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"Creating our agent\"\"\"\n",
    "    def __init__(self, _interactions, simulator):\n",
    "        \"\"\" Initialize the dictionary of interactions\"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "        self._actions = [i.action for i in _interactions if i.outcome == OUTCOME_EMPTY]\n",
    "        self.action_df = pd.DataFrame({\"action\": [i.action for i in _interactions if i.outcome == OUTCOME_EMPTY]}) # , columns=['action', 'outcome', 'valence'])\n",
    "        self.simulator = simulator\n",
    "\n",
    "    def select_action(self): \n",
    "        \"\"\"Select the action that yeilds the highest valence\"\"\"\n",
    "        # Roll the actions to try different actions when all outcome are equal\n",
    "        self.action_df = pd.concat([self.action_df.tail(1), self.action_df.head(len(self.action_df) - 1)], ignore_index=True)\n",
    "        # self.action_df = pd.concat([self.action_df.iloc[1:], self.action_df.iloc[[0]]], ignore_index=True)\n",
    "        # Try every action in a clone of the simulator\n",
    "        self.action_df[\"outcome\"] = self.action_df.apply(lambda row: self.simulator.clone().outcome(row[\"action\"]), axis=1)\n",
    "        # Record the expected valence for each resulting interaction\n",
    "        self.action_df[\"valence\"] = self.action_df.apply(lambda row: self._interactions[f\"{row[\"action\"]}{row[\"outcome\"]}\"].valence, axis=1)\n",
    "        # Sort by descending valence\n",
    "        self.action_df = self.action_df.sort_values(by=['valence'], ascending=[False]).reset_index(drop=True)\n",
    "        # print(self.action_df)\n",
    "        # Return the action that yeilds the highest valence\n",
    "        return self.action_df.loc[0, \"action\"]\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\" Tracing the previous cycle \"\"\"\n",
    "        previous_interaction = self._interactions[f\"{self._intended_interaction.action}{_outcome}\"]\n",
    "        print(f\"Action: {self._intended_interaction.action}, Prediction: {self._intended_interaction.outcome}, Outcome: {_outcome}, \" \n",
    "              f\"Prediction: {self._intended_interaction.outcome == _outcome}, Valence: {previous_interaction.valence})\")\n",
    "\n",
    "        \"\"\" Computing the next interaction to try to enact \"\"\"\n",
    "        # Select the next action\n",
    "        intended_action = self.select_action()\n",
    "        \n",
    "        # Predict the outcome based on simulation\n",
    "        intended_outcome = self.simulator.outcome(intended_action)\n",
    "        # Memorize the intended interaction\n",
    "        self._intended_interaction = self._interactions[f\"{intended_action}{intended_outcome}\"]\n",
    "        return intended_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc3d53-873c-41a7-b359-6acef6d6bcb5",
   "metadata": {},
   "source": [
    "# Run the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed57f2f-1337-4821-8c93-9f9a05e126d2",
   "metadata": {},
   "source": [
    "Nous utilisons un instance de l'environnement lui même comme simulateur passé à l'agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "fbad721a-46f2-412b-8dd6-7ee0e18e8cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dc13871b974438968396e4bb00cfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciate the small loop environment\n",
    "e = SmallLoop([0, 1], 0)\n",
    "\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(FORWARD, 0, 5),\n",
    "    Interaction(FORWARD, 1, -10),\n",
    "    Interaction(FEEL_FRONT, 0, -1),\n",
    "    Interaction(FEEL_FRONT, 1, -1),\n",
    "    Interaction(TURN_LEFT, 0, -3),\n",
    "    Interaction(TURN_LEFT, 1, -3)\n",
    "]\n",
    "simulator = SmallLoop([0, 1], 0)\n",
    "a = Agent(interactions, simulator)\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display()\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "9b187590-6d57-42ba-966f-cce41f56e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>outcome</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action  outcome  valence\n",
       "0       1        1       -1\n",
       "1       4        0       -3\n",
       "2       0        1      -10"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "e.display()\n",
    "outcome = e.outcome(action)\n",
    "a.action_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f477f-aa9a-4742-9f35-413638cafd9b",
   "metadata": {},
   "source": [
    "L'agent sélectionne toujours l'action `feel` car c'est celle qui produit l'interaction qui a la valence la moins basse (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c88b4-879f-432d-ad25-b4e19e2ab778",
   "metadata": {},
   "source": [
    "# Agent2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d0e6e-9586-4749-a791-d89aca260fdd",
   "metadata": {},
   "source": [
    "Implémentons l'Agent2 qui simule plusieurs coups à l'avance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "id": "69036914-5f6d-42bb-94a0-61db733c5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2(Agent):\n",
    "    def select_action(self): \n",
    "        \"\"\"Select the action that yeilds the highest valence\"\"\"\n",
    "        self.action_df = pd.DataFrame(columns=['action', 'outcome', 'a2', 'o2', 'valence'])\n",
    "        # Simulate two steps ahead\n",
    "        for a1 in self._actions:\n",
    "            s1 = self.simulator.clone()\n",
    "            o1 = s1.outcome(a1)\n",
    "            for a2 in self._actions:\n",
    "                s2 = s1.clone()\n",
    "                o2 = s2.outcome(a2)\n",
    "                v = self._interactions[f\"{a1}{o1}\"].valence + self._interactions[f\"{a2}{o2}\"].valence\n",
    "                new_df = pd.DataFrame({\"action\": [a1], \"outcome\": [o1], \"a2\": [a2], \"o2\": [o2], \"valence\": [v]})\n",
    "                self.action_df = pd.concat([self.action_df, new_df], ignore_index=True)\n",
    "\n",
    "        # Sort by descending valence\n",
    "        self.action_df = self.action_df.sort_values(by=['valence'], ascending=[False]).reset_index(drop=True)\n",
    "        # Return the action that yeilds the highest valence\n",
    "        return self.action_df.loc[0, \"action\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c6dd1-257c-44b8-9581-3c9b6df95b6e",
   "metadata": {},
   "source": [
    "## Testons l'Agent2 en lui passant le Small Loop comme simulateur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc605d-cfb0-4aa9-b78b-fec49063409d",
   "metadata": {},
   "source": [
    "Le simulateur est initialisée avec une position différente de celle de l'environnement. \n",
    "Le simulateur se synchronise rapidement avec l'environnement quand l'agent est bloqué par un mur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "6f6b5c27-ddca-4f4a-98a3-0603e05fb3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5509914abf4967b5d54087651e6910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciate the small loop environment\n",
    "e = SmallLoop([0, 1], 0)\n",
    "\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(FORWARD, 0, 5),\n",
    "    Interaction(FORWARD, 1, -10),\n",
    "    Interaction(FEEL_FRONT, 0, -1),\n",
    "    Interaction(FEEL_FRONT, 1, -1),\n",
    "    Interaction(TURN_LEFT, 0, -3),\n",
    "    Interaction(TURN_LEFT, 1, -3)\n",
    "]\n",
    "simulator = SmallLoop([0, 2], 0)\n",
    "a = Agent2(interactions, simulator)\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display(a.simulator)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "ffaf9a17-b16b-421a-b23c-e394343641a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction: False, Valence: -10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>outcome</th>\n",
       "      <th>a2</th>\n",
       "      <th>o2</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  action outcome a2 o2 valence\n",
       "0      4       0  0  0       2\n",
       "1      1       1  1  1      -2\n",
       "2      1       1  4  0      -4\n",
       "3      4       0  1  0      -4\n",
       "4      4       0  4  0      -6\n",
       "5      0       1  1  1     -11\n",
       "6      1       1  0  1     -11\n",
       "7      0       1  4  0     -13\n",
       "8      0       1  0  1     -20"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "e.display(a.simulator)\n",
    "e.clear(True)\n",
    "outcome = e.outcome(action)\n",
    "a.action_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c8070-8b6c-4f23-9cde-0bc692d44177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e78f3-fc82-482a-8267-f1fab583be7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyton 3.12",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
