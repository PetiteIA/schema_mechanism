{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f34084-d4b8-4160-89ad-a927a0919615",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/notebooks/agent5-DNN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# UTILISATION D'UNE LSTM POUR ESTIMER LA VALENCE ATTENDUE DE CHAQUE ACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f079acd-1557-4e30-bf85-7432f730d1dc",
   "metadata": {},
   "source": [
    "Ce notrebook présente notre troisième agent dotté d'un DNN. \n",
    "Nous entrainons un LSTM à chaque cycle d'interaction avec toutes les séquences mémorisées. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "## La classe Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44155c4a-d038-40b3-be33-e8cf77c5f976",
   "metadata": {},
   "source": [
    "On crée un token entier pour chaque interaction: `key = action * BASE_ACTION + outcome`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e96c3637-4161-49aa-9f1d-0d3342de92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_ACTION = 1 \n",
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, action, outcome, valence):\n",
    "        self.action = action\n",
    "        self.outcome = outcome\n",
    "        self.valence = valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary. \"\"\"\n",
    "        return self.action * BASE_ACTION + self.outcome \n",
    "        # return f\"{self.action}{self.outcome}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self.action}{self.outcome}:{self.valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        return self.key() == other.key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "718ff1f9-fbe1-4fe2-be4f-c2b9284fa985",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION1 = 0\n",
    "ACTION2 = 2\n",
    "OUTCOME1 = 0\n",
    "OUTCOME2 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1c38f-c8ed-48e5-bc6a-e7078ed3e5e4",
   "metadata": {},
   "source": [
    "## Environment1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d65ca61-9386-4260-a406-ec766063569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \"\"\" In Environment 1, action 2 yields outcome 0, action 3 yields outcome 1 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        if _action == ACTION1:\n",
    "            return OUTCOME1\n",
    "        else:\n",
    "            return OUTCOME2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d7d6-5444-4778-b97a-cc5bd34c6cd2",
   "metadata": {},
   "source": [
    "## Environment2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91ae8fba-72aa-4194-be5a-2f27a1637e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment2:\n",
    "    \"\"\" In Environment 2, action 2 yields outcome 1, action 3 yields outcome 0 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        if _action == ACTION1:\n",
    "            return OUTCOME2\n",
    "        else:\n",
    "            return OUTCOME1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab7280-a559-4fc2-8668-4285aac82d8d",
   "metadata": {},
   "source": [
    "## Environment3 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df2375-680e-4df9-a0ed-e84802aac1a4",
   "metadata": {},
   "source": [
    "Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bf9a4ba-2703-49e9-a63f-b72c08b8663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment3:\n",
    "    \"\"\" Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment3 \"\"\"\n",
    "        self.previous_action = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        if _action == self.previous_action:\n",
    "            _outcome = OUTCOME1\n",
    "        else:\n",
    "            _outcome = OUTCOME2\n",
    "        self.previous_action = _action\n",
    "        return _outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372722d3-e6a3-4fb1-8c65-d58d6b825a17",
   "metadata": {},
   "source": [
    "## Environment4 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553bc09f-31b0-4577-b153-6fe98225c892",
   "metadata": {},
   "source": [
    "Environment4 behaves like Environment1 during the first 10 cycles and then like Environment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf9630d4-7e78-450b-8940-463e2cd2f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment4:\n",
    "    \"\"\" Environm4 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment4 \"\"\"\n",
    "        self.step = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        \"\"\"Take the action and generate the next outcome \"\"\"\n",
    "        self.step += 1\n",
    "        # Behave like environment1 during the first 10 steps\n",
    "        if self.step < 10:\n",
    "            if _action == ACTION1:\n",
    "                return OUTCOME1\n",
    "            else:\n",
    "                return OUTCOME2            \n",
    "        # Behave like Environment2 after the first 10 steps\n",
    "        else: \n",
    "            if _action == ACTION1:\n",
    "                return OUTCOME2\n",
    "            else:\n",
    "                return OUTCOME1            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f49f7-9352-4938-9ee2-7d8a7bb5065a",
   "metadata": {},
   "source": [
    "## Initialize the interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59da5f51-d5db-4cf4-8bd0-036ec11eaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [\n",
    "    Interaction(ACTION1,OUTCOME1,-1),\n",
    "    Interaction(ACTION1,OUTCOME2,1),\n",
    "    Interaction(ACTION2,OUTCOME1,-1),\n",
    "    Interaction(ACTION2,OUTCOME2,1),\n",
    "    # Interaction(4,0,-1),\n",
    "    # Interaction(5,1,1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310417af-f0ed-44c2-b99c-9e374bd9eabf",
   "metadata": {},
   "source": [
    "# AGENT LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef084288-168a-4a54-9934-5adf87e16a05",
   "metadata": {},
   "source": [
    "Implémentons l'Agent3 qui va prédire la probabilité des prochains tokens d'une séquence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87058ae-6a93-4936-9c25-ed71fc92a189",
   "metadata": {},
   "source": [
    "## Créons le modèle de LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172732f1-0462-427b-ac80-bb4469e23302",
   "metadata": {},
   "source": [
    "Le modèle a deux entrées: previous_interaction, last_interaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74196251-d38e-43bd-beba-3c97dc76f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.len_vocab = 4\n",
    "        self.num_layers = 1\n",
    "        self.hidden_size = 64\n",
    "\n",
    "        embedding_dim = self.len_vocab \n",
    "        # Create an embedding layer to convert token indices to dense vectors\n",
    "        self.embedding = nn.Embedding(self.len_vocab, embedding_dim )\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True) # , dropout=0.5)\n",
    "        \n",
    "        # Define the output fully connected layer\n",
    "        self.fc_out = nn.Linear(self.hidden_size, self.len_vocab)\n",
    "\n",
    "        self._optimizer = torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "        self._loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    def forward(self, input_seq, hidden_in, mem_in):\n",
    "        # Convert token indices to dense vectors\n",
    "        input_embs = self.embedding(input_seq)\n",
    "\n",
    "        # Pass the embeddings through the LSTM layer\n",
    "        output, (hidden_out, mem_out) = self.lstm(input_embs, (hidden_in, mem_in))\n",
    "                \n",
    "        # Pass the LSTM output through the fully connected layer to get the final output\n",
    "        return self.fc_out(output), hidden_out, mem_out\n",
    "\n",
    "    def fit(self, inputs, targets):\n",
    "\n",
    "        input_tensor = torch.tensor(inputs) # , dtype=torch.int)\n",
    "        # print(\"input tensor\", input_tensor)\n",
    "        labels = torch.tensor(targets)\n",
    "        # print(\"label tensor\", labels)\n",
    "        \n",
    "        # Loop through each epoch\n",
    "        for epoch in range(20):    \n",
    "            # Set model to training mode\n",
    "            self.train()\n",
    "            train_acc = 0\n",
    "    \n",
    "            # Initialize hidden and memory states\n",
    "            hidden = torch.zeros(self.num_layers, input_tensor.shape[0], self.hidden_size, device=\"cpu\")\n",
    "            memory = torch.zeros(self.num_layers, input_tensor.shape[0], self.hidden_size, device=\"cpu\")\n",
    "    \n",
    "            # Forward pass through the model\n",
    "            pred, hidden, memory = self(input_tensor, hidden, memory)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = self._loss_func(pred[:, -1, :], labels)\n",
    "        \n",
    "            # Backpropagation and optimization\n",
    "            self._optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "    \n",
    "            # Append training loss to logger\n",
    "            # training_loss_logger.append(loss.item())\n",
    "    \n",
    "            # Calculate training accuracy\n",
    "            train_acc += (pred[:, -1, :].argmax(1) == labels).sum()\n",
    "            # print(f\"acc : {train_acc/len(labels):.3f} = {train_acc}/{len(labels)} for epoch {epoch}\")\n",
    "\n",
    "    def predict(self, sequence):\n",
    "        # Construct the context sequence\n",
    "        sequence = torch.tensor(sequence, dtype=torch.int)\n",
    "\n",
    "        h = torch.zeros(self.num_layers, sequence.shape[0], self.hidden_size, device=\"cpu\")\n",
    "        cell = torch.zeros(self.num_layers, sequence.shape[0], self.hidden_size, device=\"cpu\")\n",
    "        \n",
    "        with torch.no_grad():  # Pas de calcul de gradients en mode prédiction\n",
    "            logits, _, _ = self(sequence, h, cell)\n",
    "        ## probabilities = nn.functional.softmax(logits[0, -1, :], dim=0).tolist()\n",
    "        # Compute the probability of each outcome for each action\n",
    "        pairwise_logits = logits[0, -1, :].reshape(-1, 2)\n",
    "        probabilities = nn.functional.softmax(pairwise_logits, dim=1).flatten().tolist()\n",
    "        # print(\"probabilities\", probabilities)\n",
    "        return probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c09ae4-2781-4b91-9a87-9ef7b73b8b83",
   "metadata": {},
   "source": [
    "# Définisson l'agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f804222b-c3e5-4228-9ba0-ce6fc57b5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"Creating our agent\"\"\"\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize the dictionary of interactions\"\"\"\n",
    "        # Initialise le réseau de neurone\n",
    "        self._model = LSTM()\n",
    "        \n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._intended_interaction = list(self._interactions.values())[0]\n",
    "        self._last_interaction = None\n",
    "        self._previous_interaction = None\n",
    "        self._penultimate_interaction = None\n",
    "        # Le dataframe pour mémoriser les séquences d'interactions\n",
    "        self.sequences_df = pd.DataFrame({\n",
    "            'i1': pd.Series(dtype='int'),\n",
    "            'i2': pd.Series(dtype='int'),\n",
    "            'i3': pd.Series(dtype='int'),\n",
    "            'action': pd.Series(dtype='int'),\n",
    "            'valence': pd.Series(dtype='int'),\n",
    "            'count': pd.Series(dtype='int'),\n",
    "            'proclivity': pd.Series(dtype='int'),\n",
    "        })\n",
    "    \n",
    "    def action(self, _outcome):\n",
    "        \"\"\" Tracing the previous cycle \"\"\"\n",
    "        self._penultimate_interaction = self._previous_interaction \n",
    "        self._previous_interaction = self._last_interaction\n",
    "        self._last_interaction = self._interactions[self._intended_interaction.action * BASE_ACTION + _outcome ]\n",
    "        print(f\"Action: {self._intended_interaction.action}, Prediction: {self._intended_interaction.outcome}, \"\n",
    "              f\"Outcome: {_outcome}, Prediction_correct: {self._intended_interaction.outcome == _outcome}, \"\n",
    "              f\"Valence: {self._last_interaction.valence})\")\n",
    "\n",
    "        \"\"\" Computing the next interaction to try to enact \"\"\"\n",
    "        # Enregistre les séquences dans sequences_df et entraine le LSTM\n",
    "        self.learn()       \n",
    "\n",
    "        # Prédit les probabilités des prochaines interactions\n",
    "        probability_df = self.create_probability_df()\n",
    "\n",
    "        # Sélectionne l'intended interaction\n",
    "        self._intended_interaction = self.decide(probability_df)        \n",
    "\n",
    "        # Return the action\n",
    "        return self._intended_interaction.action\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"Record sequences\"\"\"\n",
    "        if self._previous_interaction is not None and self._last_interaction is not None and self._penultimate_interaction is not None:\n",
    "            # Record or increment the last sequence\n",
    "            condition = ((self.sequences_df['i1'] == self._penultimate_interaction.key()) & \n",
    "                        (self.sequences_df['i2'] == self._previous_interaction.key()) & \n",
    "                        (self.sequences_df['i3'] == self._last_interaction.key()))\n",
    "            if self.sequences_df[condition].empty:\n",
    "                new_sequence = pd.DataFrame({\n",
    "                    'i1': [self._penultimate_interaction.key()], \n",
    "                    'i2': [self._previous_interaction.key()], \n",
    "                    'i3': [self._last_interaction.key()], \n",
    "                    'action': [self._last_interaction.action], \n",
    "                    'valence': [self._last_interaction.valence],\n",
    "                    'count': [1], \n",
    "                    'proclivity': [0]\n",
    "                })\n",
    "                self.sequences_df = pd.concat([self.sequences_df, new_sequence], ignore_index=True)\n",
    "            else:\n",
    "                self.sequences_df.loc[condition, 'count'] += 1\n",
    "            # Entraine le réseau de neurone avec les séquences enregistrées dans sequences_df\n",
    "            x = self.sequences_df[['i1', 'i2']].values.tolist()\n",
    "            y = self.sequences_df['i3'].tolist()\n",
    "            self._model.fit(x, y)\n",
    "\n",
    "    def create_probability_df(self):\n",
    "        \"\"\"Crée le dataframe de probabilités\"\"\"\n",
    "        if self._previous_interaction is not None and self._last_interaction is not None and self._penultimate_interaction is not None:\n",
    "            probabilities = self._model.predict([[self._previous_interaction.key(), self._last_interaction.key()]])        \n",
    "            # Le dataframe pour trouver la meilleure expected valence\n",
    "            probability_df = pd.DataFrame({\n",
    "                'interaction': [i.key() for i in self._interactions.values()],\n",
    "                'action': [i.action for i in self._interactions.values()],\n",
    "                'outcome': [i.outcome for i in self._interactions.values()],\n",
    "                'valence': [i.valence for i in self._interactions.values()],\n",
    "                'probability': probabilities})\n",
    "            probability_df['expected_valence'] = probability_df['valence'] * probability_df['probability']\n",
    "            print(probability_df)\n",
    "            return probability_df\n",
    "        else:\n",
    "            return pd.DataFrame(columns=['interaction', 'action', 'outcome', 'valence', 'probability', 'expected_valence'])\n",
    "\n",
    "    def decide(self, probability_df):\n",
    "        \"\"\"Decide the intended interaction based on the dataframe of probabilities\"\"\"\n",
    "        # On aggrege par action en sommant l'expected valence\n",
    "        action_probability_df = probability_df.groupby('action').agg({'expected_valence': 'sum'}).reset_index()\n",
    "        # On trie \n",
    "        action_df = action_probability_df.sort_values(by=['expected_valence'], ascending=[False]).reset_index(drop=True)\n",
    "        print(action_df)\n",
    "        # On selectionne l'action et prédit l'outcome\n",
    "        if action_df.empty:\n",
    "            intended_action = ACTION1\n",
    "            intended_outcome = OUTCOME1\n",
    "        else:    \n",
    "            intended_action = action_df.loc[0, 'action']\n",
    "            # Trouve l'outcome le plus probable pour l'action sélectionnée\n",
    "            outcome_df = probability_df[probability_df['action'] == intended_action]\n",
    "            intended_outcome = outcome_df.loc[outcome_df['probability'].idxmax(), 'outcome']\n",
    "        # On construit l'intended interaction \n",
    "        return self._interactions[intended_action * BASE_ACTION + intended_outcome]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b3f5c-f48c-45ad-bf1d-4a703bac64af",
   "metadata": {},
   "source": [
    "# Testons l'agent dans Environment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8025780-7d39-442d-9600-b40641e6d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Empty DataFrame\n",
      "Columns: [action, expected_valence]\n",
      "Index: []\n",
      "Step 1 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Empty DataFrame\n",
      "Columns: [action, expected_valence]\n",
      "Index: []\n",
      "Step 2 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.752551         -0.752551\n",
      "1            1       0        1        1     0.247449          0.247449\n",
      "2            2       2        0       -1     0.478860         -0.478860\n",
      "3            3       2        1        1     0.521140          0.521140\n",
      "   action  expected_valence\n",
      "0       2          0.042280\n",
      "1       0         -0.505102\n",
      "Step 3 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.711909         -0.711909\n",
      "1            1       0        1        1     0.288091          0.288091\n",
      "2            2       2        0       -1     0.396886         -0.396886\n",
      "3            3       2        1        1     0.603114          0.603114\n",
      "   action  expected_valence\n",
      "0       2          0.206227\n",
      "1       0         -0.423817\n",
      "Step 4 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.532344         -0.532344\n",
      "1            1       0        1        1     0.467656          0.467656\n",
      "2            2       2        0       -1     0.473232         -0.473232\n",
      "3            3       2        1        1     0.526768          0.526768\n",
      "   action  expected_valence\n",
      "0       2          0.053536\n",
      "1       0         -0.064688\n",
      "Step 5 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.553306         -0.553306\n",
      "1            1       0        1        1     0.446694          0.446694\n",
      "2            2       2        0       -1     0.419777         -0.419777\n",
      "3            3       2        1        1     0.580223          0.580223\n",
      "   action  expected_valence\n",
      "0       2          0.160446\n",
      "1       0         -0.106612\n",
      "Step 6 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.612856         -0.612856\n",
      "1            1       0        1        1     0.387144          0.387144\n",
      "2            2       2        0       -1     0.293734         -0.293734\n",
      "3            3       2        1        1     0.706266          0.706266\n",
      "   action  expected_valence\n",
      "0       2          0.412533\n",
      "1       0         -0.225712\n",
      "Step 7 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.693639         -0.693639\n",
      "1            1       0        1        1     0.306361          0.306361\n",
      "2            2       2        0       -1     0.142115         -0.142115\n",
      "3            3       2        1        1     0.857885          0.857885\n",
      "   action  expected_valence\n",
      "0       2          0.715770\n",
      "1       0         -0.387278\n",
      "Step 8 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.756596         -0.756596\n",
      "1            1       0        1        1     0.243404          0.243404\n",
      "2            2       2        0       -1     0.047855         -0.047855\n",
      "3            3       2        1        1     0.952145          0.952145\n",
      "   action  expected_valence\n",
      "0       2          0.904289\n",
      "1       0         -0.513193\n",
      "Step 9 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.782508         -0.782508\n",
      "1            1       0        1        1     0.217492          0.217492\n",
      "2            2       2        0       -1     0.017167         -0.017167\n",
      "3            3       2        1        1     0.982833          0.982833\n",
      "   action  expected_valence\n",
      "0       2          0.965665\n",
      "1       0         -0.565017\n",
      "Step 10 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.785600         -0.785600\n",
      "1            1       0        1        1     0.214400          0.214400\n",
      "2            2       2        0       -1     0.008478         -0.008478\n",
      "3            3       2        1        1     0.991522          0.991522\n",
      "   action  expected_valence\n",
      "0       2          0.983045\n",
      "1       0         -0.571200\n",
      "Step 11 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.781291         -0.781291\n",
      "1            1       0        1        1     0.218709          0.218709\n",
      "2            2       2        0       -1     0.005360         -0.005360\n",
      "3            3       2        1        1     0.994640          0.994640\n",
      "   action  expected_valence\n",
      "0       2          0.989280\n",
      "1       0         -0.562582\n",
      "Step 12 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.775419         -0.775419\n",
      "1            1       0        1        1     0.224581          0.224581\n",
      "2            2       2        0       -1     0.003898         -0.003898\n",
      "3            3       2        1        1     0.996102          0.996102\n",
      "   action  expected_valence\n",
      "0       2          0.992203\n",
      "1       0         -0.550839\n",
      "Step 13 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.769546         -0.769546\n",
      "1            1       0        1        1     0.230454          0.230454\n",
      "2            2       2        0       -1     0.003071         -0.003071\n",
      "3            3       2        1        1     0.996929          0.996929\n",
      "   action  expected_valence\n",
      "0       2          0.993858\n",
      "1       0         -0.539092\n",
      "Step 14 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.764041         -0.764041\n",
      "1            1       0        1        1     0.235958          0.235958\n",
      "2            2       2        0       -1     0.002543         -0.002543\n",
      "3            3       2        1        1     0.997457          0.997457\n",
      "   action  expected_valence\n",
      "0       2          0.994915\n",
      "1       0         -0.528083\n",
      "Step 15 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.758967         -0.758967\n",
      "1            1       0        1        1     0.241033          0.241033\n",
      "2            2       2        0       -1     0.002178         -0.002178\n",
      "3            3       2        1        1     0.997822          0.997822\n",
      "   action  expected_valence\n",
      "0       2          0.995643\n",
      "1       0         -0.517934\n",
      "Step 16 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.754302         -0.754302\n",
      "1            1       0        1        1     0.245698          0.245698\n",
      "2            2       2        0       -1     0.001913         -0.001913\n",
      "3            3       2        1        1     0.998087          0.998087\n",
      "   action  expected_valence\n",
      "0       2          0.996174\n",
      "1       0         -0.508605\n",
      "Step 17 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.750007         -0.750007\n",
      "1            1       0        1        1     0.249993          0.249993\n",
      "2            2       2        0       -1     0.001711         -0.001711\n",
      "3            3       2        1        1     0.998289          0.998289\n",
      "   action  expected_valence\n",
      "0       2          0.996577\n",
      "1       0         -0.500013\n",
      "Step 18 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.746037         -0.746037\n",
      "1            1       0        1        1     0.253963          0.253963\n",
      "2            2       2        0       -1     0.001554         -0.001554\n",
      "3            3       2        1        1     0.998446          0.998446\n",
      "   action  expected_valence\n",
      "0       2          0.996893\n",
      "1       0         -0.492074\n",
      "Step 19 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.742354         -0.742354\n",
      "1            1       0        1        1     0.257646          0.257646\n",
      "2            2       2        0       -1     0.001427         -0.001427\n",
      "3            3       2        1        1     0.998573          0.998573\n",
      "   action  expected_valence\n",
      "0       2          0.997146\n",
      "1       0         -0.484708\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "a = Agent(interactions)\n",
    "e = Environment1()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    print(f\"Step {i} ----- \")\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02f401-3a78-4ced-9b8c-3b602c7be482",
   "metadata": {},
   "source": [
    "## Agent2 dans Environment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "925fb5f1-1eb6-4dee-a59b-fd6384e123d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Empty DataFrame\n",
      "Columns: [action, expected_valence]\n",
      "Index: []\n",
      "Step 1 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Empty DataFrame\n",
      "Columns: [action, expected_valence]\n",
      "Index: []\n",
      "Step 2 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.419614         -0.419614\n",
      "1            1       0        1        1     0.580386          0.580386\n",
      "2            2       2        0       -1     0.470455         -0.470455\n",
      "3            3       2        1        1     0.529545          0.529545\n",
      "   action  expected_valence\n",
      "0       0          0.160771\n",
      "1       2          0.059090\n",
      "Step 3 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.204618         -0.204618\n",
      "1            1       0        1        1     0.795382          0.795382\n",
      "2            2       2        0       -1     0.466163         -0.466163\n",
      "3            3       2        1        1     0.533837          0.533837\n",
      "   action  expected_valence\n",
      "0       0          0.590763\n",
      "1       2          0.067674\n",
      "Step 4 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.036622         -0.036622\n",
      "1            1       0        1        1     0.963378          0.963378\n",
      "2            2       2        0       -1     0.461194         -0.461194\n",
      "3            3       2        1        1     0.538805          0.538805\n",
      "   action  expected_valence\n",
      "0       0          0.926756\n",
      "1       2          0.077611\n",
      "Step 5 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.008786         -0.008786\n",
      "1            1       0        1        1     0.991214          0.991214\n",
      "2            2       2        0       -1     0.460643         -0.460643\n",
      "3            3       2        1        1     0.539357          0.539357\n",
      "   action  expected_valence\n",
      "0       0          0.982428\n",
      "1       2          0.078714\n",
      "Step 6 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.004448         -0.004448\n",
      "1            1       0        1        1     0.995552          0.995552\n",
      "2            2       2        0       -1     0.461451         -0.461451\n",
      "3            3       2        1        1     0.538549          0.538549\n",
      "   action  expected_valence\n",
      "0       0          0.991104\n",
      "1       2          0.077098\n",
      "Step 7 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.003054         -0.003054\n",
      "1            1       0        1        1     0.996946          0.996946\n",
      "2            2       2        0       -1     0.462359         -0.462359\n",
      "3            3       2        1        1     0.537641          0.537641\n",
      "   action  expected_valence\n",
      "0       0          0.993892\n",
      "1       2          0.075283\n",
      "Step 8 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.002337         -0.002337\n",
      "1            1       0        1        1     0.997663          0.997663\n",
      "2            2       2        0       -1     0.463272         -0.463272\n",
      "3            3       2        1        1     0.536727          0.536727\n",
      "   action  expected_valence\n",
      "0       0          0.995325\n",
      "1       2          0.073455\n",
      "Step 9 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001884         -0.001884\n",
      "1            1       0        1        1     0.998116          0.998116\n",
      "2            2       2        0       -1     0.464184         -0.464184\n",
      "3            3       2        1        1     0.535816          0.535816\n",
      "   action  expected_valence\n",
      "0       0          0.996233\n",
      "1       2          0.071633\n",
      "Step 10 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001568         -0.001568\n",
      "1            1       0        1        1     0.998432          0.998432\n",
      "2            2       2        0       -1     0.465076         -0.465076\n",
      "3            3       2        1        1     0.534924          0.534924\n",
      "   action  expected_valence\n",
      "0       0          0.996863\n",
      "1       2          0.069847\n",
      "Step 11 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001338         -0.001338\n",
      "1            1       0        1        1     0.998662          0.998662\n",
      "2            2       2        0       -1     0.465937         -0.465937\n",
      "3            3       2        1        1     0.534063          0.534063\n",
      "   action  expected_valence\n",
      "0       0          0.997324\n",
      "1       2          0.068126\n",
      "Step 12 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001163         -0.001163\n",
      "1            1       0        1        1     0.998837          0.998837\n",
      "2            2       2        0       -1     0.466755         -0.466755\n",
      "3            3       2        1        1     0.533245          0.533245\n",
      "   action  expected_valence\n",
      "0       0          0.997674\n",
      "1       2          0.066490\n",
      "Step 13 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001027         -0.001027\n",
      "1            1       0        1        1     0.998973          0.998973\n",
      "2            2       2        0       -1     0.467522         -0.467522\n",
      "3            3       2        1        1     0.532478          0.532478\n",
      "   action  expected_valence\n",
      "0       0          0.997946\n",
      "1       2          0.064955\n",
      "Step 14 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000919         -0.000919\n",
      "1            1       0        1        1     0.999081          0.999081\n",
      "2            2       2        0       -1     0.468235         -0.468235\n",
      "3            3       2        1        1     0.531765          0.531765\n",
      "   action  expected_valence\n",
      "0       0          0.998162\n",
      "1       2          0.063530\n",
      "Step 15 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000831         -0.000831\n",
      "1            1       0        1        1     0.999169          0.999169\n",
      "2            2       2        0       -1     0.468890         -0.468890\n",
      "3            3       2        1        1     0.531110          0.531110\n",
      "   action  expected_valence\n",
      "0       0          0.998338\n",
      "1       2          0.062219\n",
      "Step 16 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000758         -0.000758\n",
      "1            1       0        1        1     0.999242          0.999242\n",
      "2            2       2        0       -1     0.469490         -0.469490\n",
      "3            3       2        1        1     0.530510          0.530510\n",
      "   action  expected_valence\n",
      "0       0          0.998484\n",
      "1       2          0.061019\n",
      "Step 17 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000697         -0.000697\n",
      "1            1       0        1        1     0.999303          0.999303\n",
      "2            2       2        0       -1     0.470036         -0.470036\n",
      "3            3       2        1        1     0.529964          0.529964\n",
      "   action  expected_valence\n",
      "0       0          0.998605\n",
      "1       2          0.059928\n",
      "Step 18 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000646         -0.000646\n",
      "1            1       0        1        1     0.999354          0.999354\n",
      "2            2       2        0       -1     0.470533         -0.470533\n",
      "3            3       2        1        1     0.529467          0.529467\n",
      "   action  expected_valence\n",
      "0       0          0.998708\n",
      "1       2          0.058934\n",
      "Step 19 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000602         -0.000602\n",
      "1            1       0        1        1     0.999398          0.999398\n",
      "2            2       2        0       -1     0.470984         -0.470984\n",
      "3            3       2        1        1     0.529016          0.529016\n",
      "   action  expected_valence\n",
      "0       0          0.998797\n",
      "1       2          0.058033\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = Agent(interactions)\n",
    "e = Environment2()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    print(f\"Step {i} ----- \")\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ebe13-605e-4068-ab57-06416f898790",
   "metadata": {},
   "source": [
    "## Dans Environment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "835595f7-512e-46aa-b140-3e2b6c43eea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Empty DataFrame\n",
      "Columns: [action, expected_valence]\n",
      "Index: []\n",
      "Step 1 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Empty DataFrame\n",
      "Columns: [action, expected_valence]\n",
      "Index: []\n",
      "Step 2 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.752551         -0.752551\n",
      "1            1       0        1        1     0.247449          0.247449\n",
      "2            2       2        0       -1     0.478860         -0.478860\n",
      "3            3       2        1        1     0.521140          0.521140\n",
      "   action  expected_valence\n",
      "0       2          0.042280\n",
      "1       0         -0.505102\n",
      "Step 3 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.711909         -0.711909\n",
      "1            1       0        1        1     0.288091          0.288091\n",
      "2            2       2        0       -1     0.396886         -0.396886\n",
      "3            3       2        1        1     0.603114          0.603114\n",
      "   action  expected_valence\n",
      "0       2          0.206227\n",
      "1       0         -0.423817\n",
      "Step 4 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.633283         -0.633283\n",
      "1            1       0        1        1     0.366717          0.366717\n",
      "2            2       2        0       -1     0.441537         -0.441537\n",
      "3            3       2        1        1     0.558463          0.558463\n",
      "   action  expected_valence\n",
      "0       2          0.116926\n",
      "1       0         -0.266566\n",
      "Step 5 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.717330         -0.717330\n",
      "1            1       0        1        1     0.282670          0.282670\n",
      "2            2       2        0       -1     0.436269         -0.436269\n",
      "3            3       2        1        1     0.563731          0.563731\n",
      "   action  expected_valence\n",
      "0       2          0.127462\n",
      "1       0         -0.434661\n",
      "Step 6 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.701382         -0.701382\n",
      "1            1       0        1        1     0.298618          0.298618\n",
      "2            2       2        0       -1     0.580636         -0.580636\n",
      "3            3       2        1        1     0.419364          0.419364\n",
      "   action  expected_valence\n",
      "0       2         -0.161271\n",
      "1       0         -0.402765\n",
      "Step 7 ----- \n",
      "Action: 2, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.700974         -0.700974\n",
      "1            1       0        1        1     0.299026          0.299026\n",
      "2            2       2        0       -1     0.814103         -0.814103\n",
      "3            3       2        1        1     0.185897          0.185897\n",
      "   action  expected_valence\n",
      "0       0         -0.401948\n",
      "1       2         -0.628206\n",
      "Step 8 ----- \n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.477910         -0.477910\n",
      "1            1       0        1        1     0.522090          0.522090\n",
      "2            2       2        0       -1     0.817363         -0.817363\n",
      "3            3       2        1        1     0.182637          0.182637\n",
      "   action  expected_valence\n",
      "0       0          0.044179\n",
      "1       2         -0.634726\n",
      "Step 9 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.935693         -0.935693\n",
      "1            1       0        1        1     0.064307          0.064307\n",
      "2            2       2        0       -1     0.180874         -0.180874\n",
      "3            3       2        1        1     0.819126          0.819126\n",
      "   action  expected_valence\n",
      "0       2          0.638252\n",
      "1       0         -0.871385\n",
      "Step 10 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.469071         -0.469071\n",
      "1            1       0        1        1     0.530929          0.530929\n",
      "2            2       2        0       -1     0.963314         -0.963314\n",
      "3            3       2        1        1     0.036686          0.036686\n",
      "   action  expected_valence\n",
      "0       0          0.061858\n",
      "1       2         -0.926629\n",
      "Step 11 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.498759         -0.498759\n",
      "1            1       0        1        1     0.501241          0.501241\n",
      "2            2       2        0       -1     0.720327         -0.720327\n",
      "3            3       2        1        1     0.279673          0.279673\n",
      "   action  expected_valence\n",
      "0       0          0.002482\n",
      "1       2         -0.440654\n",
      "Step 12 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.973982         -0.973982\n",
      "1            1       0        1        1     0.026018          0.026018\n",
      "2            2       2        0       -1     0.028566         -0.028566\n",
      "3            3       2        1        1     0.971434          0.971434\n",
      "   action  expected_valence\n",
      "0       2          0.942867\n",
      "1       0         -0.947964\n",
      "Step 13 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.051580         -0.051580\n",
      "1            1       0        1        1     0.948420          0.948420\n",
      "2            2       2        0       -1     0.978158         -0.978158\n",
      "3            3       2        1        1     0.021842          0.021842\n",
      "   action  expected_valence\n",
      "0       0          0.896840\n",
      "1       2         -0.956317\n",
      "Step 14 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.899382         -0.899382\n",
      "1            1       0        1        1     0.100619          0.100619\n",
      "2            2       2        0       -1     0.409350         -0.409350\n",
      "3            3       2        1        1     0.590650          0.590650\n",
      "   action  expected_valence\n",
      "0       2          0.181301\n",
      "1       0         -0.798763\n",
      "Step 15 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.156068         -0.156068\n",
      "1            1       0        1        1     0.843932          0.843932\n",
      "2            2       2        0       -1     0.940151         -0.940151\n",
      "3            3       2        1        1     0.059849          0.059849\n",
      "   action  expected_valence\n",
      "0       0          0.687864\n",
      "1       2         -0.880301\n",
      "Step 16 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1      0.96531          -0.96531\n",
      "1            1       0        1        1      0.03469           0.03469\n",
      "2            2       2        0       -1      0.08809          -0.08809\n",
      "3            3       2        1        1      0.91191           0.91191\n",
      "   action  expected_valence\n",
      "0       2          0.823821\n",
      "1       0         -0.930620\n",
      "Step 17 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.059470         -0.059470\n",
      "1            1       0        1        1     0.940530          0.940530\n",
      "2            2       2        0       -1     0.950729         -0.950729\n",
      "3            3       2        1        1     0.049271          0.049271\n",
      "   action  expected_valence\n",
      "0       0          0.881060\n",
      "1       2         -0.901458\n",
      "Step 18 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.982082         -0.982082\n",
      "1            1       0        1        1     0.017918          0.017918\n",
      "2            2       2        0       -1     0.040221         -0.040221\n",
      "3            3       2        1        1     0.959779          0.959779\n",
      "   action  expected_valence\n",
      "0       2          0.919558\n",
      "1       0         -0.964164\n",
      "Step 19 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.028042         -0.028042\n",
      "1            1       0        1        1     0.971958          0.971958\n",
      "2            2       2        0       -1     0.951428         -0.951428\n",
      "3            3       2        1        1     0.048572          0.048572\n",
      "   action  expected_valence\n",
      "0       0          0.943916\n",
      "1       2         -0.902857\n",
      "Step 20 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.989959         -0.989959\n",
      "1            1       0        1        1     0.010041          0.010041\n",
      "2            2       2        0       -1     0.024335         -0.024335\n",
      "3            3       2        1        1     0.975665          0.975665\n",
      "   action  expected_valence\n",
      "0       2          0.951330\n",
      "1       0         -0.979919\n",
      "Step 21 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.014219         -0.014219\n",
      "1            1       0        1        1     0.985781          0.985781\n",
      "2            2       2        0       -1     0.922326         -0.922326\n",
      "3            3       2        1        1     0.077674          0.077674\n",
      "   action  expected_valence\n",
      "0       0          0.971562\n",
      "1       2         -0.844651\n",
      "Step 22 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.993844         -0.993844\n",
      "1            1       0        1        1     0.006156          0.006156\n",
      "2            2       2        0       -1     0.017664         -0.017664\n",
      "3            3       2        1        1     0.982336          0.982336\n",
      "   action  expected_valence\n",
      "0       2          0.964673\n",
      "1       0         -0.987689\n",
      "Step 23 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.007501         -0.007501\n",
      "1            1       0        1        1     0.992499          0.992499\n",
      "2            2       2        0       -1     0.882684         -0.882684\n",
      "3            3       2        1        1     0.117316          0.117316\n",
      "   action  expected_valence\n",
      "0       0          0.984998\n",
      "1       2         -0.765368\n",
      "Step 24 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.995818         -0.995818\n",
      "1            1       0        1        1     0.004182          0.004182\n",
      "2            2       2        0       -1     0.013832         -0.013832\n",
      "3            3       2        1        1     0.986168          0.986168\n",
      "   action  expected_valence\n",
      "0       2          0.972336\n",
      "1       0         -0.991636\n",
      "Step 25 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.004621         -0.004621\n",
      "1            1       0        1        1     0.995379          0.995379\n",
      "2            2       2        0       -1     0.852283         -0.852283\n",
      "3            3       2        1        1     0.147717          0.147717\n",
      "   action  expected_valence\n",
      "0       0          0.990759\n",
      "1       2         -0.704566\n",
      "Step 26 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.996932         -0.996932\n",
      "1            1       0        1        1     0.003068          0.003068\n",
      "2            2       2        0       -1     0.011224         -0.011224\n",
      "3            3       2        1        1     0.988776          0.988776\n",
      "   action  expected_valence\n",
      "0       2          0.977551\n",
      "1       0         -0.993865\n",
      "Step 27 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.003245         -0.003245\n",
      "1            1       0        1        1     0.996755          0.996755\n",
      "2            2       2        0       -1     0.830706         -0.830706\n",
      "3            3       2        1        1     0.169294          0.169294\n",
      "   action  expected_valence\n",
      "0       0          0.993510\n",
      "1       2         -0.661413\n",
      "Step 28 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.997619         -0.997619\n",
      "1            1       0        1        1     0.002381          0.002381\n",
      "2            2       2        0       -1     0.009356         -0.009356\n",
      "3            3       2        1        1     0.990644          0.990644\n",
      "   action  expected_valence\n",
      "0       2          0.981288\n",
      "1       0         -0.995238\n",
      "Step 29 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.002482         -0.002482\n",
      "1            1       0        1        1     0.997518          0.997518\n",
      "2            2       2        0       -1     0.814603         -0.814603\n",
      "3            3       2        1        1     0.185397          0.185397\n",
      "   action  expected_valence\n",
      "0       0          0.995035\n",
      "1       2         -0.629206\n",
      "Step 30 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.998072         -0.998072\n",
      "1            1       0        1        1     0.001928          0.001928\n",
      "2            2       2        0       -1     0.007982         -0.007982\n",
      "3            3       2        1        1     0.992018          0.992018\n",
      "   action  expected_valence\n",
      "0       2          0.984035\n",
      "1       0         -0.996143\n",
      "Step 31 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1      0.00201          -0.00201\n",
      "1            1       0        1        1      0.99799           0.99799\n",
      "2            2       2        0       -1      0.80185          -0.80185\n",
      "3            3       2        1        1      0.19815           0.19815\n",
      "   action  expected_valence\n",
      "0       0          0.995980\n",
      "1       2         -0.603699\n",
      "Step 32 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.998386         -0.998386\n",
      "1            1       0        1        1     0.001614          0.001614\n",
      "2            2       2        0       -1     0.006947         -0.006947\n",
      "3            3       2        1        1     0.993053          0.993053\n",
      "   action  expected_valence\n",
      "0       2          0.986106\n",
      "1       0         -0.996773\n",
      "Step 33 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001693         -0.001693\n",
      "1            1       0        1        1     0.998307          0.998307\n",
      "2            2       2        0       -1     0.791249         -0.791249\n",
      "3            3       2        1        1     0.208751          0.208751\n",
      "   action  expected_valence\n",
      "0       0          0.996614\n",
      "1       2         -0.582499\n",
      "Step 34 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.998614         -0.998614\n",
      "1            1       0        1        1     0.001386          0.001386\n",
      "2            2       2        0       -1     0.006148         -0.006148\n",
      "3            3       2        1        1     0.993852          0.993852\n",
      "   action  expected_valence\n",
      "0       2          0.987704\n",
      "1       0         -0.997229\n",
      "Step 35 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001466         -0.001466\n",
      "1            1       0        1        1     0.998534          0.998534\n",
      "2            2       2        0       -1     0.782113         -0.782113\n",
      "3            3       2        1        1     0.217887          0.217887\n",
      "   action  expected_valence\n",
      "0       0          0.997067\n",
      "1       2         -0.564226\n",
      "Step 36 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.998786         -0.998786\n",
      "1            1       0        1        1     0.001214          0.001214\n",
      "2            2       2        0       -1     0.005518         -0.005518\n",
      "3            3       2        1        1     0.994482          0.994482\n",
      "   action  expected_valence\n",
      "0       2          0.988964\n",
      "1       0         -0.997571\n",
      "Step 37 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001297         -0.001297\n",
      "1            1       0        1        1     0.998703          0.998703\n",
      "2            2       2        0       -1     0.774031         -0.774031\n",
      "3            3       2        1        1     0.225969          0.225969\n",
      "   action  expected_valence\n",
      "0       0          0.997406\n",
      "1       2         -0.548062\n",
      "Step 38 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.998918         -0.998918\n",
      "1            1       0        1        1     0.001082          0.001082\n",
      "2            2       2        0       -1     0.005011         -0.005011\n",
      "3            3       2        1        1     0.994989          0.994989\n",
      "   action  expected_valence\n",
      "0       2          0.989978\n",
      "1       0         -0.997836\n",
      "Step 39 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001165         -0.001165\n",
      "1            1       0        1        1     0.998835          0.998835\n",
      "2            2       2        0       -1     0.766750         -0.766750\n",
      "3            3       2        1        1     0.233250          0.233250\n",
      "   action  expected_valence\n",
      "0       0           0.99767\n",
      "1       2          -0.53350\n",
      "Step 40 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999023         -0.999023\n",
      "1            1       0        1        1     0.000977          0.000977\n",
      "2            2       2        0       -1     0.004596         -0.004596\n",
      "3            3       2        1        1     0.995404          0.995404\n",
      "   action  expected_valence\n",
      "0       2          0.990809\n",
      "1       0         -0.998045\n",
      "Step 41 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.001059         -0.001059\n",
      "1            1       0        1        1     0.998941          0.998941\n",
      "2            2       2        0       -1     0.760108         -0.760108\n",
      "3            3       2        1        1     0.239892          0.239892\n",
      "   action  expected_valence\n",
      "0       0          0.997881\n",
      "1       2         -0.520216\n",
      "Step 42 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999108         -0.999108\n",
      "1            1       0        1        1     0.000892          0.000892\n",
      "2            2       2        0       -1     0.004250         -0.004250\n",
      "3            3       2        1        1     0.995750          0.995750\n",
      "   action  expected_valence\n",
      "0       2          0.991500\n",
      "1       0         -0.998215\n",
      "Step 43 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000972         -0.000972\n",
      "1            1       0        1        1     0.999028          0.999028\n",
      "2            2       2        0       -1     0.753998         -0.753998\n",
      "3            3       2        1        1     0.246002          0.246002\n",
      "   action  expected_valence\n",
      "0       0          0.998056\n",
      "1       2         -0.507995\n",
      "Step 44 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999177         -0.999177\n",
      "1            1       0        1        1     0.000823          0.000823\n",
      "2            2       2        0       -1     0.003958         -0.003958\n",
      "3            3       2        1        1     0.996042          0.996042\n",
      "   action  expected_valence\n",
      "0       2          0.992085\n",
      "1       0         -0.998355\n",
      "Step 45 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000899         -0.000899\n",
      "1            1       0        1        1     0.999101          0.999101\n",
      "2            2       2        0       -1     0.748344         -0.748344\n",
      "3            3       2        1        1     0.251656          0.251656\n",
      "   action  expected_valence\n",
      "0       0          0.998202\n",
      "1       2         -0.496689\n",
      "Step 46 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999236         -0.999236\n",
      "1            1       0        1        1     0.000764          0.000764\n",
      "2            2       2        0       -1     0.003707         -0.003707\n",
      "3            3       2        1        1     0.996293          0.996293\n",
      "   action  expected_valence\n",
      "0       2          0.992586\n",
      "1       0         -0.998472\n",
      "Step 47 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000836         -0.000836\n",
      "1            1       0        1        1     0.999164          0.999164\n",
      "2            2       2        0       -1     0.743097         -0.743097\n",
      "3            3       2        1        1     0.256903          0.256903\n",
      "   action  expected_valence\n",
      "0       0          0.998327\n",
      "1       2         -0.486194\n",
      "Step 48 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999286         -0.999286\n",
      "1            1       0        1        1     0.000714          0.000714\n",
      "2            2       2        0       -1     0.003490         -0.003490\n",
      "3            3       2        1        1     0.996510          0.996510\n",
      "   action  expected_valence\n",
      "0       2          0.993021\n",
      "1       0         -0.998572\n",
      "Step 49 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000782         -0.000782\n",
      "1            1       0        1        1     0.999218          0.999218\n",
      "2            2       2        0       -1     0.738216         -0.738216\n",
      "3            3       2        1        1     0.261784          0.261784\n",
      "   action  expected_valence\n",
      "0       0          0.998436\n",
      "1       2         -0.476433\n",
      "Step 50 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999329         -0.999329\n",
      "1            1       0        1        1     0.000671          0.000671\n",
      "2            2       2        0       -1     0.003299         -0.003299\n",
      "3            3       2        1        1     0.996701          0.996701\n",
      "   action  expected_valence\n",
      "0       2          0.993402\n",
      "1       0         -0.998657\n",
      "Step 51 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000734         -0.000734\n",
      "1            1       0        1        1     0.999266          0.999266\n",
      "2            2       2        0       -1     0.733672         -0.733672\n",
      "3            3       2        1        1     0.266328          0.266328\n",
      "   action  expected_valence\n",
      "0       0          0.998532\n",
      "1       2         -0.467345\n",
      "Step 52 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999366         -0.999366\n",
      "1            1       0        1        1     0.000634          0.000634\n",
      "2            2       2        0       -1     0.003129         -0.003129\n",
      "3            3       2        1        1     0.996871          0.996871\n",
      "   action  expected_valence\n",
      "0       2          0.993741\n",
      "1       0         -0.998732\n",
      "Step 53 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000692         -0.000692\n",
      "1            1       0        1        1     0.999308          0.999308\n",
      "2            2       2        0       -1     0.729439         -0.729439\n",
      "3            3       2        1        1     0.270561          0.270561\n",
      "   action  expected_valence\n",
      "0       0          0.998616\n",
      "1       2         -0.458879\n",
      "Step 54 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999399         -0.999399\n",
      "1            1       0        1        1     0.000601          0.000601\n",
      "2            2       2        0       -1     0.002977         -0.002977\n",
      "3            3       2        1        1     0.997023          0.997023\n",
      "   action  expected_valence\n",
      "0       2          0.994045\n",
      "1       0         -0.998798\n",
      "Step 55 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000654         -0.000654\n",
      "1            1       0        1        1     0.999346          0.999346\n",
      "2            2       2        0       -1     0.725495         -0.725495\n",
      "3            3       2        1        1     0.274505          0.274505\n",
      "   action  expected_valence\n",
      "0       0          0.998692\n",
      "1       2         -0.450989\n",
      "Step 56 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999428         -0.999428\n",
      "1            1       0        1        1     0.000572          0.000572\n",
      "2            2       2        0       -1     0.002840         -0.002840\n",
      "3            3       2        1        1     0.997160          0.997160\n",
      "   action  expected_valence\n",
      "0       2          0.994320\n",
      "1       0         -0.998857\n",
      "Step 57 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000620         -0.000620\n",
      "1            1       0        1        1     0.999380          0.999380\n",
      "2            2       2        0       -1     0.721816         -0.721816\n",
      "3            3       2        1        1     0.278184          0.278184\n",
      "   action  expected_valence\n",
      "0       0          0.998761\n",
      "1       2         -0.443632\n",
      "Step 58 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999455         -0.999455\n",
      "1            1       0        1        1     0.000545          0.000545\n",
      "2            2       2        0       -1     0.002715         -0.002715\n",
      "3            3       2        1        1     0.997285          0.997285\n",
      "   action  expected_valence\n",
      "0       2           0.99457\n",
      "1       0          -0.99891\n",
      "Step 59 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000589         -0.000589\n",
      "1            1       0        1        1     0.999411          0.999411\n",
      "2            2       2        0       -1     0.718382         -0.718382\n",
      "3            3       2        1        1     0.281618          0.281618\n",
      "   action  expected_valence\n",
      "0       0          0.998822\n",
      "1       2         -0.436763\n",
      "Step 60 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999479         -0.999479\n",
      "1            1       0        1        1     0.000521          0.000521\n",
      "2            2       2        0       -1     0.002600         -0.002600\n",
      "3            3       2        1        1     0.997400          0.997400\n",
      "   action  expected_valence\n",
      "0       2          0.994801\n",
      "1       0         -0.998957\n",
      "Step 61 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000561         -0.000561\n",
      "1            1       0        1        1     0.999439          0.999439\n",
      "2            2       2        0       -1     0.715170         -0.715170\n",
      "3            3       2        1        1     0.284830          0.284830\n",
      "   action  expected_valence\n",
      "0       0          0.998879\n",
      "1       2         -0.430340\n",
      "Step 62 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999500         -0.999500\n",
      "1            1       0        1        1     0.000500          0.000500\n",
      "2            2       2        0       -1     0.002493         -0.002493\n",
      "3            3       2        1        1     0.997507          0.997507\n",
      "   action  expected_valence\n",
      "0       2          0.995013\n",
      "1       0         -0.999001\n",
      "Step 63 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000535         -0.000535\n",
      "1            1       0        1        1     0.999465          0.999465\n",
      "2            2       2        0       -1     0.712160         -0.712160\n",
      "3            3       2        1        1     0.287840          0.287840\n",
      "   action  expected_valence\n",
      "0       0          0.998930\n",
      "1       2         -0.424321\n",
      "Step 64 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999520         -0.999520\n",
      "1            1       0        1        1     0.000480          0.000480\n",
      "2            2       2        0       -1     0.002395         -0.002395\n",
      "3            3       2        1        1     0.997605          0.997605\n",
      "   action  expected_valence\n",
      "0       2          0.995211\n",
      "1       0         -0.999040\n",
      "Step 65 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000511         -0.000511\n",
      "1            1       0        1        1     0.999489          0.999489\n",
      "2            2       2        0       -1     0.709331         -0.709331\n",
      "3            3       2        1        1     0.290669          0.290669\n",
      "   action  expected_valence\n",
      "0       0          0.998977\n",
      "1       2         -0.418662\n",
      "Step 66 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999538         -0.999538\n",
      "1            1       0        1        1     0.000462          0.000462\n",
      "2            2       2        0       -1     0.002303         -0.002303\n",
      "3            3       2        1        1     0.997698          0.997698\n",
      "   action  expected_valence\n",
      "0       2          0.995395\n",
      "1       0         -0.999077\n",
      "Step 67 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000490         -0.000490\n",
      "1            1       0        1        1     0.999510          0.999510\n",
      "2            2       2        0       -1     0.706661         -0.706661\n",
      "3            3       2        1        1     0.293339          0.293339\n",
      "   action  expected_valence\n",
      "0       0          0.999021\n",
      "1       2         -0.413322\n",
      "Step 68 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999555         -0.999555\n",
      "1            1       0        1        1     0.000445          0.000445\n",
      "2            2       2        0       -1     0.002216         -0.002216\n",
      "3            3       2        1        1     0.997784          0.997784\n",
      "   action  expected_valence\n",
      "0       2          0.995568\n",
      "1       0         -0.999110\n",
      "Step 69 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1      0.00047          -0.00047\n",
      "1            1       0        1        1      0.99953           0.99953\n",
      "2            2       2        0       -1      0.70413          -0.70413\n",
      "3            3       2        1        1      0.29587           0.29587\n",
      "   action  expected_valence\n",
      "0       0          0.999061\n",
      "1       2         -0.408260\n",
      "Step 70 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999571         -0.999571\n",
      "1            1       0        1        1     0.000429          0.000429\n",
      "2            2       2        0       -1     0.002135         -0.002135\n",
      "3            3       2        1        1     0.997865          0.997865\n",
      "   action  expected_valence\n",
      "0       2          0.995730\n",
      "1       0         -0.999142\n",
      "Step 71 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000451         -0.000451\n",
      "1            1       0        1        1     0.999549          0.999549\n",
      "2            2       2        0       -1     0.701719         -0.701719\n",
      "3            3       2        1        1     0.298281          0.298281\n",
      "   action  expected_valence\n",
      "0       0          0.999098\n",
      "1       2         -0.403439\n",
      "Step 72 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999585         -0.999585\n",
      "1            1       0        1        1     0.000415          0.000415\n",
      "2            2       2        0       -1     0.002058         -0.002058\n",
      "3            3       2        1        1     0.997942          0.997942\n",
      "   action  expected_valence\n",
      "0       2          0.995883\n",
      "1       0         -0.999170\n",
      "Step 73 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000434         -0.000434\n",
      "1            1       0        1        1     0.999566          0.999566\n",
      "2            2       2        0       -1     0.699410         -0.699410\n",
      "3            3       2        1        1     0.300590          0.300590\n",
      "   action  expected_valence\n",
      "0       0          0.999132\n",
      "1       2         -0.398820\n",
      "Step 74 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999599         -0.999599\n",
      "1            1       0        1        1     0.000401          0.000401\n",
      "2            2       2        0       -1     0.001986         -0.001986\n",
      "3            3       2        1        1     0.998014          0.998014\n",
      "   action  expected_valence\n",
      "0       2          0.996028\n",
      "1       0         -0.999197\n",
      "Step 75 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000418         -0.000418\n",
      "1            1       0        1        1     0.999582          0.999582\n",
      "2            2       2        0       -1     0.697186         -0.697186\n",
      "3            3       2        1        1     0.302814          0.302814\n",
      "   action  expected_valence\n",
      "0       0          0.999164\n",
      "1       2         -0.394373\n",
      "Step 76 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999611         -0.999611\n",
      "1            1       0        1        1     0.000389          0.000389\n",
      "2            2       2        0       -1     0.001918         -0.001918\n",
      "3            3       2        1        1     0.998083          0.998083\n",
      "   action  expected_valence\n",
      "0       2          0.996165\n",
      "1       0         -0.999222\n",
      "Step 77 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000403         -0.000403\n",
      "1            1       0        1        1     0.999597          0.999597\n",
      "2            2       2        0       -1     0.695033         -0.695033\n",
      "3            3       2        1        1     0.304967          0.304967\n",
      "   action  expected_valence\n",
      "0       0          0.999194\n",
      "1       2         -0.390067\n",
      "Step 78 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999623         -0.999623\n",
      "1            1       0        1        1     0.000377          0.000377\n",
      "2            2       2        0       -1     0.001853         -0.001853\n",
      "3            3       2        1        1     0.998147          0.998147\n",
      "   action  expected_valence\n",
      "0       2          0.996295\n",
      "1       0         -0.999246\n",
      "Step 79 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000389         -0.000389\n",
      "1            1       0        1        1     0.999611          0.999611\n",
      "2            2       2        0       -1     0.692937         -0.692937\n",
      "3            3       2        1        1     0.307063          0.307063\n",
      "   action  expected_valence\n",
      "0       0          0.999222\n",
      "1       2         -0.385875\n",
      "Step 80 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999634         -0.999634\n",
      "1            1       0        1        1     0.000366          0.000366\n",
      "2            2       2        0       -1     0.001791         -0.001791\n",
      "3            3       2        1        1     0.998209          0.998209\n",
      "   action  expected_valence\n",
      "0       2          0.996418\n",
      "1       0         -0.999268\n",
      "Step 81 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000376         -0.000376\n",
      "1            1       0        1        1     0.999624          0.999624\n",
      "2            2       2        0       -1     0.690889         -0.690889\n",
      "3            3       2        1        1     0.309111          0.309111\n",
      "   action  expected_valence\n",
      "0       0          0.999248\n",
      "1       2         -0.381777\n",
      "Step 82 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999644         -0.999644\n",
      "1            1       0        1        1     0.000356          0.000356\n",
      "2            2       2        0       -1     0.001732         -0.001732\n",
      "3            3       2        1        1     0.998268          0.998268\n",
      "   action  expected_valence\n",
      "0       2          0.996536\n",
      "1       0         -0.999288\n",
      "Step 83 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000364         -0.000364\n",
      "1            1       0        1        1     0.999636          0.999636\n",
      "2            2       2        0       -1     0.688880         -0.688880\n",
      "3            3       2        1        1     0.311120          0.311120\n",
      "   action  expected_valence\n",
      "0       0          0.999272\n",
      "1       2         -0.377760\n",
      "Step 84 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999654         -0.999654\n",
      "1            1       0        1        1     0.000346          0.000346\n",
      "2            2       2        0       -1     0.001676         -0.001676\n",
      "3            3       2        1        1     0.998324          0.998324\n",
      "   action  expected_valence\n",
      "0       2          0.996647\n",
      "1       0         -0.999307\n",
      "Step 85 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000353         -0.000353\n",
      "1            1       0        1        1     0.999647          0.999647\n",
      "2            2       2        0       -1     0.686905         -0.686905\n",
      "3            3       2        1        1     0.313095          0.313095\n",
      "   action  expected_valence\n",
      "0       0          0.999295\n",
      "1       2         -0.373810\n",
      "Step 86 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999663         -0.999663\n",
      "1            1       0        1        1     0.000337          0.000337\n",
      "2            2       2        0       -1     0.001623         -0.001623\n",
      "3            3       2        1        1     0.998377          0.998377\n",
      "   action  expected_valence\n",
      "0       2          0.996753\n",
      "1       0         -0.999325\n",
      "Step 87 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000342         -0.000342\n",
      "1            1       0        1        1     0.999658          0.999658\n",
      "2            2       2        0       -1     0.684964         -0.684964\n",
      "3            3       2        1        1     0.315036          0.315036\n",
      "   action  expected_valence\n",
      "0       0          0.999316\n",
      "1       2         -0.369929\n",
      "Step 88 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999671         -0.999671\n",
      "1            1       0        1        1     0.000329          0.000329\n",
      "2            2       2        0       -1     0.001573         -0.001573\n",
      "3            3       2        1        1     0.998427          0.998427\n",
      "   action  expected_valence\n",
      "0       2          0.996855\n",
      "1       0         -0.999342\n",
      "Step 89 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000332         -0.000332\n",
      "1            1       0        1        1     0.999668          0.999668\n",
      "2            2       2        0       -1     0.683062         -0.683062\n",
      "3            3       2        1        1     0.316938          0.316938\n",
      "   action  expected_valence\n",
      "0       0          0.999336\n",
      "1       2         -0.366123\n",
      "Step 90 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999679         -0.999679\n",
      "1            1       0        1        1     0.000321          0.000321\n",
      "2            2       2        0       -1     0.001524         -0.001524\n",
      "3            3       2        1        1     0.998476          0.998476\n",
      "   action  expected_valence\n",
      "0       2          0.996951\n",
      "1       0         -0.999358\n",
      "Step 91 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000323         -0.000323\n",
      "1            1       0        1        1     0.999677          0.999677\n",
      "2            2       2        0       -1     0.681207         -0.681207\n",
      "3            3       2        1        1     0.318793          0.318793\n",
      "   action  expected_valence\n",
      "0       0          0.999355\n",
      "1       2         -0.362414\n",
      "Step 92 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999686         -0.999686\n",
      "1            1       0        1        1     0.000314          0.000314\n",
      "2            2       2        0       -1     0.001478         -0.001478\n",
      "3            3       2        1        1     0.998522          0.998522\n",
      "   action  expected_valence\n",
      "0       2          0.997043\n",
      "1       0         -0.999372\n",
      "Step 93 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000314         -0.000314\n",
      "1            1       0        1        1     0.999686          0.999686\n",
      "2            2       2        0       -1     0.679413         -0.679413\n",
      "3            3       2        1        1     0.320587          0.320587\n",
      "   action  expected_valence\n",
      "0       0          0.999373\n",
      "1       2         -0.358826\n",
      "Step 94 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999693         -0.999693\n",
      "1            1       0        1        1     0.000307          0.000307\n",
      "2            2       2        0       -1     0.001434         -0.001434\n",
      "3            3       2        1        1     0.998566          0.998566\n",
      "   action  expected_valence\n",
      "0       2          0.997131\n",
      "1       0         -0.999387\n",
      "Step 95 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000305         -0.000305\n",
      "1            1       0        1        1     0.999695          0.999695\n",
      "2            2       2        0       -1     0.677697         -0.677697\n",
      "3            3       2        1        1     0.322303          0.322303\n",
      "   action  expected_valence\n",
      "0       0          0.999389\n",
      "1       2         -0.355395\n",
      "Step 96 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999700         -0.999700\n",
      "1            1       0        1        1     0.000300          0.000300\n",
      "2            2       2        0       -1     0.001392         -0.001392\n",
      "3            3       2        1        1     0.998608          0.998608\n",
      "   action  expected_valence\n",
      "0       2          0.997215\n",
      "1       0         -0.999400\n",
      "Step 97 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000297         -0.000297\n",
      "1            1       0        1        1     0.999703          0.999703\n",
      "2            2       2        0       -1     0.676076         -0.676076\n",
      "3            3       2        1        1     0.323924          0.323924\n",
      "   action  expected_valence\n",
      "0       0          0.999405\n",
      "1       2         -0.352152\n",
      "Step 98 ----- \n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.999706         -0.999706\n",
      "1            1       0        1        1     0.000294          0.000294\n",
      "2            2       2        0       -1     0.001352         -0.001352\n",
      "3            3       2        1        1     0.998648          0.998648\n",
      "   action  expected_valence\n",
      "0       2          0.997295\n",
      "1       0         -0.999412\n",
      "Step 99 ----- \n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.000290         -0.000290\n",
      "1            1       0        1        1     0.999710          0.999710\n",
      "2            2       2        0       -1     0.674563         -0.674563\n",
      "3            3       2        1        1     0.325437          0.325437\n",
      "   action  expected_valence\n",
      "0       0          0.999420\n",
      "1       2         -0.349126\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = Agent(interactions)\n",
    "e = Environment3()\n",
    "outcome = 0\n",
    "for i in range(100):\n",
    "    print(f\"Step {i} ----- \")\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afffde6f-fbc0-46f1-a375-eefadc001a3e",
   "metadata": {},
   "source": [
    "L'agent apprend à alterner les action à partir du pas 11 et fait une prédiction correct à partir du pas 14."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc2539-8682-4ad2-9840-e5a4a51c0630",
   "metadata": {},
   "source": [
    "## Agent5 dans Environment4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01bb0749-f161-464e-b8dc-255b7b098045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Empty DataFrame\n",
      "Columns: [action, expected_valence]\n",
      "Index: []\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Empty DataFrame\n",
      "Columns: [action, expected_valence]\n",
      "Index: []\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.752551         -0.752551\n",
      "1            1       0        1        1     0.247449          0.247449\n",
      "2            2       2        0       -1     0.478860         -0.478860\n",
      "3            3       2        1        1     0.521140          0.521140\n",
      "   action  expected_valence\n",
      "0       2          0.042280\n",
      "1       0         -0.505102\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.711909         -0.711909\n",
      "1            1       0        1        1     0.288091          0.288091\n",
      "2            2       2        0       -1     0.396886         -0.396886\n",
      "3            3       2        1        1     0.603114          0.603114\n",
      "   action  expected_valence\n",
      "0       2          0.206227\n",
      "1       0         -0.423817\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.532344         -0.532344\n",
      "1            1       0        1        1     0.467656          0.467656\n",
      "2            2       2        0       -1     0.473232         -0.473232\n",
      "3            3       2        1        1     0.526768          0.526768\n",
      "   action  expected_valence\n",
      "0       2          0.053536\n",
      "1       0         -0.064688\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.553306         -0.553306\n",
      "1            1       0        1        1     0.446694          0.446694\n",
      "2            2       2        0       -1     0.419777         -0.419777\n",
      "3            3       2        1        1     0.580223          0.580223\n",
      "   action  expected_valence\n",
      "0       2          0.160446\n",
      "1       0         -0.106612\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.612856         -0.612856\n",
      "1            1       0        1        1     0.387144          0.387144\n",
      "2            2       2        0       -1     0.293734         -0.293734\n",
      "3            3       2        1        1     0.706266          0.706266\n",
      "   action  expected_valence\n",
      "0       2          0.412533\n",
      "1       0         -0.225712\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.693639         -0.693639\n",
      "1            1       0        1        1     0.306361          0.306361\n",
      "2            2       2        0       -1     0.142115         -0.142115\n",
      "3            3       2        1        1     0.857885          0.857885\n",
      "   action  expected_valence\n",
      "0       2          0.715770\n",
      "1       0         -0.387278\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.756596         -0.756596\n",
      "1            1       0        1        1     0.243404          0.243404\n",
      "2            2       2        0       -1     0.047855         -0.047855\n",
      "3            3       2        1        1     0.952145          0.952145\n",
      "   action  expected_valence\n",
      "0       2          0.904289\n",
      "1       0         -0.513193\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.782508         -0.782508\n",
      "1            1       0        1        1     0.217492          0.217492\n",
      "2            2       2        0       -1     0.017167         -0.017167\n",
      "3            3       2        1        1     0.982833          0.982833\n",
      "   action  expected_valence\n",
      "0       2          0.965665\n",
      "1       0         -0.565017\n",
      "Action: 2, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.802267         -0.802267\n",
      "1            1       0        1        1     0.197733          0.197733\n",
      "2            2       2        0       -1     0.105561         -0.105561\n",
      "3            3       2        1        1     0.894439          0.894439\n",
      "   action  expected_valence\n",
      "0       2          0.788879\n",
      "1       0         -0.604534\n",
      "Action: 2, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.881948         -0.881948\n",
      "1            1       0        1        1     0.118052          0.118052\n",
      "2            2       2        0       -1     0.123078         -0.123078\n",
      "3            3       2        1        1     0.876922          0.876922\n",
      "   action  expected_valence\n",
      "0       2          0.753845\n",
      "1       0         -0.763896\n",
      "Action: 2, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.701522         -0.701522\n",
      "1            1       0        1        1     0.298477          0.298477\n",
      "2            2       2        0       -1     0.383214         -0.383214\n",
      "3            3       2        1        1     0.616786          0.616786\n",
      "   action  expected_valence\n",
      "0       2          0.233572\n",
      "1       0         -0.403045\n",
      "Action: 2, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.538795         -0.538795\n",
      "1            1       0        1        1     0.461205          0.461205\n",
      "2            2       2        0       -1     0.653209         -0.653209\n",
      "3            3       2        1        1     0.346791          0.346791\n",
      "   action  expected_valence\n",
      "0       0         -0.077591\n",
      "1       2         -0.306418\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.429444         -0.429444\n",
      "1            1       0        1        1     0.570556          0.570556\n",
      "2            2       2        0       -1     0.641411         -0.641411\n",
      "3            3       2        1        1     0.358590          0.358590\n",
      "   action  expected_valence\n",
      "0       0          0.141111\n",
      "1       2         -0.282821\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.519462         -0.519462\n",
      "1            1       0        1        1     0.480538          0.480538\n",
      "2            2       2        0       -1     0.384424         -0.384424\n",
      "3            3       2        1        1     0.615576          0.615576\n",
      "   action  expected_valence\n",
      "0       2          0.231153\n",
      "1       0         -0.038924\n",
      "Action: 2, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.146875         -0.146875\n",
      "1            1       0        1        1     0.853125          0.853125\n",
      "2            2       2        0       -1     0.799334         -0.799334\n",
      "3            3       2        1        1     0.200666          0.200666\n",
      "   action  expected_valence\n",
      "0       0          0.706249\n",
      "1       2         -0.598668\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.051240         -0.051240\n",
      "1            1       0        1        1     0.948760          0.948760\n",
      "2            2       2        0       -1     0.890989         -0.890989\n",
      "3            3       2        1        1     0.109011          0.109011\n",
      "   action  expected_valence\n",
      "0       0          0.897519\n",
      "1       2         -0.781977\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.062374         -0.062374\n",
      "1            1       0        1        1     0.937626          0.937626\n",
      "2            2       2        0       -1     0.867331         -0.867331\n",
      "3            3       2        1        1     0.132669          0.132669\n",
      "   action  expected_valence\n",
      "0       0          0.875253\n",
      "1       2         -0.734661\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "   interaction  action  outcome  valence  probability  expected_valence\n",
      "0            0       0        0       -1     0.026726         -0.026726\n",
      "1            1       0        1        1     0.973274          0.973274\n",
      "2            2       2        0       -1     0.932932         -0.932932\n",
      "3            3       2        1        1     0.067068          0.067068\n",
      "   action  expected_valence\n",
      "0       0          0.946548\n",
      "1       2         -0.865864\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = Agent(interactions)\n",
    "e = Environment4()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c99f70-a15d-4e2d-b590-3a4712524640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25645336-ffdb-42ca-8ac3-a69f7667e0b8",
   "metadata": {},
   "source": [
    "# Analyse\n",
    "\n",
    "Ca fonctionne ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae66437-afb3-472d-b046-1a498e6dee84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
