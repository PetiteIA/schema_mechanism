{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f34084-d4b8-4160-89ad-a927a0919615",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/notebooks/agent7.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# THE AGENT WHO PROGRAMMED ITSELF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "Upon completing this lab, you will be able to implement a developmental agent that can re-enact a whole sequence of interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "## Define the necessary classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44155c4a-d038-40b3-be33-e8cf77c5f976",
   "metadata": {},
   "source": [
    "Let's improve the Interaction class again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96c3637-4161-49aa-9f1d-0d3342de92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, action, outcome, valence):\n",
    "        self._action = action\n",
    "        self._outcome = outcome\n",
    "        self._valence = valence\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_outcome(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._outcome\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self._action}{self._outcome}\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key. Used for compatibility with CompositeInteraction\"\"\"\n",
    "        return self.key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self._action}{self._outcome}:{self._valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False            "
   ]
  },
  {
   "cell_type": "raw",
   "id": "be99690f-4199-4438-afdd-13c7ee0b65fe",
   "metadata": {},
   "source": [
    "Let's improve the CompositeInteraction class again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3243d6-1de3-418e-9236-8af0287131da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeInteraction:\n",
    "    \"\"\"A composite interaction is a tuple (pre_interaction, post_interaction) and a weight\"\"\"\n",
    "    def __init__(self, pre_interaction, post_interaction):\n",
    "        self.pre_interaction = pre_interaction\n",
    "        self.post_interaction = post_interaction\n",
    "        self.weight = 1\n",
    "        self.isActivated = False\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"Return the action of the pre interaction\"\"\"\n",
    "        return self.pre_interaction.get_action()\n",
    "    \n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the valence of the pre_interaction plus the valence of the post_interaction\"\"\"\n",
    "        return self.pre_interaction.get_valence() + self.post_interaction.get_valence()\n",
    "\n",
    "    def reinforce(self):\n",
    "        \"\"\"Increment the composite interaction's weight\"\"\"\n",
    "        self.weight += 1\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string '<pre_interaction><post_interaction>'. \"\"\"\n",
    "        return f\"({self.pre_interaction.key()},{self.post_interaction.key()})\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key of the pre_interaction\"\"\"\n",
    "        return self.pre_interaction.pre_key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print the interaction in the Newick tree format (pre_interaction, post_interaction: valence) \"\"\"\n",
    "        return f\"({self.pre_interaction}, {self.post_interaction}: {self.weight})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same pre and post interactions \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return (self.pre_interaction == other.pre_interaction) and (self.post_interaction == other.post_interaction)\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152512a3-ef97-473a-91a7-9a36fe70ba33",
   "metadata": {},
   "source": [
    "## Define the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b81c3-5671-4ec6-bb7d-9db4f99c7c0b",
   "metadata": {},
   "source": [
    "We will use a Pandas DataFrame to compute the selection of the next intended interaction and to predict its most likely outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7e5da-0188-4924-92f4-3ecbfc2fce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d65a49-9e8a-4834-b064-d9fff651abdc",
   "metadata": {},
   "source": [
    "###### Let's implement a base Agent that has the functionnalities of Agent6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0bf369-48ef-48d7-a92b-3c7ef8dc1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize our agent \"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._composite_interactions = {}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "        self._last_interaction = None\n",
    "        self._previous_interaction = None\n",
    "        self._penultimate_interaction = None\n",
    "        self._last_composite_interaction = None\n",
    "        self._previous_composite_interaction = None\n",
    "        # Create a dataframe of default primitive interactions \n",
    "        default_interactions = [interaction for interaction in _interactions if interaction.get_outcome() == 0]\n",
    "        data = {'interaction': [i.key() for i in default_interactions],\n",
    "                'action': [i.get_action() for i in default_interactions],\n",
    "                'weight': [0] * len(default_interactions),\n",
    "                'proclivity': [0] * len(default_interactions)}\n",
    "        self.primitive_df = pd.DataFrame(data)\n",
    "        # Store the selection dataframe as a class attribute so we can display it in the notebook\n",
    "        self.selection_df = None\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Implement the agent's policy\"\"\"\n",
    "        # tracing the previous cycle\n",
    "        self._previous_composite_interaction = self._last_composite_interaction\n",
    "        self._penultimate_interaction = self._previous_interaction\n",
    "        self._previous_interaction = self._last_interaction\n",
    "        self._last_interaction = self._interactions[f\"{self._intended_interaction.get_action()}{_outcome}\"]\n",
    "        print(f\"Action: {self._intended_interaction.get_action()}, Prediction: {self._intended_interaction.get_outcome()}, \"\n",
    "              f\"Outcome: {_outcome}, Prediction_correct: {self._intended_interaction.get_outcome() == _outcome}, \"\n",
    "              f\"Valence: {self._last_interaction.get_valence()}\")\n",
    "\n",
    "        # Call the learning mechanism\n",
    "        self.learn()\n",
    "        \n",
    "        # Create a dataframe from the activated composite interaction \n",
    "        activated_keys = [composite_interaction.key() for composite_interaction in self._composite_interactions.values() \n",
    "                          if composite_interaction.pre_interaction == self._last_interaction or \n",
    "                          composite_interaction.pre_interaction == self._last_composite_interaction]\n",
    "        data = {'composite': activated_keys,\n",
    "                'weight': [self._composite_interactions[k].weight for k in activated_keys],\n",
    "                'post_valence': [self._composite_interactions[k].post_interaction.get_valence() for k in activated_keys],\n",
    "                'action': [self._composite_interactions[k].post_interaction.get_action() for k in activated_keys],\n",
    "                'interaction': [self._composite_interactions[k].post_interaction.pre_key() for k in activated_keys]\n",
    "                }\n",
    "        activated_df = pd.DataFrame(data)\n",
    "\n",
    "        # Create the selection dataframe from the primitive and the activated dataframes\n",
    "        df = pd.concat([self.primitive_df, activated_df], ignore_index=True)\n",
    "\n",
    "        # Compute the proclivity for each action\n",
    "        df['proclivity'] = df['weight'] * df['post_valence']\n",
    "        grouped_df = df.groupby('action').agg({'proclivity': 'sum'}).reset_index()\n",
    "        df = df.merge(grouped_df, on='action', suffixes=('', '_sum'))\n",
    "\n",
    "        # Find the most probable outcome for each action\n",
    "        max_weight_df = df.loc[df.groupby('action')['weight'].idxmax(), ['action', 'interaction']].reset_index(drop=True)\n",
    "        max_weight_df.columns = ['action', 'intended']\n",
    "        df = df.merge(max_weight_df, on='action')\n",
    "\n",
    "        # Find the first row that has the highest proclivity\n",
    "        max_index = df['proclivity_sum'].idxmax()\n",
    "        intended_interaction_key = df.loc[max_index, ['intended']].values[0]\n",
    "        self._intended_interaction = self._interactions[intended_interaction_key]\n",
    "        print(\"Intended\", self._intended_interaction)\n",
    "\n",
    "        # Store the selection dataframe for printing\n",
    "        self.selection_df = df.copy()\n",
    "        \n",
    "        return self._intended_interaction.get_action()\n",
    "\n",
    "    def learn(self):\n",
    "        # Recording previous composite interaction\n",
    "        if self._previous_interaction is not None:\n",
    "            # Record or reinforce the first level composite interaction\n",
    "            composite_interaction = CompositeInteraction(self._previous_interaction, self._last_interaction)\n",
    "            if composite_interaction.key() not in self._composite_interactions:\n",
    "                self._composite_interactions[composite_interaction.key()] = composite_interaction\n",
    "                print(f\"Learning {composite_interaction}\")\n",
    "                self._last_composite_interaction = composite_interaction\n",
    "            else:\n",
    "                self._composite_interactions[composite_interaction.key()].reinforce()\n",
    "                print(f\"Reinforcing {self._composite_interactions[composite_interaction.key()]}\")\n",
    "                self._last_composite_interaction = self._composite_interactions[composite_interaction.key()]\n",
    "                # Retrieve the existing composite interaction\n",
    "                composite_interaction = self._composite_interactions[composite_interaction.key()]\n",
    "            \n",
    "            # Record or reinforce the second level composite interaction\n",
    "            if self._previous_composite_interaction is not None:\n",
    "                composite_interaction_2 = CompositeInteraction(self._previous_composite_interaction, self._last_interaction)\n",
    "                if composite_interaction_2.key() not in self._composite_interactions:\n",
    "                    self._composite_interactions[composite_interaction_2.key()] = composite_interaction_2\n",
    "                    print(f\"Learning {composite_interaction_2}\")\n",
    "                else:\n",
    "                    self._composite_interactions[composite_interaction_2.key()].reinforce()\n",
    "                    print(f\"Reinforcing {self._composite_interactions[composite_interaction_2.key()]}\")\n",
    "        \n",
    "            if self._penultimate_interaction is not None:\n",
    "                composite_interaction_3 = CompositeInteraction(self._penultimate_interaction, composite_interaction)\n",
    "                if composite_interaction_3.key() not in self._composite_interactions:\n",
    "                    self._composite_interactions[composite_interaction_3.key()] = composite_interaction_3\n",
    "                    print(f\"Learning {composite_interaction_3}\")\n",
    "                else:\n",
    "                    self._composite_interactions[composite_interaction_3.key()].reinforce()\n",
    "                    print(f\"Reinforcing {self._composite_interactions[composite_interaction_3.key()]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019f138-a218-44b2-964a-8095fbe891a7",
   "metadata": {},
   "source": [
    "# PRELIMINARY EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f2924-f597-4d34-bc96-3602dc4460b7",
   "metadata": {},
   "source": [
    "Let's test this agent in Environment5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "cf9a38a7-78b8-4590-90c4-4ce903b26876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment5:\n",
    "    \"\"\" Environment5 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment4 \"\"\"\n",
    "        self._previous_action = 0\n",
    "        self._last_action = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        \"\"\"Take the action and generate the next outcome \"\"\"\n",
    "        if action == self._last_action and action == self._previous_action:\n",
    "            # If same action during the last 3 steps then outcome 0\n",
    "            outcome = 0\n",
    "        else:\n",
    "            # If different action then outcome 1\n",
    "            outcome = 1\n",
    "        self._previous_action = self._last_action\n",
    "        self._last_action = action\n",
    "        return outcome  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "6f6d76df-89e4-4ab3-a327-afa813a27325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the agent in Environment5\n",
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1)\n",
    "]\n",
    "a = Agent(interactions)\n",
    "e = Environment5()\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf97eb-7aca-4157-ba8e-3e97f2b85ae1",
   "metadata": {},
   "source": [
    "Run the simulation step by step to see the Selection DataFrame. Use `Ctrl+Enter` to run the cell bellow and stay on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "5b044b4d-162e-4491-929c-a73eb584dcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1\n",
      "Reinforcing (01:1, 01:1: 6)\n",
      "Reinforcing ((11:1, 01:1: 6), 01:1: 6)\n",
      "Reinforcing (11:1, (01:1, 01:1: 6): 6)\n",
      "Intended 11:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composite</th>\n",
       "      <th>weight</th>\n",
       "      <th>post_valence</th>\n",
       "      <th>action</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>proclivity_sum</th>\n",
       "      <th>intended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(01,01)</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(01,00)</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((01,01),00)</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(01,(01,00))</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(01,(00,11))</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(01,11)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((01,01),11)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(01,(01,11))</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(01,(11,01))</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       composite  weight  post_valence  action  proclivity  proclivity_sum  \\\n",
       "0            NaN       0           NaN       0         NaN             8.0   \n",
       "1            NaN       0           NaN       1         NaN            12.0   \n",
       "2        (01,01)       6           1.0       0         6.0             8.0   \n",
       "3        (01,00)       2          -1.0       0        -2.0             8.0   \n",
       "4   ((01,01),00)       2          -1.0       0        -2.0             8.0   \n",
       "5   (01,(01,00))       2           0.0       0         0.0             8.0   \n",
       "6   (01,(00,11))       2           0.0       0         0.0             8.0   \n",
       "7        (01,11)       3           1.0       1         3.0            12.0   \n",
       "8   ((01,01),11)       3           1.0       1         3.0            12.0   \n",
       "9   (01,(01,11))       3           2.0       0         6.0             8.0   \n",
       "10  (01,(11,01))       3           2.0       1         6.0            12.0   \n",
       "\n",
       "   intended  \n",
       "0        01  \n",
       "1        11  \n",
       "2        01  \n",
       "3        01  \n",
       "4        01  \n",
       "5        01  \n",
       "6        01  \n",
       "7        11  \n",
       "8        11  \n",
       "9        01  \n",
       "10       11  "
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "outcome = e.outcome(action)\n",
    "a.selection_df[['composite', 'weight', 'post_valence', 'action', 'proclivity', 'proclivity_sum', 'intended']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daa278-434e-43ce-8520-8fabef69cd83",
   "metadata": {},
   "source": [
    "Observe the Selection DataFrame above as you run the agent step by step. \n",
    "Each activated composite interaction proposes the action of its post_interaction with proclity equals to the composite interaction's weight multiplied by the post interactions' valence. \n",
    "\n",
    "The proclivities are summed for each action. The action that has the highest sum proclivity is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065939b-e62a-4123-81fb-97bb0a6ddcdb",
   "metadata": {},
   "source": [
    "Let's test this agent in Environment6 that returns 1 if and only if the agent takes the same action twice in a row only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "5bf9a4ba-2703-49e9-a63f-b72c08b8663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment6:\n",
    "    \"\"\" Environm4 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment4 \"\"\"\n",
    "        self._previous_action = 0\n",
    "        self._last_action = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        \"\"\"Take the action and generate the next outcome \"\"\"\n",
    "        if self._last_action == action and self._previous_action != action:\n",
    "            # If same action twice only\n",
    "            outcome = 1\n",
    "        else:\n",
    "            # If different action then outcome 0\n",
    "            outcome = 0\n",
    "        self._previous_action = self._last_action\n",
    "        self._last_action = action\n",
    "        return outcome     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "c77efa8b-15fa-4624-9f72-2af2783e47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the agent in Environment6\n",
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1)\n",
    "]\n",
    "a = Agent(interactions)\n",
    "e = Environment6()\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "id": "32a9aac4-611d-4201-acd2-1e1df173014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 48\n",
      "Action: 1, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1\n",
      "Reinforcing (10:-1, 10:-1: 5)\n",
      "Reinforcing ((11:1, 10:-1: 4), 10:-1: 3)\n",
      "Reinforcing (11:1, (10:-1, 10:-1: 5): 3)\n",
      "Intended 11:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composite</th>\n",
       "      <th>weight</th>\n",
       "      <th>post_valence</th>\n",
       "      <th>action</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>proclivity_sum</th>\n",
       "      <th>intended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10,00)</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10,(00,01))</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10,11)</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(10,(11,00))</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(10,(11,10))</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(10,10)</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((10,10),10)</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(10,(10,10))</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>((10,10),00)</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(10,(10,00))</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(10,(00,10))</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       composite  weight  post_valence  action  proclivity  proclivity_sum  \\\n",
       "0            NaN       0           NaN       0         NaN            -9.0   \n",
       "1            NaN       0           NaN       1         NaN            -7.0   \n",
       "2        (10,00)       5          -1.0       0        -5.0            -9.0   \n",
       "3   (10,(00,01))       4           0.0       0         0.0            -9.0   \n",
       "4        (10,11)       8           1.0       1         8.0            -7.0   \n",
       "5   (10,(11,00))       4           0.0       1         0.0            -7.0   \n",
       "6   (10,(11,10))       4           0.0       1         0.0            -7.0   \n",
       "7        (10,10)       5          -1.0       1        -5.0            -7.0   \n",
       "8   ((10,10),10)       2          -1.0       1        -2.0            -7.0   \n",
       "9   (10,(10,10))       2          -2.0       1        -4.0            -7.0   \n",
       "10  ((10,10),00)       2          -1.0       0        -2.0            -9.0   \n",
       "11  (10,(10,00))       2          -2.0       1        -4.0            -7.0   \n",
       "12  (10,(00,10))       1          -2.0       0        -2.0            -9.0   \n",
       "\n",
       "   intended  \n",
       "0        00  \n",
       "1        11  \n",
       "2        00  \n",
       "3        00  \n",
       "4        11  \n",
       "5        11  \n",
       "6        11  \n",
       "7        11  \n",
       "8        11  \n",
       "9        11  \n",
       "10       00  \n",
       "11       11  \n",
       "12       00  "
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "outcome = e.outcome(action)\n",
    "a.selection_df[['composite', 'weight', 'post_valence', 'action', 'proclivity', 'proclivity_sum', 'intended']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ce510-9438-47d1-ac88-ab79c063d592",
   "metadata": {},
   "source": [
    "The agent cannot get the optimum valence in Environment6. We are going to design Agent7 that can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50d96e-4f12-4531-a122-9d13d8bd8639",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199faee9-a546-4d86-8e09-484bf2212523",
   "metadata": {},
   "source": [
    "We want Agent7 to be able to select the next action based on the possiblity to enact a full composite interaction. This is illustrated in Figure 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e95995-8077-46ed-a03d-e318623cb82b",
   "metadata": {},
   "source": [
    "![Agent5](img/Figure_1_Agent7.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742aecbc-5e94-4cc6-bf5d-1b6c12bde814",
   "metadata": {},
   "source": [
    "Figure 1: Agent7 records and reinforces two levels of composite interactions:\n",
    "* First-level composite interaction $c_{t-1} = (i_{t-2}, i_{t-1}: weight)$, \n",
    "* Second-level composite interaction $((i_{t-3}, i_{t-2}), i_{t-1}: weight)$, $i_{t-3}, (i_{t-2}, i_{t-1}): weight)$, \n",
    "and $((i_{t-4}, i_{t-2}), (i_{t-2}, i_{t-1}): weight)$. \n",
    "\n",
    "The last enacted primitive interaction $i_{t-1}$ and the last enacted composite interaction $c_{t-1}$ activates previously-learned composite interactions that propose their post interaction. \n",
    "\n",
    "Now we want this post interaction to possibly be a composite interaction.\n",
    "This means that Agent7 is now capable of making a decision based on an anticipation of two steps ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "id": "2e150c60-5315-4a49-822f-2681fb22a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent7(Agent):\n",
    "    def learn(self):\n",
    "        # Implement the learning mechanism of Agent6 here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fec51-19aa-447d-a456-893249acc994",
   "metadata": {},
   "source": [
    "## Test your Agent7 in Environment6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "id": "74c423e8-de20-479c-84f7-8d64b3985433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate a new agent\n",
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1),\n",
    "    Interaction(2,0,-1),\n",
    "    Interaction(2,1,1)\n",
    "]\n",
    "a = Agent7(interactions)\n",
    "e = Environment6()\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0159e4d4-f851-432b-8127-63403d7a45c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1\n",
      "Intended 00:-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composite</th>\n",
       "      <th>weight</th>\n",
       "      <th>expected_valence</th>\n",
       "      <th>action</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>proclivity_sum</th>\n",
       "      <th>intended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   composite  weight  expected_valence  action  proclivity  proclivity_sum  \\\n",
       "0        NaN     0.0               NaN     0.0         NaN             0.0   \n",
       "1        NaN     0.0               NaN     1.0         NaN             0.0   \n",
       "2        NaN     0.0               NaN     2.0         NaN             0.0   \n",
       "\n",
       "  intended  \n",
       "0       00  \n",
       "1       10  \n",
       "2       20  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "outcome = e.outcome(action)\n",
    "a.selection_df[['composite', 'weight', 'expected_valence', 'action', 'proclivity', 'proclivity_sum', 'intended']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c101e5-2dad-4e57-a52e-eb1f7d634564",
   "metadata": {},
   "source": [
    "## Test your Agent7 in the grid world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15a134-34a6-4039-9b43-f8fd76d93b5e",
   "metadata": {},
   "source": [
    "## Report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e661c15-c1ed-4512-a1d9-0fbdb8f91879",
   "metadata": {},
   "source": [
    "Explain what you programmed and what results you observed. Export this document as PDF including your code, the traces you obtained, and your explanations below (no more than a few paragraphs):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
