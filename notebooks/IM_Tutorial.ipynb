{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# INTERACTIONAL MOTIVATION TUTORIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "Upon completing this tutorial, you will be able to adjust the valence of an Interactional Motivation (IM) system to design an agent that generates the behavior you intend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957e7b6-d560-4e4e-a8bf-0a7b62817a7a",
   "metadata": {},
   "source": [
    "# Let's implement the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3243d6-1de3-418e-9236-8af0287131da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CompositeInteraction:\n",
    "    \"\"\"A composite interaction is a tuple (pre_interaction, post_interaction) and a weight\"\"\"\n",
    "    def __init__(self, pre_interaction, post_interaction):\n",
    "        self.pre_interaction = pre_interaction\n",
    "        self.post_interaction = post_interaction\n",
    "        self.weight = 1\n",
    "        self._step = 1\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the flatten sequence of intermediary primitive interactions terminated with the final decision\"\"\"\n",
    "        return f\"{self.pre_interaction.sequence()}{self.post_interaction.get_decision()}\"\n",
    "\n",
    "    def get_actions(self):\n",
    "        \"\"\"Return the flat sequence of the decisions of this interaction as a string\"\"\"\n",
    "        return f\"{self.pre_interaction.get_actions()}{self.post_interaction.get_actions()}\"\n",
    "    \n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the primite action\"\"\"\n",
    "        return self.pre_interaction.get_primitive_action()\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the valence of the pre_interaction plus the valence of the post_interaction\"\"\"\n",
    "        return self.pre_interaction.get_valence() + self.post_interaction.get_valence()\n",
    "\n",
    "    def reinforce(self):\n",
    "        \"\"\"Increment the composite interaction's weight\"\"\"\n",
    "        self.weight += 1\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string '<pre_interaction><post_interaction>'. \"\"\"\n",
    "        return f\"({self.pre_interaction.key()},{self.post_interaction.key()})\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key of the pre_interaction\"\"\"\n",
    "        return self.pre_interaction.pre_key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print the interaction in the Newick tree format (pre_interaction, post_interaction: valence) \"\"\"\n",
    "        return f\"({self.pre_interaction}, {self.post_interaction}: {self.weight})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same pre and post interactions \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return (self.pre_interaction == other.pre_interaction) and (self.post_interaction == other.post_interaction)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"Return the length of the number of primitive interactions in this composite interaction\"\"\"\n",
    "        return self.pre_interaction.get_length() + self.post_interaction.get_length()\n",
    "\n",
    "    def increment(self, interaction, interactions):\n",
    "        \"\"\"Increment the step of the appropriate sub-interaction. Return the enacted interaction if it is over, or None if it is ongoing.\"\"\"\n",
    "        # First step \n",
    "        if self._step == 1:\n",
    "            interaction = self.pre_interaction.increment(interaction, interactions)\n",
    "            # Ongoing pre-interaction. Return None\n",
    "            if interaction is None:\n",
    "                return None\n",
    "            # Pre-interaction succeeded. Increment the step and return None\n",
    "            elif interaction == self.pre_interaction:\n",
    "                self._step = 2\n",
    "                return None\n",
    "            # Pre-interaction failed. Reset the step and return the enacted interaction\n",
    "            else:\n",
    "                self._step = 1\n",
    "                return interaction\n",
    "        # Second step\n",
    "        else:\n",
    "            interaction = self.post_interaction.increment(interaction, interactions)\n",
    "            # Ongoing post-interaction. Return None\n",
    "            if interaction is None:\n",
    "                return None\n",
    "            # Post-interaction succeeded. Reset the step and return this interaction\n",
    "            elif interaction == self.post_interaction:\n",
    "                self._step = 1\n",
    "                return self\n",
    "            # Post-interaction failed. Reset the step and return the enacted interaction\n",
    "            else:\n",
    "                self._step = 1\n",
    "                composite_interaction = CompositeInteraction(self.pre_interaction, interaction)\n",
    "                if composite_interaction.key() not in interactions:\n",
    "                    # Add the enacted composite interaction to memory\n",
    "                    interactions[composite_interaction.key()] = composite_interaction\n",
    "                    print(f\"Learning {composite_interaction}\")\n",
    "                    return composite_interaction\n",
    "                else:\n",
    "                    # Reinforce the existing composite interaction and return it\n",
    "                    interactions[composite_interaction.key()].reinforce()\n",
    "                    #print(f\"Reinforcing {interactions[composite_interaction.key()]}\")\n",
    "                    return interactions[composite_interaction.key()]\n",
    "\n",
    "    def current(self):\n",
    "        \"\"\"Return the current intended primitive interaction\"\"\"\n",
    "        # Step 1: the current primitive interaction of the pre-interaction\n",
    "        if self._step == 1:\n",
    "            return self.pre_interaction.current()\n",
    "        # Step 2: The current primitive interaction of the post-interaction\n",
    "        else:\n",
    "            return self.post_interaction.current()\n",
    "\n",
    "    def sequence(self):\n",
    "        \"\"\"Return the flat sequence of primitive interactions of this composite interaction\"\"\"\n",
    "        return f\"{self.pre_interaction.sequence()}{self.post_interaction.sequence()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7fd8bc-9dee-4aef-a217-3ed77844e2f2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, _action, _outcome, _valence):\n",
    "        self._action = _action\n",
    "        self._outcome = _outcome\n",
    "        self._valence = _valence\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_actions(self):\n",
    "        \"\"\"Return the action as a string for compatibilty with CompositeInteraction\"\"\"\n",
    "        return str(self._action)\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the decision key\"\"\"\n",
    "        return f\"{self._action}\"\n",
    "        # return f\"a{self._action}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the action for compatibility with CompositeInteraction\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_outcome(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._outcome\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self._action}{self._outcome}\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key. Used for compatibility with CompositeInteraction\"\"\"\n",
    "        return self.key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self._action}{self._outcome}:{self._valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"The length of the sequence of this interaction\"\"\"\n",
    "        return 1\n",
    "\n",
    "    def increment(self, interaction, interactions):\n",
    "        \"\"\"Return the enacted interaction for compatibility with composite interactions\"\"\"\n",
    "        return interaction\n",
    "\n",
    "    def current(self):\n",
    "        \"\"\"Return itself for compatibility with composite interactions\"\"\"\n",
    "        return self\n",
    "\n",
    "    def sequence(self):\n",
    "        \"\"\"Return the key. Use for compatibility with composite interactions\"\"\"\n",
    "        return self.key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf545ea9-a6b5-4c2a-8179-4145894e26a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize our agent \"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._primitive_intended_interaction = self._interactions[\"00\"]\n",
    "        self._intended_interaction = None\n",
    "\n",
    "        # The context\n",
    "        self._penultimate_interaction = None\n",
    "        self._previous_interaction = None\n",
    "        self._last_interaction = None\n",
    "        self._penultimate_composite_interaction = None\n",
    "        self._previous_composite_interaction = None\n",
    "        self._last_composite_interaction = None\n",
    "        \n",
    "        # Prepare the dataframe of proposed interactions\n",
    "        default_interactions = [interaction for interaction in _interactions if interaction.get_outcome() == 0]\n",
    "        data = {'activated': [\"\"] * len(default_interactions),\n",
    "                'weight': [0] * len(default_interactions),\n",
    "                'action': [i.get_action() for i in default_interactions],\n",
    "                'actions': [i.get_actions() for i in default_interactions],\n",
    "                'intention': [i.key() for i in default_interactions],\n",
    "                'valence': [i.get_valence() for i in default_interactions],\n",
    "                'decision': [i.get_decision() for i in default_interactions],\n",
    "                'length': [1] * len(default_interactions),\n",
    "                'primitive': [i.key() for i in default_interactions]}\n",
    "        self._default_df = pd.DataFrame(data)\n",
    "        self.proposed_df = None\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Implement the agent's policy\"\"\"\n",
    "\n",
    "        # Trace the previous cycle\n",
    "        primitive_enacted_interaction = self._interactions[f\"{self._primitive_intended_interaction.get_action()}{_outcome}\"]\n",
    "        # print(\n",
    "        #    f\"Action: {self._primitive_intended_interaction.get_action()}, Prediction: {self._primitive_intended_interaction.get_outcome()}, \"\n",
    "        #    f\"Outcome: {_outcome}, Prediction_correct: {self._primitive_intended_interaction.get_outcome() == _outcome}, \"\n",
    "        #    f\"Valence: {primitive_enacted_interaction.get_valence()}\")\n",
    "\n",
    "        # Follow up the enaction\n",
    "        if self._intended_interaction is None: # First interaction cycle\n",
    "            enacted_interaction = primitive_enacted_interaction\n",
    "        else:\n",
    "            enacted_interaction = self._intended_interaction.increment(primitive_enacted_interaction, self._interactions)\n",
    "\n",
    "        # If the intended interaction is over (completely enacted or aborted)\n",
    "        if enacted_interaction is not None:\n",
    "            # Memorize the context\n",
    "            self._penultimate_composite_interaction = self._previous_composite_interaction\n",
    "            self._previous_composite_interaction = self._last_composite_interaction\n",
    "            self._penultimate_interaction = self._previous_interaction\n",
    "            self._previous_interaction = self._last_interaction\n",
    "            self._last_interaction = enacted_interaction\n",
    "            # Call the learning mechanism\n",
    "            self.learn(enacted_interaction)\n",
    "            # Create the proposed dataframe\n",
    "            self.create_proposed_df()\n",
    "            self.aggregate_propositions()\n",
    "            # Decide the next enaction\n",
    "            self.decide()\n",
    "\n",
    "        # Return the next primitive action\n",
    "        self._primitive_intended_interaction = self._intended_interaction.current()\n",
    "        return self._primitive_intended_interaction.get_action()\n",
    "        \n",
    "    def learn(self, enacted_interaction):\n",
    "        \"\"\"Learn the composite interactions\"\"\"\n",
    "        # First level of composite interactions\n",
    "        self._last_composite_interaction = self.learn_composite_interaction(self._previous_interaction, enacted_interaction)\n",
    "        # Second level of composite interactions\n",
    "        self.learn_composite_interaction(self._previous_composite_interaction, enacted_interaction)\n",
    "        self.learn_composite_interaction(self._penultimate_interaction, self._last_composite_interaction)\n",
    "\n",
    "        # Higher level composite interaction made of two composite interactions\n",
    "        if self._last_composite_interaction is not None:\n",
    "            self.learn_composite_interaction(self._penultimate_composite_interaction, self._last_composite_interaction)\n",
    "\n",
    "    \n",
    "    def learn_composite_interaction(self, pre_interaction, post_interaction):\n",
    "        \"\"\"Record or reinforce the composite interaction made of (pre_interaction, post_interaction)\"\"\"\n",
    "        if pre_interaction is None:\n",
    "            return None\n",
    "        else:\n",
    "            # If the pre-interaction exists\n",
    "            composite_interaction = CompositeInteraction(pre_interaction, post_interaction)\n",
    "            if composite_interaction.key() not in self._interactions:\n",
    "                # Add the composite interaction to memory\n",
    "                self._interactions[composite_interaction.key()] = composite_interaction\n",
    "                # print(f\"Learning {composite_interaction}\")\n",
    "                return composite_interaction\n",
    "            else:\n",
    "                # Reinforce the existing composite interaction and return it\n",
    "                self._interactions[composite_interaction.key()].reinforce()\n",
    "                # print(f\"Reinforcing {self._interactions[composite_interaction.key()]}\")\n",
    "                return self._interactions[composite_interaction.key()]\n",
    "\n",
    "    def create_proposed_df(self):\n",
    "        \"\"\"Create the proposed dataframe from the activated interactions\"\"\"\n",
    "        # The list of activated interaction that match the current context\n",
    "        activated_keys = [composite_interaction.key() for composite_interaction in\n",
    "                          self._interactions.values()\n",
    "                          if composite_interaction.get_length() > 1 and\n",
    "                          (composite_interaction.pre_interaction == self._last_interaction or\n",
    "                          composite_interaction.pre_interaction == self._last_composite_interaction)]\n",
    "        data = {'activated': activated_keys,\n",
    "                'weight': [self._interactions[k].weight for k in activated_keys],\n",
    "                'action': [self._interactions[k].post_interaction.get_primitive_action() for k in activated_keys],\n",
    "                'actions': [self._interactions[k].post_interaction.get_actions() for k in activated_keys],\n",
    "                'intention': [self._interactions[k].post_interaction.key() for k in activated_keys],\n",
    "                'valence': [self._interactions[k].post_interaction.get_valence() for k in activated_keys],\n",
    "                'decision': [self._interactions[k].post_interaction.get_decision() for k in activated_keys],\n",
    "                'primitive': [self._interactions[k].post_interaction.pre_key() for k in activated_keys],\n",
    "                'length': [self._interactions[k].post_interaction.get_length() for k in activated_keys],\n",
    "                }\n",
    "        activated_df = pd.DataFrame(data).astype(self._default_df.dtypes)  # Force the same types for the case it is empty\n",
    "\n",
    "        # Create the proposed dataframe\n",
    "        self.proposed_df = pd.concat([self._default_df, activated_df], ignore_index=True)\n",
    "\n",
    "        # Compute the proclivity for each proposition\n",
    "        self.proposed_df['proclivity'] = self.proposed_df['weight'] * self.proposed_df['valence']\n",
    "\n",
    "    def aggregate_propositions(self):\n",
    "        \"\"\"Aggregate the proclivity\"\"\"\n",
    "        # Aggregate the proclivity for each decision\n",
    "        grouped_df = self.proposed_df.groupby('decision').agg({'proclivity': 'sum', 'actions': 'first', 'action': 'first', 'length': 'first', \n",
    "                                                               'intention': 'first', 'primitive': 'first'}).reset_index()\n",
    "        # For each proposed composite decision \n",
    "        for index, proposed in grouped_df[grouped_df['length'] > 1].iterrows():\n",
    "            # print(f\"Index {index}, actions {proposition['actions']}, intention {proposition['intention']}\")\n",
    "            # Find shorter decisions that start with the same sequence \n",
    "            for _, shorter in self.proposed_df[self.proposed_df.apply(lambda row: proposed['actions'].startswith(row['actions']) \n",
    "                                                                      and row['length'] < proposed['length'], axis=1)].iterrows():\n",
    "                # Add the proclivity of the shorter decisions\n",
    "                grouped_df.loc[index, 'proclivity'] += shorter['proclivity']\n",
    "                # print(f\"Decision {proposition['decision']} recieves {shorter['proclivity']} from partial {shorter['intention']}\")\n",
    "        \n",
    "        # Sort by descending proclivity\n",
    "        self.proposed_df = grouped_df.sort_values(by=['proclivity', 'decision'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    def decide(self):\n",
    "        \"\"\"Selects the intended_interaction that at the top of the proposed dataframe\"\"\"\n",
    "        # The intended interaction is in the first row because it has been sorted by descending proclivity\n",
    "        intended_interaction_key = self.proposed_df.loc[0, 'intention']\n",
    "        # print(\"Intention:\", intended_interaction_key)\n",
    "        self._intended_interaction = self._interactions[intended_interaction_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afad0a0-b639-4168-8a62-c97a323b67e8",
   "metadata": {},
   "source": [
    "# Let's implement the environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fada0b-48a0-4840-ab31-a6fc65c7a7a0",
   "metadata": {},
   "source": [
    "This environment can execute three actions: \n",
    "* `move_forward`\n",
    "* `turn_left`\n",
    "* `turn_right` \n",
    "\n",
    "which may yield six possible outcomes:\n",
    "\n",
    "* `stable` : the target remains at the same distance (only after `turn` actions)\n",
    "* `bump` : the agent collided with a wall (only after `move_forward`)\n",
    "* `increase_left`: the target got closer on the left of the agent\n",
    "* `increase_front`: the target got closer in front of the agent\n",
    "* `increase_right`: the target got closer on the right of the agent\n",
    "* `decrease`: the target got farther or disappeared from the sensory field\n",
    "* `eat`: the agent reached the target and ate it (only after `move_forward`)\n",
    "\n",
    "Figure 1 show the three sensory areas `left` `front` et  `right`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668e949-1dc6-447b-8f76-c7d1ba0ef4f7",
   "metadata": {},
   "source": [
    "![Agent11](img/Figure_1_vision.svg)\n",
    "\n",
    "_Figure 1: Distal sensory field_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e654a53-51f5-460a-9ad5-569ac9240783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions\n",
    "FORWARD = 0\n",
    "TURN_LEFT = 1\n",
    "TURN_RIGHT = 2\n",
    "\n",
    "# Outcomes\n",
    "STABLE = 0\n",
    "BUMP = 1\n",
    "INCREASE_LEFT = 2\n",
    "INCREASE_RIGHT = 3\n",
    "INCREASE_FRONT = 4\n",
    "DECREASE = 5\n",
    "EAT = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15624ba-33e2-4b0c-825c-6a01195d7ad6",
   "metadata": {},
   "source": [
    "We define the environment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c153ef60-2a2c-4cfe-9896-92b47ba234e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from ipywidgets import Button, HBox,VBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "BUMPING = 4\n",
    "TARGET = 5\n",
    "save_dir = \"sav\"\n",
    "agent_color = \"#1976D2\"\n",
    "colors = [\"#D6D6D6\", '#5C946E', '#FAE2DB', '#535865', \"#F93943\", \"#E365C1\"]\n",
    "# Directions\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "class Environment():\n",
    "    def __init__(self, position, direction):\n",
    "        self.grid = np.array([\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        ])\n",
    "        self.maze = self.grid.copy()\n",
    "        self.position = np.array(position)  # Using NumPy array of shape (2)\n",
    "        self.direction = direction\n",
    "        self.cmap = ListedColormap(colors)\n",
    "        self.norm = BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5], self.cmap.N)\n",
    "        self.marker_size = 400\n",
    "        self.marker_map = {LEFT: '<', DOWN: 'v', RIGHT: '>', UP: '^'}\n",
    "        self.marker_color = agent_color\n",
    "        self.directions = np.array([\n",
    "            [0, -1],  # Left\n",
    "            [1, 0],   # Down\n",
    "            [0, 1],   # Right\n",
    "            [-1, 0]   # Up\n",
    "        ])\n",
    "        self.previous_smell = 0\n",
    "        self.smell_feedback = np.array([\n",
    "            [STABLE,   INCREASE_LEFT, INCREASE_RIGHT, INCREASE_FRONT], \n",
    "            [DECREASE, INCREASE_LEFT, STABLE,         INCREASE_FRONT], \n",
    "            [DECREASE, STABLE,        INCREASE_RIGHT, INCREASE_FRONT], \n",
    "            [DECREASE, DECREASE,      DECREASE,       INCREASE_FRONT] \n",
    "        ])\n",
    "        \n",
    "\n",
    "    def smell(self):\n",
    "        \"\"\"Return the smell feedback: 1: smell left, 2: smell right, 3: smell front\"\"\"\n",
    "        smell_up_left = np.any(self.grid[:self.position[0]+1, :self.position[1]+1] == TARGET) \n",
    "        smell_up_right = np.any(self.grid[:self.position[0]+1, self.position[1]:] == TARGET) \n",
    "        smell_down_left = np.any(self.grid[self.position[0]:, :self.position[1]+1] == TARGET) \n",
    "        smell_down_right = np.any(self.grid[self.position[0]:, self.position[1]:] == TARGET) \n",
    "        # print(f\"Smell up-left:{smell_up_left}, up-right:{smell_up_right}, down-left:{smell_down_left}, down-right:{smell_down_right}\")\n",
    "        smell_left = {LEFT: smell_down_left, DOWN: smell_down_right, RIGHT: smell_up_right, UP: smell_up_left}[self.direction]\n",
    "        smell_right = {LEFT: smell_up_left, DOWN: smell_down_left, RIGHT: smell_down_right, UP: smell_up_right}[self.direction]\n",
    "        smell = smell_left + 2 * smell_right \n",
    "        result = self.smell_feedback[self.previous_smell, smell]\n",
    "        self.previous_smell = smell\n",
    "        return result\n",
    "    \n",
    "    def outcome(self, action):\n",
    "        \"\"\"Update the grid. Return the outcome of the action.\"\"\"\n",
    "        result = STABLE\n",
    "\n",
    "        if action == FORWARD:  \n",
    "            target_position = self.position + self.directions[self.direction]\n",
    "            if self.grid[tuple(target_position)] in [0, TARGET]:  # Don't bump in targets\n",
    "                self.position[:] = target_position\n",
    "            else:\n",
    "                result = BUMP\n",
    "                self.maze[tuple(target_position)] = BUMPING\n",
    "        \n",
    "        elif action == TURN_RIGHT:\n",
    "            self.direction = {LEFT: UP, DOWN: LEFT, RIGHT: DOWN, UP: RIGHT}[self.direction]\n",
    "        \n",
    "        elif action == TURN_LEFT:\n",
    "            self.direction = {LEFT: DOWN, DOWN: RIGHT, RIGHT: UP, UP: LEFT}[self.direction]\n",
    "        \n",
    "        elif action == FEEL_FRONT:\n",
    "            feeling_position = self.position + self.directions[self.direction]\n",
    "            if self.grid[tuple(feeling_position)] == 0:\n",
    "                self.maze[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = BUMP\n",
    "                self.maze[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_LEFT:\n",
    "            feeling_position = self.position + self.directions[(self.direction + 1) % 4]\n",
    "            if self.grid[tuple(feeling_position)] == 0:\n",
    "                self.maze[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = BUMP\n",
    "                self.maze[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_RIGHT:\n",
    "            feeling_position = self.position + self.directions[self.direction - 1]\n",
    "            if self.grid[tuple(feeling_position)] == 0:\n",
    "                self.maze[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = BUMP\n",
    "                self.maze[tuple(feeling_position)] = FEELING_WALL\n",
    "\n",
    "        # Smell\n",
    "        smell_feedback = self.smell()\n",
    "        if self.grid[self.position[0], self.position[1]] == TARGET:\n",
    "            self.grid[self.position[0], self.position[1]] = 0\n",
    "            self.maze[self.position[0], self.position[1]] = 0\n",
    "            result = EAT\n",
    "        # If not bump then smell_feeback\n",
    "        if not result:\n",
    "            result = smell_feedback\n",
    "        \n",
    "        # print(f\"Line: {self.position[0]}, Column: {self.position[1]}, direction: {self.direction}\")\n",
    "        return result  \n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the grid in the notebook\"\"\"\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "            plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "            plt.show()\n",
    "            def on_click(event):\n",
    "                if event.inaxes is ax and event.button == 1 and event.xdata is not None:\n",
    "                    xi, yi = event.xdata, event.ydata\n",
    "                    if self.grid[round(yi), round(xi)] == TARGET:\n",
    "                        self.grid[round(yi), round(xi)] = 0\n",
    "                        self.maze[round(yi), round(xi)] = 0\n",
    "                    else:\n",
    "                        self.grid[round(yi), round(xi)] = TARGET\n",
    "                        self.maze[round(yi), round(xi)] = TARGET\n",
    "                    ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "        cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "    \n",
    "    def save(self, step):\n",
    "        \"\"\"Save the display as a PNG file\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "        ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "        plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "        ax.text(self.grid.shape[1]-1.5, 0.2, f\"{step:>3}\", fontsize=12, color='White')\n",
    "        plt.savefig(f\"{save_dir}/{step:03}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def clear(self, clear):\n",
    "        \"\"\"Clear the grid display\"\"\"\n",
    "        if clear:\n",
    "            self.maze[:, :] = self.grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0188a-e490-4c14-b3d1-50868d0ccd3f",
   "metadata": {},
   "source": [
    "# Let's test the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39217f-9d79-444f-93ba-8d81e2f16470",
   "metadata": {},
   "source": [
    "We initialize the valences of interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d22620-c12a-4015-b356-c28dd24fc4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_left_stable_val = 0\n",
    "trn_left_left_val = 5\n",
    "trn_left_right_val = 5\n",
    "trn_left_front_val = 10\n",
    "trn_left_decrease_val = -10\n",
    "\n",
    "fwd_stable_val = -5\n",
    "fwd_bump_val = -10\n",
    "fwd_left_val = 5\n",
    "fwd_right_val = 5\n",
    "fwd_front_val = 10\n",
    "fwd_decrease_val = -10\n",
    "eat_val = 0\n",
    "\n",
    "trn_right_stable_val = 0\n",
    "trn_right_left_val = 5\n",
    "trn_right_right_val = 5\n",
    "trn_right_front_val = 10\n",
    "trn_right_decrease_val = -10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53648111-9155-4082-91de-72d8a02f5628",
   "metadata": {},
   "source": [
    "We display interactive cursors that can be used to modify the valences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c2ad7a-8dd4-40b6-b448-d14d384e4545",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a92805c38044edb8c8709006238eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, continuous_update=False, description='Trn left stable', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# Définition des curseurs\n",
    "slider_trn_left_stable = widgets.IntSlider(value=trn_left_stable_val, min=-20, max=10, description='Trn left stable', continuous_update=False)\n",
    "slider_trn_left_left = widgets.IntSlider(value=trn_left_left_val, min=-20, max=10, description='Trn left Left', continuous_update=False)\n",
    "slider_trn_left_front = widgets.IntSlider(value=trn_left_front_val, min=-20, max=10, description='Trn left front', continuous_update=False)\n",
    "slider_trn_left_right = widgets.IntSlider(value=trn_left_right_val, min=-20, max=10, description='Trn left right', continuous_update=False)\n",
    "slider_trn_left_decrease = widgets.IntSlider(value=trn_left_decrease_val, min=-20, max=10, description='Trn left decrease', continuous_update=False)\n",
    "vbox1 = widgets.VBox([slider_trn_left_stable, slider_trn_left_left, slider_trn_left_front, slider_trn_left_right, slider_trn_left_decrease])\n",
    "\n",
    "slider_fwd_stable = widgets.IntSlider(value=fwd_stable_val, min=-20, max=10, description='Fwd stable', continuous_update=False)\n",
    "slider_fwd_decrease = widgets.IntSlider(value=fwd_decrease_val, min=-20, max=10, description='Fwd decrease', continuous_update=False)\n",
    "slider_fwd_bump = widgets.IntSlider(value=fwd_bump_val, min=-20, max=10, description='Bump', continuous_update=False)\n",
    "slider_eat = widgets.IntSlider(value=eat_val, min=-20, max=10, description='Eat', continuous_update=False)\n",
    "slider_fwd_left = widgets.IntSlider(value=fwd_left_val, min=-20, max=10, description='Fwd left', continuous_update=False)\n",
    "slider_fwd_front = widgets.IntSlider(value=fwd_front_val, min=-20, max=10, description='Fwd front', continuous_update=False)\n",
    "slider_fwd_right = widgets.IntSlider(value=fwd_right_val, min=-20, max=10, description='Fwd right', continuous_update=False)\n",
    "vbox2 = widgets.VBox([slider_fwd_stable, slider_fwd_left, slider_fwd_front, slider_fwd_right, slider_fwd_decrease, slider_fwd_bump, slider_eat])\n",
    "\n",
    "slider_trn_right_stable = widgets.IntSlider(value=trn_right_stable_val, min=-20, max=10, description='Trn right stable', continuous_update=False)\n",
    "slider_trn_right_left = widgets.IntSlider(value=trn_right_left_val, min=-20, max=10, description='Trn right Left', continuous_update=False)\n",
    "slider_trn_right_front = widgets.IntSlider(value=trn_right_front_val, min=-20, max=10, description='Trn right front', continuous_update=False)\n",
    "slider_trn_right_right = widgets.IntSlider(value=trn_right_right_val, min=-20, max=10, description='Trn right right', continuous_update=False)\n",
    "slider_trn_right_decrease = widgets.IntSlider(value=trn_right_decrease_val, min=-20, max=10, description='Trn right decrease', continuous_update=False)\n",
    "vbox3 = widgets.VBox([slider_trn_right_stable, slider_trn_right_left, slider_trn_right_front, slider_trn_right_right, slider_trn_right_decrease])\n",
    "\n",
    "# Affichage des curseurs\n",
    "display(widgets.HBox([vbox1, vbox2, vbox3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef0655-a210-4015-b5d1-b3e74fd82707",
   "metadata": {},
   "source": [
    "We initialize the exeriment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e59db638-c069-4589-ae5f-fe50f0fac89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aced9902621480a8599a1f5dd640ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciate the environment\n",
    "e = Environment([6, 4], UP)\n",
    "\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(FORWARD, STABLE, slider_fwd_stable.value),\n",
    "    Interaction(FORWARD, BUMP, slider_fwd_bump.value),\n",
    "    Interaction(FORWARD, INCREASE_LEFT, slider_fwd_left.value),\n",
    "    Interaction(FORWARD, INCREASE_RIGHT, slider_fwd_right.value),\n",
    "    Interaction(FORWARD, INCREASE_FRONT, slider_fwd_front.value),\n",
    "    Interaction(FORWARD, DECREASE, slider_fwd_decrease.value),\n",
    "    Interaction(FORWARD, EAT, slider_eat.value),\n",
    "    Interaction(TURN_LEFT, STABLE, slider_trn_left_stable.value),\n",
    "    Interaction(TURN_LEFT, INCREASE_LEFT, slider_trn_left_left.value),\n",
    "    Interaction(TURN_LEFT, INCREASE_RIGHT, slider_trn_left_right.value),\n",
    "    Interaction(TURN_LEFT, INCREASE_FRONT, slider_trn_left_front.value),\n",
    "    Interaction(TURN_LEFT, DECREASE, slider_trn_left_decrease.value),\n",
    "    Interaction(TURN_RIGHT, STABLE, slider_trn_right_stable.value),\n",
    "    Interaction(TURN_RIGHT, INCREASE_LEFT, slider_trn_right_left.value),\n",
    "    Interaction(TURN_RIGHT, INCREASE_RIGHT, slider_trn_right_right.value),\n",
    "    Interaction(TURN_RIGHT, INCREASE_FRONT, slider_trn_right_front.value),\n",
    "    Interaction(TURN_RIGHT, DECREASE, slider_trn_right_decrease.value),\n",
    "]\n",
    "a = Agent(interactions)\n",
    "\n",
    "# Initialize the experiment\n",
    "step = 0\n",
    "outcome = 0\n",
    "out = Output()\n",
    "e.display()\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89a45b-36cd-4aac-8108-cc255dee27d6",
   "metadata": {},
   "source": [
    "We run the agent one step at a time (using Ctrl+Enter on the next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e38a590-b256-433f-a1d9-100cc7b0a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>actions</th>\n",
       "      <th>action</th>\n",
       "      <th>length</th>\n",
       "      <th>intention</th>\n",
       "      <th>primitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  decision  proclivity actions  action  length intention primitive\n",
       "0        0           0       0       0       1        00        00\n",
       "1        1           0       1       1       1        10        10\n",
       "2        2           0       2       2       1        20        20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step: {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "e.display()\n",
    "e.clear(True)\n",
    "# e.save(step)  # Sauvegarde le fichier image qui servira au gif\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfa042-98b2-4bee-80fd-8db40b3cfaa1",
   "metadata": {},
   "source": [
    "When the agent has eaten the target, use one of the cells below to insert a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "c33dcc4d-8d3f-4a32-919a-86a54ecc1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.grid[3,3] = TARGET\n",
    "e.maze[3,3] = TARGET\n",
    "e.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "e1201627-7f88-4d1c-9a07-7f64641769f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.grid[6, 5] = TARGET\n",
    "e.maze[6, 5] = TARGET\n",
    "e.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "213f855a-f389-4a39-b3ac-0350e5d23a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.grid[2, 9] = TARGET\n",
    "e.maze[2, 9] = TARGET\n",
    "e.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106724a7-82e7-4624-9661-e9be6f4cc515",
   "metadata": {},
   "source": [
    "### Choose between `Widget` mode  or `InLine` mode\n",
    "\n",
    "in `InLine` mode, you must execute one of the cells above to insert a new target.\n",
    "In `widget` mode, you can click on the environment to insert or remove a target.\n",
    "\n",
    "Choose the mode by commenting or decommenting the corresponding line below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "9a034c32-737a-4a6f-9295-44bd34f703d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget mode to allow clicking on the environment to insert or remove targets\n",
    "%matplotlib widget\n",
    "\n",
    "# inline mode to disable clicks on the environment\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a8e1b-ffc1-4f89-8a61-e1ec135124e5",
   "metadata": {},
   "source": [
    "# Run the agent in a loop\n",
    "\n",
    "Choose the steps and the positions to insert new targets in `target_steps` et `target_positions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478727ba-f660-499d-8e9f-657b3af255a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the environment\n",
    "e = Environment([6, 4], UP)\n",
    "# Initialize the agent\n",
    "a = Agent(interactions)\n",
    "outcome = 0\n",
    "\n",
    "# Define when and where new targets are inserted\n",
    "target_steps = [0, 40, 80, 120, 160, 200, 240, 280, 320, 360]\n",
    "target_positions = {0:[3, 6], 40: [4, 11], 80:[2, 2], 120:[7, 2], 160:[2, 4], 200:[6, 7], 240:[2,2], 280:[4,6], 320:[7, 2], 360:[2, 10]}\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display()\n",
    "display(out)\n",
    "for step in range(400):\n",
    "    if step in target_steps:\n",
    "        e.grid[target_positions[step][0], target_positions[step][1]] = TARGET\n",
    "        e.maze[target_positions[step][0], target_positions[step][1]] = TARGET\n",
    "    action = a.action(outcome)\n",
    "    e.display()\n",
    "    e.save(step)  # Save a screenshot \n",
    "    e.clear(True)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6f0d7-39d8-4993-90f8-f3282426f0d5",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "## 1. The agent who banged its head on the wall \n",
    "\n",
    "Give a positive valence to the `bump` interaction. \n",
    "Observe that the agent will place itself in front of a wall and keep buming into it as if it enjoied it!\n",
    "\n",
    "## 2. The agent who beated around the bush\n",
    "\n",
    "Choose the valences to make the agent turn around the target without actually reaching it.\n",
    "\n",
    "## 3. The agent who ran\n",
    "\n",
    "Choose the valences to make the agent go away from the target. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2449d-1ae9-495e-a26e-fc6a297c4438",
   "metadata": {},
   "source": [
    "# Create the animated GIF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "77dd51a7-b14b-42af-b6fc-c015db2ce4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import os\n",
    "\n",
    "img_dir = f\"./{save_dir}\"\n",
    "all_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "images = [imageio.imread(f) for f in all_files]\n",
    "imageio.mimsave(\"movie.gif\", images, fps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f3e834-d723-4b09-8909-0cd2d6c77ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
