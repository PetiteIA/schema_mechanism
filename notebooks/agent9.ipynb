{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f34084-d4b8-4160-89ad-a927a0919615",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/notebooks/agent9.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# THE AGENT WHO PROGRAMMED ITSELF (UNDER CONSTRUCTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "Upon completing this lab, you will be able to implement a developmental agent that can re-execute a previously learned sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c69c3-3286-400e-95bb-6067722cd7fc",
   "metadata": {},
   "source": [
    "# Define the necessary classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f6be28-47b4-4fe1-9d10-8b3d31472ab2",
   "metadata": {},
   "source": [
    "Ensure the required packages are installed if they aren't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ce1cd-4e18-458e-97c1-c19d57259674",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea051881-b708-41cd-9d9b-5c4533ce9c17",
   "metadata": {},
   "source": [
    "The interaction class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7a0eba-8faa-41eb-8c8a-dce185fed2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, _action, _outcome, _valence):\n",
    "        self._action = _action\n",
    "        self._outcome = _outcome\n",
    "        self._valence = _valence\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the decision key\"\"\"\n",
    "        return f\"a{self._action}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the action for compatibility with CompositeInteraction\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_outcome(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._outcome\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self._action}{self._outcome}\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key. Used for compatibility with CompositeInteraction\"\"\"\n",
    "        return self.key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self._action}{self._outcome}:{self._valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18fde8-97a7-4e5a-bd12-0909475e8747",
   "metadata": {},
   "source": [
    "The CompositeInteraction class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0fdfa0b-06ef-4229-9a34-c951f0801a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeInteraction:\n",
    "    \"\"\"A composite interaction is a tuple (pre_interaction, decision, post_interaction) and a weight\"\"\"\n",
    "    def __init__(self, pre_interaction, decision, post_interaction):\n",
    "        self.pre_interaction = pre_interaction\n",
    "        self.decision = decision\n",
    "        self.post_interaction = post_interaction\n",
    "        self.weight = 1\n",
    "        self.isActivated = False\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the sequence of decisions\"\"\"\n",
    "        return self.decision\n",
    "        # return f\"{self.pre_interaction.key()}{self.post_interaction.get_decision()}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the primitive action\"\"\"\n",
    "        return self.pre_interaction.get_primitive_action()\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the valence of the pre_interaction plus the valence of the post_interaction\"\"\"\n",
    "        return self.pre_interaction.get_valence() + self.post_interaction.get_valence()\n",
    "\n",
    "    def reinforce(self):\n",
    "        \"\"\"Increment the composite interaction's weight\"\"\"\n",
    "        self.weight += 1\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string\n",
    "        '<pre_interaction>,<decision>,<post_interaction>'. \"\"\"\n",
    "        # return f\"({self.pre_interaction.key()},{self.post_interaction.key()})\"\n",
    "        return f\"({self.pre_interaction.key()},{self.decision},{self.post_interaction.key()})\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key of the pre_interaction\"\"\"\n",
    "        return self.pre_interaction.pre_key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print the interaction in the Newick tree format (pre_interaction, post_interaction: valence) \"\"\"\n",
    "        return f\"({self.pre_interaction}, {self.decision}, {self.post_interaction}: {self.weight})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same keys \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9d871-0401-43c2-b05f-a77119e9fe5e",
   "metadata": {},
   "source": [
    "The agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b9df907-ddf8-4080-9ac1-6c292d2048ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize our agent \"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._composite_interactions = {}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "        self._decision = None  # \"0\"\n",
    "        self._last_interaction = None\n",
    "        self._previous_interaction = None\n",
    "        self._penultimate_interaction = None\n",
    "        self._last_composite_interaction = None\n",
    "        self._previous_composite_interaction = None\n",
    "        self._penultimate_composite_interaction = None\n",
    "        # Create a dataframe of default primitive interactions\n",
    "        default_interactions = [interaction for interaction in _interactions if interaction.get_outcome() == 0]\n",
    "        data = {'activated': [np.nan] * len(default_interactions),\n",
    "                'weight': [0] * len(default_interactions),\n",
    "                'action': [i.get_primitive_action() for i in default_interactions],\n",
    "                'interaction': [i.key() for i in default_interactions],\n",
    "                'valence': [i.get_valence() for i in default_interactions],\n",
    "                'decision': [i.get_decision() for i in default_interactions],\n",
    "                'proclivity': [0] * len(default_interactions)}\n",
    "        self.primitive_df = pd.DataFrame(data)\n",
    "        # Store the selection dataframe as a class attribute so we can display it in the notebook\n",
    "        self.proposed_df = None\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Implement the agent's policy\"\"\"\n",
    "        # Memorize the context\n",
    "        self._penultimate_composite_interaction = self._previous_composite_interaction\n",
    "        self._previous_composite_interaction = self._last_composite_interaction\n",
    "        self._penultimate_interaction = self._previous_interaction\n",
    "        self._previous_interaction = self._last_interaction\n",
    "        self._last_interaction = self._interactions[f\"{self._intended_interaction.get_action()}{_outcome}\"]\n",
    "\n",
    "        # tracing the previous cycle\n",
    "        print(\n",
    "            f\"Action: {self._intended_interaction.get_action()}, Prediction: {self._intended_interaction.get_outcome()}, \"\n",
    "            f\"Outcome: {_outcome}, Prediction_correct: {self._intended_interaction.get_outcome() == _outcome}, \"\n",
    "            f\"Valence: {self._last_interaction.get_valence()}\")\n",
    "\n",
    "        # Call the learning mechanism\n",
    "        self.learn()\n",
    "\n",
    "        # Create the proposed dataframe\n",
    "        self.create_proposed_df()\n",
    "        self.aggregate_propositions()\n",
    "\n",
    "        # Select the intended primitive interaction\n",
    "        self.decide()\n",
    "\n",
    "        return self._intended_interaction.get_action()\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"Learn the composite interactions\"\"\"\n",
    "        # First level of composite interactions\n",
    "        # self._last_composite_interaction = self.learn_composite_interaction(\n",
    "        #     self._previous_interaction, self._last_interaction.get_decision(), self._last_interaction)\n",
    "        self._last_composite_interaction = self.learn_composite_interaction(\n",
    "            self._previous_interaction, self._decision, self._last_interaction)\n",
    "\n",
    "        # Second level of composite interactions\n",
    "        # self.learn_composite_interaction(self._previous_composite_interaction, self._last_interaction.get_decision(),\n",
    "        #                                  self._last_interaction)\n",
    "        self.learn_composite_interaction(\n",
    "            self._previous_composite_interaction, self._decision, self._last_interaction)\n",
    "\n",
    "        if self._last_composite_interaction is not None:\n",
    "            decision = f\"{self._last_composite_interaction.pre_interaction.key()}{self._last_composite_interaction.post_interaction.get_decision()}\"\n",
    "            self.learn_composite_interaction(self._penultimate_interaction, decision, self._last_composite_interaction)\n",
    "            # self.learn_composite_interaction(self._penultimate_interaction, self._decision, self._last_composite_interaction)\n",
    "            self.learn_composite_interaction(self._penultimate_composite_interaction, decision, self._last_composite_interaction)\n",
    "\n",
    "    def learn_composite_interaction(self, pre_interaction, decision, post_interaction):\n",
    "        \"\"\"Record or reinforce the composite interaction made of (pre_interaction, post_interaction)\"\"\"\n",
    "        if pre_interaction is None:\n",
    "            return None\n",
    "        else:\n",
    "            # If the pre interaction exist\n",
    "            composite_interaction = CompositeInteraction(pre_interaction, decision, post_interaction)\n",
    "            if composite_interaction.key() not in self._composite_interactions:\n",
    "                # Add the composite interaction to memory\n",
    "                self._composite_interactions[composite_interaction.key()] = composite_interaction\n",
    "                print(f\"Learning {composite_interaction}\")\n",
    "                return composite_interaction\n",
    "            else:\n",
    "                # Reinforce the existing composite interaction and return it\n",
    "                self._composite_interactions[composite_interaction.key()].reinforce()\n",
    "                print(f\"Reinforcing {self._composite_interactions[composite_interaction.key()]}\")\n",
    "                return self._composite_interactions[composite_interaction.key()]\n",
    "\n",
    "    def create_proposed_df(self):\n",
    "        \"\"\"Create the proposed dataframe from the activated interactions\"\"\"\n",
    "        # The list of activated interaction that match the current context\n",
    "        activated_keys = [composite_interaction.key() for composite_interaction in\n",
    "                          self._composite_interactions.values()\n",
    "                          if composite_interaction.pre_interaction == self._last_interaction or\n",
    "                          composite_interaction.pre_interaction == self._last_composite_interaction]\n",
    "        data = {'activated': activated_keys,\n",
    "                'weight': [self._composite_interactions[k].weight for k in activated_keys],\n",
    "                'action': [self._composite_interactions[k].post_interaction.get_primitive_action() for k in\n",
    "                           activated_keys],\n",
    "                'interaction': [self._composite_interactions[k].post_interaction.pre_key() for k in activated_keys],\n",
    "                'valence': [self._composite_interactions[k].post_interaction.get_valence() for k in activated_keys],\n",
    "                'decision': [self._composite_interactions[k].get_decision() for k in activated_keys],\n",
    "                }\n",
    "        activated_df = pd.DataFrame(data)\n",
    "\n",
    "        # Create the selection dataframe from the primitive and the activated dataframes\n",
    "        self.proposed_df = pd.concat([self.primitive_df, activated_df], ignore_index=True)\n",
    "\n",
    "        # # Compute the proclivity for each proposition\n",
    "        self.proposed_df['proclivity'] = self.proposed_df['weight'] * self.proposed_df['valence']\n",
    "\n",
    "    def aggregate_propositions(self):\n",
    "        \"\"\"Aggregate the proclivity\"\"\"\n",
    "        # Compute the proclivity for each action\n",
    "        grouped_df = self.proposed_df.groupby('decision').agg({'proclivity': 'sum'}).reset_index()\n",
    "        self.proposed_df = self.proposed_df.merge(grouped_df, on='decision', suffixes=('', '_agg'))\n",
    "        # Sort by descending order of proclivity\n",
    "        self.proposed_df = self.proposed_df.sort_values(by=['proclivity_agg', 'decision'], ascending=[False, False])\n",
    "\n",
    "        # Find the most probable primitive interaction for each action\n",
    "        max_weight_df = self.proposed_df.loc[\n",
    "            self.proposed_df.groupby('decision')['weight'].idxmax(), ['decision', 'interaction']].reset_index(\n",
    "            drop=True)\n",
    "        max_weight_df.columns = ['decision', 'intended']\n",
    "        self.proposed_df = self.proposed_df.merge(max_weight_df, on='decision')\n",
    "\n",
    "    def decide(self):\n",
    "        \"\"\"Selects the intended interaction from the proposed dataframe\"\"\"\n",
    "        # Find the first row that has the highest proclivity\n",
    "        max_index = self.proposed_df['proclivity_agg'].idxmax()\n",
    "        self._decision = self.proposed_df.loc[max_index, ['decision']].values[0]\n",
    "\n",
    "        # Find the intended interaction corresponding to the action that has the highest proclivity\n",
    "        intended_interaction_key = self.proposed_df.loc[max_index, ['intended']].values[0]\n",
    "        self._intended_interaction = self._interactions[intended_interaction_key]\n",
    "        print(f\"Decision {self._decision}, Intended {self._intended_interaction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced88a6c-51fe-43f2-b5f6-9f193d450d4d",
   "metadata": {},
   "source": [
    "Environment7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "73ba7d6c-aaac-47bb-93f5-82d7c13db369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "class Environment7:\n",
    "    \"\"\" The grid \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize the grid and the agent's pose \"\"\"\n",
    "        self.grid = np.array([[1, 0, 0, 1]])\n",
    "        self.position = 1\n",
    "        self.direction = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        \"\"\"Take the action and generate the next outcome \"\"\"\n",
    "        if _action == 0:\n",
    "            # Move left\n",
    "            if self.position > 1:\n",
    "                # No bump\n",
    "                self.position -= 1\n",
    "                self.grid[0, -1] = 1\n",
    "                _outcome = 0\n",
    "            elif self.grid[0, 0] == 1:\n",
    "                # First bump\n",
    "                _outcome = 1\n",
    "                self.grid[0, 0] = 2\n",
    "            else:\n",
    "                # Subsequent bumps\n",
    "                _outcome = 0\n",
    "        else:\n",
    "            # Move right\n",
    "            if self.position < self.grid.shape[1] - 2:  # 2:\n",
    "                # No bump\n",
    "                self.position += 1\n",
    "                self.grid[0, 0] = 1\n",
    "                _outcome = 0\n",
    "            elif self.grid[0, -1] == 1:\n",
    "                # First bump\n",
    "                _outcome = 1\n",
    "                self.grid[0, -1] = 2\n",
    "            else:\n",
    "                # Subsequent bumps\n",
    "                _outcome = 0\n",
    "        return _outcome\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display the grid\"\"\"\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            # Hide the ticks\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # Display the grid\n",
    "            ax.imshow(self.grid, cmap='Greens', vmin=0, vmax=2)\n",
    "            plt.scatter(self.position, 0, s=1000, marker='o')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04626024-08da-4ef5-9301-6fe97b5a0073",
   "metadata": {},
   "source": [
    "# Test the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "7fd991e5-1288-43aa-a049-c447db28b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate a new agent\n",
    "interactions = [\n",
    "    Interaction(0, 0, -1),  # Left\n",
    "    Interaction(0, 1, 1),\n",
    "    Interaction(1, 0, -1),\n",
    "    Interaction(1, 1, 1),  # Right\n",
    "    # Interaction(2, 0, -1),\n",
    "    # Interaction(2, 1, -1)\n",
    "]\n",
    "a = Agent(interactions)\n",
    "e = Environment7()\n",
    "\n",
    "# Output widget for displaying the plot\n",
    "out = Output()\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf97eb-7aca-4157-ba8e-3e97f2b85ae1",
   "metadata": {},
   "source": [
    "Run the simulation step by step to see the environment and the proposed DataFrame. Use `Ctrl+Enter` to run the cell bellow and stay on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "0159e4d4-f851-432b-8127-63403d7a45c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526b1f3b01a946f5a35800e41db907f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 640x480 with 1 Axes>', 'i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 1, Prediction: 1, Outcome: 0, Prediction_correct: False, Valence: -1\n",
      "Reinforcing (10:-1, 11a1, 10:-1: 3)\n",
      "Reinforcing ((10:-1, 11a1, 10:-1: 3), 11a1, 10:-1: 2)\n",
      "Reinforcing (10:-1, 10a1, (10:-1, 11a1, 10:-1: 3): 2)\n",
      "Learning ((10:-1, 11a1, 10:-1: 3), 10a1, (10:-1, 11a1, 10:-1: 3): 1)\n",
      "Decision 11a0, Intended 11:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activated</th>\n",
       "      <th>weight</th>\n",
       "      <th>action</th>\n",
       "      <th>interaction</th>\n",
       "      <th>valence</th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>proclivity_agg</th>\n",
       "      <th>intended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10,11a0,(11,a0,00))</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11a0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10,11a0,(11,00a0,00))</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11a0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10,00a0,(00,a0,01))</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>00a0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10,a1,11)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(10,a1,10)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(10,a0,00)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(10,11a1,(11,a1,10))</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11a1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(10,11a1,11)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11a1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(10,11a1,10)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>11a1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>((10,11a1,10),11a1,10)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>11a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(10,10a0,(10,a0,00))</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(10,10a1,(10,a1,10))</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(10,10a1,(10,11a1,10))</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>((10,11a1,10),10a1,(10,11a1,10))</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           activated  weight  action interaction  valence  \\\n",
       "0               (10,11a0,(11,a0,00))       1       1          11        0   \n",
       "1             (10,11a0,(11,00a0,00))       1       1          11        0   \n",
       "2               (10,00a0,(00,a0,01))       1       0          00        0   \n",
       "3                                NaN       0       1          10       -1   \n",
       "4                         (10,a1,11)       1       1          11        1   \n",
       "5                         (10,a1,10)       2       1          10       -1   \n",
       "6                                NaN       0       0          00       -1   \n",
       "7                         (10,a0,00)       1       0          00       -1   \n",
       "8               (10,11a1,(11,a1,10))       2       1          11        0   \n",
       "9                       (10,11a1,11)       3       1          11        1   \n",
       "10                      (10,11a1,10)       3       1          10       -1   \n",
       "11            ((10,11a1,10),11a1,10)       2       1          10       -1   \n",
       "12              (10,10a0,(10,a0,00))       1       1          10       -2   \n",
       "13              (10,10a1,(10,a1,10))       1       1          10       -2   \n",
       "14            (10,10a1,(10,11a1,10))       2       1          10       -2   \n",
       "15  ((10,11a1,10),10a1,(10,11a1,10))       1       1          10       -2   \n",
       "\n",
       "   decision  proclivity  proclivity_agg intended  \n",
       "0      11a0           0               0       11  \n",
       "1      11a0           0               0       11  \n",
       "2      00a0           0               0       00  \n",
       "3        a1           0              -1       10  \n",
       "4        a1           1              -1       10  \n",
       "5        a1          -2              -1       10  \n",
       "6        a0           0              -1       00  \n",
       "7        a0          -1              -1       00  \n",
       "8      11a1           0              -2       11  \n",
       "9      11a1           3              -2       11  \n",
       "10     11a1          -3              -2       11  \n",
       "11     11a1          -2              -2       11  \n",
       "12     10a0          -2              -2       10  \n",
       "13     10a1          -2              -8       10  \n",
       "14     10a1          -4              -8       10  \n",
       "15     10a1          -2              -8       10  "
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "e.display()\n",
    "display(out)\n",
    "action = a.action(outcome)\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77593530-0598-474e-9bf4-bf19e2568d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
