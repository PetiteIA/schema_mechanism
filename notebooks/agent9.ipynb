{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f34084-d4b8-4160-89ad-a927a0919615",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/notebooks/agent9.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# L'AGENT QUI ESPERAIT GAGNER AU COUP SUIVANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Objectifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "Ce tutoriel montre comment implémenter un agent qui prend une décision basée sur l'espérence de valence des deux prochains cycles d'interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "# Préparons les classes Interaction et CompositeInteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7e5da-0188-4924-92f4-3ecbfc2fce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install ipywidgets\n",
    "!pip install IPython.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d018f-39ae-471d-9976-0737298bc1a0",
   "metadata": {},
   "source": [
    "Mêmes classes `Interaction` et `CompositeInteraction` que pour Agent7 et Agent8 mais ajout de la méthode `get_length()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca7fd8bc-9dee-4aef-a217-3ed77844e2f2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, _action, _outcome, _valence):\n",
    "        self._action = _action\n",
    "        self._outcome = _outcome\n",
    "        self._valence = _valence\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the decision key\"\"\"\n",
    "        return f\"a{self._action}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the action for compatibility with CompositeInteraction\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_outcome(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._outcome\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self._action}{self._outcome}\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key. Used for compatibility with CompositeInteraction\"\"\"\n",
    "        return self.key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self._action}{self._outcome}:{self._valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"The length of the sequence of this interaction\"\"\"\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef3243d6-1de3-418e-9236-8af0287131da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CompositeInteraction:\n",
    "    \"\"\"A composite interaction is a tuple (pre_interaction, post_interaction) and a weight\"\"\"\n",
    "    def __init__(self, pre_interaction, post_interaction):\n",
    "        self.pre_interaction = pre_interaction\n",
    "        self.post_interaction = post_interaction\n",
    "        self.weight = 1\n",
    "        self.isActivated = False\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the sequence of decisions\"\"\"\n",
    "        # return self.key()\n",
    "        return f\"{self.pre_interaction.key()}{self.post_interaction.get_decision()}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the primite action\"\"\"\n",
    "        return self.pre_interaction.get_primitive_action()\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the valence of the pre_interaction plus the valence of the post_interaction\"\"\"\n",
    "        return self.pre_interaction.get_valence() + self.post_interaction.get_valence()\n",
    "\n",
    "    def reinforce(self):\n",
    "        \"\"\"Increment the composite interaction's weight\"\"\"\n",
    "        self.weight += 1\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string '<pre_interaction><post_interaction>'. \"\"\"\n",
    "        return f\"({self.pre_interaction.key()},{self.post_interaction.key()})\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key of the pre_interaction\"\"\"\n",
    "        return self.pre_interaction.pre_key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print the interaction in the Newick tree format (pre_interaction, post_interaction: valence) \"\"\"\n",
    "        return f\"({self.pre_interaction}, {self.post_interaction}: {self.weight})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same pre and post interactions \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return (self.pre_interaction == other.pre_interaction) and (self.post_interaction == other.post_interaction)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_length(self):\n",
    "        return self.pre_interaction.get_length() + self.post_interaction.get_length()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152512a3-ef97-473a-91a7-9a36fe70ba33",
   "metadata": {},
   "source": [
    "# Définissons l'agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d65a49-9e8a-4834-b064-d9fff651abdc",
   "metadata": {},
   "source": [
    "Implémentons un agent qui calcule la valence attendue pour les décisions qui impliquent les deux pas de temps suivants.\n",
    "\n",
    "Nous ajoutons aussi l'apprentissage d'une interaction composite de second niveau pour mémoriser le chainage de deux interactions composites de premier niveau : $((i_{t-4}, i_{t-3}), (i_{t-2}, i_{t-1}))$ \n",
    "\n",
    "La Figure 1 illustre ce mécanisme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e95995-8077-46ed-a03d-e318623cb82b",
   "metadata": {},
   "source": [
    "![Agent5](img/Figure_1_Agent9.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742aecbc-5e94-4cc6-bf5d-1b6c12bde814",
   "metadata": {},
   "source": [
    "Figure 1: L'agent calcule une valence attendue pour chaque interaction proposée puis une valence attendue aggrégée par décision.\n",
    "\n",
    "La valence attendue $\\mathbb{E}(V_d)$ est calculée en fonction de la valence $v_i$ de chaque interaction $i$ pouvant résulter de la décision $d$ et leurs probabilités d'être enactée $p(i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957e7b6-d560-4e4e-a8bf-0a7b62817a7a",
   "metadata": {},
   "source": [
    "# Implémentons l'agent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a74e6d-2479-4dae-8eea-b480efe84fb8",
   "metadata": {},
   "source": [
    "La méthode `learn()` est modifiée pour apprendre l'interaction composite faite de deux interactions composites de plus bas niveau. \n",
    "\n",
    "Les méthodes `create_proposed_df()` et `aggregate_propositions()` sont modifiées pour que le champ `intended` contienne la première interaction primitive de la décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "bf545ea9-a6b5-4c2a-8179-4145894e26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize our agent \"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._composite_interactions = {}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "        self._last_interaction = None\n",
    "        self._previous_interaction = None\n",
    "        self._penultimate_interaction = None\n",
    "        self._last_composite_interaction = None\n",
    "        self._previous_composite_interaction = None\n",
    "        self._penultimate_composite_interaction = None\n",
    "        # Create a dataframe of default primitive interactions\n",
    "        default_interactions = [interaction for interaction in _interactions if interaction.get_outcome() == 0]\n",
    "        data = {'activated': [np.nan] * len(default_interactions),\n",
    "                'weight': [0] * len(default_interactions),\n",
    "                'action': [i.get_primitive_action() for i in default_interactions],\n",
    "                'intention': [i.key() for i in default_interactions],\n",
    "                'valence': [i.get_valence() for i in default_interactions],\n",
    "                'decision': [i.get_decision() for i in default_interactions],\n",
    "                'proclivity': [0] * len(default_interactions), \n",
    "                'length': [1] * len(default_interactions),\n",
    "                'primitive': [i.key() for i in default_interactions]}\n",
    "        self.primitive_df = pd.DataFrame(data)\n",
    "        # Store the selection dataframe as a class attribute so we can display it in the notebook\n",
    "        self.proposed_df = None\n",
    "\n",
    "        # Manage composite intended interactions\n",
    "        self.primitive_intended_interaction = self._intended_interaction\n",
    "        self.interaction_step = 0\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Implement the agent's policy\"\"\"\n",
    "        # Memorize the context\n",
    "        self._penultimate_composite_interaction = self._previous_composite_interaction\n",
    "        self._previous_composite_interaction = self._last_composite_interaction\n",
    "        self._penultimate_interaction = self._previous_interaction\n",
    "        self._previous_interaction = self._last_interaction\n",
    "        self._last_interaction = self._interactions[f\"{self.primitive_intended_interaction.get_action()}{_outcome}\"]\n",
    "\n",
    "        # tracing the previous cycle\n",
    "        print(\n",
    "            f\"Action: {self.primitive_intended_interaction.get_action()}, Prediction: {self.primitive_intended_interaction.get_outcome()}, \"\n",
    "            f\"Outcome: {_outcome}, Prediction_correct: {self.primitive_intended_interaction.get_outcome() == _outcome}, \"\n",
    "            f\"Valence: {self._last_interaction.get_valence()}\")\n",
    "\n",
    "        # Call the learning mechanism\n",
    "        self.learn()\n",
    "\n",
    "        if self.interaction_step == 1 and self.primitive_intended_interaction == self._last_interaction:\n",
    "            # Continue the composite interaction\n",
    "            self.interaction_step = 0\n",
    "            self.primitive_intended_interaction = self._intended_interaction.post_interaction\n",
    "            return self._intended_interaction.post_interaction.get_action()\n",
    "\n",
    "        else:\n",
    "            # Create the proposed dataframe\n",
    "            self.create_proposed_df()\n",
    "            self.aggregate_propositions()\n",
    "    \n",
    "            # Select the intended primitive interaction\n",
    "            self.decide()\n",
    "    \n",
    "            if isinstance(self._intended_interaction, Interaction):\n",
    "                self.interaction_step = 0\n",
    "                self.primitive_intended_interaction = self._intended_interaction\n",
    "                return self._intended_interaction.get_action()\n",
    "            else:\n",
    "                self.interaction_step = 1\n",
    "                self.primitive_intended_interaction = self._intended_interaction.pre_interaction\n",
    "                return self._intended_interaction.pre_interaction.get_action()\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"Learn the composite interactions\"\"\"\n",
    "        # First level of composite interactions\n",
    "        self._last_composite_interaction = self.learn_composite_interaction(self._previous_interaction,\n",
    "                                                                            self._last_interaction)\n",
    "        # Second level of composite interactions\n",
    "        self.learn_composite_interaction(self._previous_composite_interaction, self._last_interaction)\n",
    "        self.learn_composite_interaction(self._penultimate_interaction, self._last_composite_interaction)\n",
    "\n",
    "        # Higher level composite interaction made of two composite interactions\n",
    "        if self._last_composite_interaction is not None:\n",
    "            self.learn_composite_interaction(self._penultimate_composite_interaction, self._last_composite_interaction)\n",
    "\n",
    "    \n",
    "    def learn_composite_interaction(self, pre_interaction, post_interaction):\n",
    "        \"\"\"Record or reinforce the composite interaction made of (pre_interaction, post_interaction)\"\"\"\n",
    "        if pre_interaction is None:\n",
    "            return None\n",
    "        else:\n",
    "            # If the pre interaction exist\n",
    "            composite_interaction = CompositeInteraction(pre_interaction, post_interaction)\n",
    "            if composite_interaction.key() not in self._composite_interactions:\n",
    "                # Add the composite interaction to memory\n",
    "                self._composite_interactions[composite_interaction.key()] = composite_interaction\n",
    "                print(f\"Learning {composite_interaction}\")\n",
    "                return composite_interaction\n",
    "            else:\n",
    "                # Reinforce the existing composite interaction and return it\n",
    "                self._composite_interactions[composite_interaction.key()].reinforce()\n",
    "                print(f\"Reinforcing {self._composite_interactions[composite_interaction.key()]}\")\n",
    "                return self._composite_interactions[composite_interaction.key()]\n",
    "\n",
    "    def create_proposed_df(self):\n",
    "        \"\"\"Create the proposed dataframe from the activated interactions\"\"\"\n",
    "        # The list of activated interaction that match the current context\n",
    "        activated_keys = [composite_interaction.key() for composite_interaction in\n",
    "                          self._composite_interactions.values()\n",
    "                          if composite_interaction.pre_interaction == self._last_interaction or\n",
    "                          composite_interaction.pre_interaction == self._last_composite_interaction]\n",
    "        data = {'activated': activated_keys,\n",
    "                'weight': [self._composite_interactions[k].weight for k in activated_keys],\n",
    "                'action': [self._composite_interactions[k].post_interaction.get_primitive_action() for k in activated_keys],\n",
    "                'intention': [self._composite_interactions[k].post_interaction.key() for k in activated_keys],\n",
    "                'valence': [self._composite_interactions[k].post_interaction.get_valence() for k in activated_keys],\n",
    "                'decision': [self._composite_interactions[k].post_interaction.get_decision() for k in activated_keys],\n",
    "                'primitive': [self._composite_interactions[k].post_interaction.pre_key() for k in activated_keys],  # <-- MODIFIED\n",
    "                'length': [self._composite_interactions[k].post_interaction.get_length() for k in activated_keys],\n",
    "                }\n",
    "        activated_df = pd.DataFrame(data)\n",
    "\n",
    "        # Create the selection dataframe from the primitive and the activated dataframes\n",
    "        self.proposed_df = pd.concat([self.primitive_df, activated_df], ignore_index=True)\n",
    "\n",
    "        # Compute the proclivity for each proposition\n",
    "        self.proposed_df['proclivity'] = self.proposed_df['weight'] * self.proposed_df['valence']\n",
    "\n",
    "    def aggregate_propositions(self):\n",
    "        \"\"\"Aggregate the proclivity\"\"\"\n",
    "        # Compute the proclivity for each action\n",
    "        grouped_df = self.proposed_df.groupby('decision').agg({'proclivity': 'sum'}).reset_index()\n",
    "        self.proposed_df = self.proposed_df.merge(grouped_df, on='decision', suffixes=('', '_agg'))\n",
    "        # Sort by descending order of proclivity\n",
    "        self.proposed_df = self.proposed_df.sort_values(by=['proclivity_agg', 'decision'], ascending=[False, False])\n",
    "\n",
    "        # Find the most probable primitive interaction for each action <-- MODIFIED\n",
    "        #max_weight_df = self.proposed_df.loc[self.proposed_df.groupby('decision')['weight'].idxmax(), ['decision', 'interaction']].reset_index(\n",
    "        #    drop=True)\n",
    "        #max_weight_df.columns = ['decision', 'intended']\n",
    "        #self.proposed_df = self.proposed_df.merge(max_weight_df, on='decision')\n",
    "        \n",
    "    def decide(self):\n",
    "        \"\"\"Select the intended primitive or composite interaction from the proposed dataframe\"\"\"\n",
    "        # Find the row that has the highest proclivity\n",
    "        max_index = self.proposed_df['proclivity_agg'].idxmax()\n",
    "        # Find the intended interaction in the row that has the highest proclivity\n",
    "        intended_interaction_key = self.proposed_df.loc[max_index, ['intention']].values[0]\n",
    "        if intended_interaction_key in self._interactions:\n",
    "            self._intended_interaction = self._interactions[intended_interaction_key]\n",
    "        else:\n",
    "            self._intended_interaction = self._composite_interactions[intended_interaction_key]\n",
    "        print(\"Intention:\", self._intended_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afad0a0-b639-4168-8a62-c97a323b67e8",
   "metadata": {},
   "source": [
    "## Implémentons l'environnement SmallLoop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15624ba-33e2-4b0c-825c-6a01195d7ad6",
   "metadata": {},
   "source": [
    "On crée l'environnement Small Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "c153ef60-2a2c-4cfe-9896-92b47ba234e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from ipywidgets import Button, HBox,VBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "FORWARD = 0\n",
    "TURN_LEFT = 1\n",
    "TURN_RIGHT = 2\n",
    "FEEL_FRONT = 3\n",
    "FEEL_LEFT = 4\n",
    "FEEL_RIGHT = 5\n",
    "\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "FEELING = 2\n",
    "BUMPING = 3\n",
    "\n",
    "class SmallLoop():\n",
    "    def __init__(self, poX, poY, direction):\n",
    "        self.grid = np.array([\n",
    "            [1, 1, 1, 1, 1], \n",
    "            [1, 0, 0, 0, 1],\n",
    "            [1, 0, 1, 0, 1],\n",
    "            [1, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 1, 1]\n",
    "        ])\n",
    "        self.maze = self.grid.copy()\n",
    "        self.poX = poX\n",
    "        self.poY = poY\n",
    "        self.direction = direction\n",
    "        self.cmap = ListedColormap(['white', 'green', 'yellow', 'red'])\n",
    "        self.norm = BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], self.cmap.N)\n",
    "\n",
    "    def outcome(self, action):\n",
    "        # print('before:', self.agent_position.strPosition(), action_dcit[action])\n",
    "        self.maze[:,:] = self.grid\n",
    "        result = 0\n",
    "        \n",
    "        if action == FORWARD:  # move forward\n",
    "            # print('the action is move forward')\n",
    "            # print(str(self.position.pointX)+': '+ str(self.position.pointY)+ ' ' +self.direction, action)\n",
    "        \n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX][self.poY - 1] == 0:\n",
    "                    self.poY -= 1\n",
    "                else:\n",
    "                    self.maze[self.poX][self.poY - 1] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX + 1][self.poY] == 0:\n",
    "                    self.poX += 1\n",
    "                else:\n",
    "                    self.maze[self.poX + 1][self.poY] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX][self.poY + 1] == 0:\n",
    "                    self.poY += 1\n",
    "                else:\n",
    "                    self.maze[self.poX][self.poY + 1] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX - 1][self.poY] == 0:\n",
    "                    self.poX -= 1\n",
    "                else:\n",
    "                    self.maze[self.poX - 1][self.poY] = BUMPING\n",
    "                    result = 1\n",
    "            # print(str(self.position.pointX)+': '+ str(self.position.pointY)+ ' ' +self.direction, action)\n",
    "        elif action == TURN_RIGHT:\n",
    "            if self.direction == LEFT:\n",
    "                self.direction = UP\n",
    "            elif self.direction == DOWN:\n",
    "                self.direction = LEFT\n",
    "            elif self.direction == RIGHT:\n",
    "                self.direction = DOWN\n",
    "            elif self.direction == UP:\n",
    "                self.direction = RIGHT\n",
    "        elif action == TURN_LEFT:\n",
    "            if self.direction == LEFT:\n",
    "                self.direction = DOWN  # RIGHT  # DOWN\n",
    "            elif self.direction == DOWN:\n",
    "                self.direction = RIGHT\n",
    "            elif self.direction == RIGHT:\n",
    "                self.direction = UP  # LEFT  # UP\n",
    "            elif self.direction == UP:\n",
    "                self.direction = LEFT\n",
    "        elif action == FEEL_FRONT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "        elif action == FEEL_LEFT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "        elif action == FEEL_RIGHT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "        print(f\"Line: {self.poX}, Column: {self.poY}, direction: {self.direction}\")\n",
    "        # return self.position,\n",
    "\n",
    "        return result  \n",
    "    \n",
    "    def display(self):\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            # ax.set_xticks([])\n",
    "            # ax.set_yticks([])\n",
    "            # ax.axis('off')\n",
    "            # ax.imshow(self.maze, cmap='Greens', vmin=0, vmax=2)\n",
    "            ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "            if self.direction == LEFT:\n",
    "                # Y is column and X is line\n",
    "                plt.scatter(self.poY, self.poX, s=400, marker='<')\n",
    "            elif self.direction == DOWN:\n",
    "                plt.scatter(self.poY, self.poX, s=400, marker='v')\n",
    "            elif self.direction == RIGHT:\n",
    "                plt.scatter(self.poY, self.poX, s=400, marker='>')\n",
    "            else: # UP\n",
    "                plt.scatter(self.poY, self.poX, s=400, marker='^')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0188a-e490-4c14-b3d1-50868d0ccd3f",
   "metadata": {},
   "source": [
    "On instancie l'agent et l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "e59db638-c069-4589-ae5f-fe50f0fac89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70503002279146e8879c827e8f7b99ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciate the small loop environment\n",
    "e = SmallLoop(1, 1, 0)\n",
    "\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(0,0,5),\n",
    "    Interaction(0,1,-10),\n",
    "    Interaction(1,0,-6),\n",
    "    Interaction(1,1,-6),\n",
    "    Interaction(2,0,-6),\n",
    "    Interaction(2,1,-6),\n",
    "    Interaction(3,0,-1),\n",
    "    Interaction(3,1,-1)\n",
    "]\n",
    "a = Agent(interactions)\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display()\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6e38a590-b256-433f-a1d9-100cc7b0a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Action: 3, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: -1\n",
      "Learning (00:5, 31:-1: 1)\n",
      "Intention: 30:-1\n",
      "Line: 1, Column: 1, direction: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activated</th>\n",
       "      <th>weight</th>\n",
       "      <th>action</th>\n",
       "      <th>intention</th>\n",
       "      <th>valence</th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>length</th>\n",
       "      <th>primitive</th>\n",
       "      <th>proclivity_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>a3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>a2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>a1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activated  weight  action intention  valence decision  proclivity  length  \\\n",
       "3        NaN     0.0     3.0        30     -1.0       a3        -0.0     1.0   \n",
       "2        NaN     0.0     2.0        20     -6.0       a2        -0.0     1.0   \n",
       "1        NaN     0.0     1.0        10     -6.0       a1        -0.0     1.0   \n",
       "0        NaN     0.0     0.0        00      5.0       a0         0.0     1.0   \n",
       "\n",
       "  primitive  proclivity_agg  \n",
       "3        30             0.0  \n",
       "2        20             0.0  \n",
       "1        10             0.0  \n",
       "0        00             0.0  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step: {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "e.display()\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4087b3-8f23-497f-a6f2-7f8569a7d3d9",
   "metadata": {},
   "source": [
    "Au pas 156 la décision 00a3 est prise car elle n'est pas contre balancée par le fait que l'interaction 00 pourrait échouer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c689e-8a92-472d-9374-5ebf75be2392",
   "metadata": {},
   "source": [
    "# Calcul de la valence attendue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b1b654-9015-465d-b997-d0e662217c88",
   "metadata": {},
   "source": [
    "La valence attendue (_expected valence_) $\\mathbb{E}(V_d)$ est la somme des valence des interactions pouvant résulter de cette décision multipliées par la probabilité d'enacter chacune de ces interaction :\n",
    "\n",
    "$\\displaystyle \\mathbb{E}(V_d) = \\sum_{i \\in I_d} v_{i} \\cdot p_{i} $\n",
    "\n",
    "Dans le cas des décisions composites, nous prenons en compte :\n",
    "* Le succès: l'interaction composite anticipée (_intended composite interaction_).\n",
    "* L'échec sur la première interaction: une autre intéraction primitive a été enactée à la place de celle attendue.\n",
    "\n",
    "Nous prenons en compte les possibilités d'échec dans le calcul de la proclivité. \n",
    "Pour cela nous ajoutons les proclivité des interactions qui correspondent à des échecs à la proclivité de la décision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a9576-a41c-49fa-be0b-993533beb3bf",
   "metadata": {},
   "source": [
    "# Implémentons l'Agent9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f498a-4ec3-4e8b-bec8-b0c68ebabae9",
   "metadata": {},
   "source": [
    "Modifions l'aggrégation des décisions composites pour prendre en compte la possibilité qu'elles échouent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "e5ffbec4-36c2-4313-8bc4-d9221b8b995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent9(Agent):\n",
    "    def aggregate_propositions(self):\n",
    "        \"\"\"Aggregate the proclivity\"\"\"\n",
    "        # Aggregate the proclivity for each decision\n",
    "        grouped_df = self.proposed_df.groupby('decision').agg({'proclivity': 'sum', 'action': 'first', 'length': 'first', 'intention': 'first', 'primitive': 'first'}).reset_index()\n",
    "\n",
    "        # For each composite decision, find the proposed primitive interactions that have the same action but a different outcome \n",
    "        for index, proposition in grouped_df[grouped_df['length'] > 1].iterrows():\n",
    "            # print(f\"Index {index}, action {proposition['action']}, intended {proposition['intended']}\")\n",
    "            for _, primitive in self.proposed_df[(self.proposed_df['action'] == proposition['action']) \n",
    "                                                & (self.proposed_df['primitive'] != proposition['primitive'])\n",
    "                                                & (self.proposed_df['length'] == 1)].iterrows():\n",
    "                grouped_df.loc[index, 'proclivity'] += primitive['proclivity']\n",
    "                # print(f\"Decision {proposition['decision']} recieves {primitive['proclivity']} from failing {primitive['intended']}\")\n",
    "        \n",
    "        # Sort by descending proclivity\n",
    "        self.proposed_df = grouped_df.sort_values(by=['proclivity', 'decision'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    def decide(self):\n",
    "        \"\"\"Select the intended primitive or composite interaction from the proposed dataframe\"\"\"\n",
    "        # The intended interaction is in the first row because it has been sorted by descending proclivity\n",
    "        intended_interaction_key = self.proposed_df.loc[0, 'intention']\n",
    "        if intended_interaction_key in self._interactions:\n",
    "            self._intended_interaction = self._interactions[intended_interaction_key]\n",
    "        else:\n",
    "            self._intended_interaction = self._composite_interactions[intended_interaction_key]\n",
    "        print(\"Intention:\", self._intended_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2651201-104a-42b5-ae02-d43d6e19bb91",
   "metadata": {},
   "source": [
    "# Testons dans le small loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "0a594b3c-d3d7-476f-b608-6f71ba8a57ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c722666afafd46b8981a450d4caa19ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e = SmallLoop(1, 1, 0)\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(0,0,5),\n",
    "    Interaction(0,1,-10),\n",
    "    Interaction(1,0,-3),\n",
    "    Interaction(1,1,-3),\n",
    "    Interaction(2,0,-3),\n",
    "    Interaction(2,1,-3),\n",
    "    Interaction(3,0,-1),\n",
    "    Interaction(3,1,-1)\n",
    "]\n",
    "a = Agent9(interactions)\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display()\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "135f3fe6-f989-4a0d-8444-bdb4236e55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 47\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -3\n",
      "Reinforcing (31:-1, 10:-3: 5)\n",
      "Reinforcing ((00:5, 31:-1: 6), 10:-3: 5)\n",
      "Reinforcing (00:5, (31:-1, 10:-3: 5): 5)\n",
      "Reinforcing ((30:-1, 00:5: 5), (31:-1, 10:-3: 5): 5)\n",
      "Line: 2, Column: 1, direction: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>action</th>\n",
       "      <th>length</th>\n",
       "      <th>intention</th>\n",
       "      <th>primitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10a0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(10,00)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a0</td>\n",
       "      <td>-20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>-24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01a1</td>\n",
       "      <td>-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(01,10)</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  decision  proclivity  action  length intention primitive\n",
       "0     10a0          16       1       2   (10,00)        10\n",
       "1       a2           0       2       1        20        20\n",
       "2       a3           0       3       1        30        30\n",
       "3       a0         -20       0       1        00        00\n",
       "4       a1         -24       1       1        10        10\n",
       "5     01a1         -26       0       2   (01,10)        01"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step: {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "e.display()\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e16b06-6cd3-4656-9a07-452b846c01af",
   "metadata": {},
   "source": [
    "A partir du pas 25, l'agent apprend à toucher devant et ne pas avancer s'il touche un mur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9e108-92f2-4c75-96c7-6ecacf9851b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
