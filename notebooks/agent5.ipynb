{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f34084-d4b8-4160-89ad-a927a0919615",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/notebooks/agent5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# THE AGENT WHO CHANGED HIS MIND"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "Upon completing this lab, you will be able to implement a developmental agent that reinforces simple behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "## Define the Interaction class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44155c4a-d038-40b3-be33-e8cf77c5f976",
   "metadata": {},
   "source": [
    "Let's use the same interaction class as Agent4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e96c3637-4161-49aa-9f1d-0d3342de92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, action, outcome, valence):\n",
    "        self.action = action\n",
    "        self.outcome = outcome\n",
    "        self.valence = valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self.action}{self.outcome}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self.action}{self.outcome}:{self.valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        return self.key() == other.key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152512a3-ef97-473a-91a7-9a36fe70ba33",
   "metadata": {},
   "source": [
    "## Define the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b81c3-5671-4ec6-bb7d-9db4f99c7c0b",
   "metadata": {},
   "source": [
    "The agent is initialized with the list of interactions \n",
    "\n",
    "On a new step _t+1_:\n",
    "* The interaction enacted on step _t_ is memorized in `self._last_interaction`\n",
    "* The interaction enacted on step _t-1_ is memorized in `self._previous_interaction`\n",
    "* The intended interaction `(selected action, predicted outcome)` is memorized in `self._intended_interaction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f0bf369-48ef-48d7-a92b-3c7ef8dc1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"Creating our agent\"\"\"\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize the dictionary of interactions\"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "        self._last_interaction = None\n",
    "        self._previous_interaction = None\n",
    "\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\" Tracing the previous cycle \"\"\"\n",
    "        self._previous_interaction = self._last_interaction\n",
    "        self._last_interaction = self._interactions[f\"{self._intended_interaction.action}{_outcome}\"]\n",
    "        print(f\"Action: {self._intended_interaction.action}, Prediction: {self._intended_interaction.outcome}, \"\n",
    "              f\"Outcome: {_outcome}, Prediction_correct: {self._intended_interaction.outcome == _outcome}, \"\n",
    "              f\"Valence: {self._last_interaction.valence})\")\n",
    "\n",
    "        \"\"\" Computing the next interaction to try to enact \"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        intended_action = 0\n",
    "        # TODO: Implement the agent's prediction mechanism\n",
    "        intended_outcome = 0\n",
    "        # Memorize the intended interaction\n",
    "        self._last_interaction = self._interactions[f\"{intended_action}{intended_outcome}\"]\n",
    "        return intended_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1c38f-c8ed-48e5-bc6a-e7078ed3e5e4",
   "metadata": {},
   "source": [
    "## Environment1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d65ca61-9386-4260-a406-ec766063569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \"\"\" In Environment 1, action 0 yields outcome 0, action 1 yields outcome 1 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        if _action == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d7d6-5444-4778-b97a-cc5bd34c6cd2",
   "metadata": {},
   "source": [
    "## Environment2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91ae8fba-72aa-4194-be5a-2f27a1637e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment2:\n",
    "    \"\"\" In Environment 2, action 0 yields outcome 1, action 1 yields outcome 0 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        if _action == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab7280-a559-4fc2-8668-4285aac82d8d",
   "metadata": {},
   "source": [
    "## Environment3 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df2375-680e-4df9-a0ed-e84802aac1a4",
   "metadata": {},
   "source": [
    "Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5bf9a4ba-2703-49e9-a63f-b72c08b8663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment3:\n",
    "    \"\"\" Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment3 \"\"\"\n",
    "        self.previous_action = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        if _action == self.previous_action:\n",
    "            _outcome = 0\n",
    "        else:\n",
    "            _outcome = 1\n",
    "        self.previous_action = _action\n",
    "        return _outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372722d3-e6a3-4fb1-8c65-d58d6b825a17",
   "metadata": {},
   "source": [
    "## Environment4 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553bc09f-31b0-4577-b153-6fe98225c892",
   "metadata": {},
   "source": [
    "Environment4 behaves like Environment1 during the first 10 cycles and then like Environment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf9630d4-7e78-450b-8940-463e2cd2f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment4:\n",
    "    \"\"\" Environm4 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment4 \"\"\"\n",
    "        self.step = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        \"\"\"Take the action and generate the next outcome \"\"\"\n",
    "        self.step += 1\n",
    "        # Behave like environment1 during the first 10 steps\n",
    "        if self.step < 10:\n",
    "            if _action == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1            \n",
    "        # Behave like Environment2 after the first 10 steps\n",
    "        else: \n",
    "            if _action == 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f49f7-9352-4938-9ee2-7d8a7bb5065a",
   "metadata": {},
   "source": [
    "## Initialize the interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59da5f51-d5db-4cf4-8bd0-036ec11eaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1),\n",
    "    Interaction(2,0,-1),\n",
    "    Interaction(2,1,1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d25cea-a183-45c5-a624-1345aace245a",
   "metadata": {},
   "source": [
    "Interactions are initialized with their action, their outcome, and their valence:\n",
    "\n",
    "|| outcome 0 | outcome 1|\n",
    "|---|---|---|\n",
    "| action 0| -1 | 1 |\n",
    "| action 1 | -1 | 1 |\n",
    "| action 2 | -1 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095ec84-3fcd-455c-bb3b-f9a72980048e",
   "metadata": {},
   "source": [
    "## Instantiate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33066d34-7f06-4b38-97b8-d7d5adbb237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16279c4-936b-4f37-a0c9-ca4b77609adf",
   "metadata": {},
   "source": [
    "## Instantiate the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17b3c8c8-0cbd-4f64-a97c-61519ad24dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ce510-9438-47d1-ac88-ab79c063d592",
   "metadata": {},
   "source": [
    "## Test run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f6d76df-89e4-4ab3-a327-afa813a27325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n"
     ]
    }
   ],
   "source": [
    "outcome = 0\n",
    "for i in range(30):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019f138-a218-44b2-964a-8095fbe891a7",
   "metadata": {},
   "source": [
    "# PRELIMINARY EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daa278-434e-43ce-8520-8fabef69cd83",
   "metadata": {},
   "source": [
    "Run your Agent4 in Environment4.\n",
    "\n",
    "Depending on how you designed it, it may not be able to re-adapt after Environment4 changes on step 10. \n",
    "Let's design Agent5 that can readapt!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50d96e-4f12-4531-a122-9d13d8bd8639",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199faee9-a546-4d86-8e09-484bf2212523",
   "metadata": {},
   "source": [
    "Implement Agent5 that obtains positive valences in either Environment 1, 2, 3, and that can adapt to Environment 4 and then readapt after 10 more steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ac5e5-e466-495f-93af-54ebc7ad8548",
   "metadata": {},
   "source": [
    "Now we call *primitive interaction* a tuple `(action, outcome)`.\n",
    "We call *composite interaction* a sequence of two primitive interactions: `composite_intreaction = (pre_interaction, post_interaction)`.\n",
    "\n",
    "Composite interactions are used to store the sequences of the last two enacted interactions.\n",
    "They have a weight that counts the number of times that this sequence has been enacted. \n",
    "\n",
    "When computing the prediction, the agent uses the weight of the activated composite interactions to predict the most likely outcome for each possible action in a given context as shown in Figure 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e95995-8077-46ed-a03d-e318623cb82b",
   "metadata": {},
   "source": [
    "![Agent5](img/Figure_1_Agent5.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742aecbc-5e94-4cc6-bf5d-1b6c12bde814",
   "metadata": {},
   "source": [
    "Figure 1: Agent5 records and reinforces composite interactions as tuples $(i_{t-2}, i_{t-1}: weight)$. The last enacted interaction $i_{t-1}$ activates previously-learned composite interactions that propose the action of their post interaction.\n",
    "\n",
    "The proclivity $proclivity_a$ is computed for each action $a$ according to the formula: \n",
    "\n",
    "$\\displaystyle proclivity_a = \\sum_{c \\in A} w_c \\cdot v_{post(c)}$\n",
    "\n",
    "in which $A$ is the set of activated composite interactions that propose action $a$, $w_a$ is the weight of composite interaction $c$, $v_{post(c)}$ is the valence of the post interaction of $c$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc277cf-6b7f-415c-8438-3206ea8bb5d4",
   "metadata": {},
   "source": [
    "## Let's define the class CompositeInteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "125be7be-0646-4fd2-b42f-0b962954ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeInteraction:\n",
    "    \"\"\"A composite interaction is a tuple (pre_interaction, post_interaction) and a weight\"\"\"\n",
    "    def __init__(self, pre_interaction, post_interaction):\n",
    "        self.pre_interaction = pre_interaction\n",
    "        self.post_interaction = post_interaction\n",
    "        self.weight = 1\n",
    "\n",
    "    def reinforce(self):\n",
    "        \"\"\"Increment the composite interaction's weight\"\"\"\n",
    "        self.weight += 1\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string '<pre_interaction><post_interaction>'. \"\"\"\n",
    "        return f\"{self.pre_interaction}{self.post_interaction}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print the interaction in the Newick tree format (pre_interaction, post_interaction: valence) \"\"\"\n",
    "        return f\"({self.pre_interaction}, {self.post_interaction})\"\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\" The hash is necessary to use interactions as keys in a dictionary \"\"\"\n",
    "        return self.key()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Composite interactions are equal if they have the same pre and post interactions \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return (self.pre_interaction == other.pre_interaction) and (self.post_interaction == other.post_interaction)\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b9a28-121c-4379-8701-1d49ad197b8d",
   "metadata": {},
   "source": [
    "## Create Agent5 by overriding the class Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9ba2b-8129-4bf7-82dc-074803f95bdf",
   "metadata": {},
   "source": [
    "You may add any attribute and method you deem usefull to the class Agent5.\n",
    "\n",
    "When selecting the next action, Agent5 must take into account the likelyhood of each possible outcome and the valence of the predicted resulting interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85b966d4-aca5-4a08-8413-d4906fdbbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent5(Agent):\n",
    "    pass\n",
    "    # TODO override the method action(self, _outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b3f5c-f48c-45ad-bf1d-4a703bac64af",
   "metadata": {},
   "source": [
    "## Test your Agent5 in Environment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8025780-7d39-442d-9600-b40641e6d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent5(interactions)\n",
    "e = Environment1()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02f401-3a78-4ced-9b8c-3b602c7be482",
   "metadata": {},
   "source": [
    "## Test your Agent5 in Environment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925fb5f1-1eb6-4dee-a59b-fd6384e123d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent5(interactions)\n",
    "e = Environment2()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ebe13-605e-4068-ab57-06416f898790",
   "metadata": {},
   "source": [
    "## Test your Agent5 in Environment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835595f7-512e-46aa-b140-3e2b6c43eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent5(interactions)\n",
    "e = Environment3()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc2539-8682-4ad2-9840-e5a4a51c0630",
   "metadata": {},
   "source": [
    "## Test your Agent5 in Environment4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb0749-f161-464e-b8dc-255b7b098045",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent5(interactions)\n",
    "e = Environment4()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc8226-b4ac-49c7-b1a8-9b17adc19964",
   "metadata": {},
   "source": [
    "## Test your Agent5 with interactions that have other valences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01175431-ead3-480e-b8e3-e20ee9321379",
   "metadata": {},
   "source": [
    "Replace the valences of interactions with your choice in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdfd38-0d4e-48a3-ab0f-87177c2da97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose different valence of interactions\n",
    "interactions = [\n",
    "    Interaction(0,0,1),\n",
    "    Interaction(0,1,0),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1),\n",
    "    Interaction(2,0,-1),\n",
    "    Interaction(2,1,1)\n",
    "]\n",
    "# Run the agent\n",
    "a = Agent5(interactions)\n",
    "e = Environment4()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1c321-c33f-497e-8219-a0904ab6ebab",
   "metadata": {},
   "source": [
    "## Test your agent in the Turtle environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71630824-e023-49b7-a143-6ffccae07209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install the turtle environment\n",
    "!pip3 install ColabTurtle\n",
    "from ColabTurtle.Turtle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35913a4-4426-4e50-ba74-6790e579fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Initialize the turtle environment\n",
    "\n",
    "BORDER_WIDTH = 20\n",
    "\n",
    "class ColabTurtleEnvironment:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Creating the Turtle window \"\"\"\n",
    "        bgcolor(\"lightGray\")\n",
    "        penup()\n",
    "        goto(window_width() / 2, window_height()/2)\n",
    "        face(0)\n",
    "        pendown()\n",
    "        color(\"green\")\n",
    "\n",
    "    def outcome(self, action):\n",
    "        \"\"\" Enacting an action and returning the outcome \"\"\"\n",
    "        _outcome = 0\n",
    "        for i in range(10):\n",
    "            # _outcome = 0\n",
    "            if action == 0:\n",
    "                # move forward\n",
    "                forward(10)\n",
    "            elif action == 1:\n",
    "                # rotate left\n",
    "                left(4)\n",
    "                forward(2)\n",
    "            elif action == 2:\n",
    "                # rotate right\n",
    "                right(4)\n",
    "                forward(2)\n",
    "\n",
    "            # Bump on screen edge and return outcome 1\n",
    "            if xcor() < BORDER_WIDTH:\n",
    "                goto(BORDER_WIDTH, ycor())\n",
    "                _outcome = 1\n",
    "            if xcor() > window_width() - BORDER_WIDTH:\n",
    "                goto(window_width() - BORDER_WIDTH, ycor())\n",
    "                _outcome = 1\n",
    "            if ycor() < BORDER_WIDTH:\n",
    "                goto(xcor(), BORDER_WIDTH)\n",
    "                _outcome = 1\n",
    "            if ycor() > window_height() - BORDER_WIDTH:\n",
    "                goto(xcor(), window_height() -BORDER_WIDTH)\n",
    "                _outcome = 1\n",
    "\n",
    "            # Change color\n",
    "            if _outcome == 0:\n",
    "                color(\"green\")\n",
    "            else:\n",
    "                # Finit l'interaction\n",
    "                color(\"red\")\n",
    "                # if action == 0:\n",
    "                #     break\n",
    "                if action == 1:\n",
    "                    for j in range(10):\n",
    "                        left(4)\n",
    "                elif action == 2:\n",
    "                    for j in range(10):\n",
    "                        right(4)\n",
    "                break\n",
    "\n",
    "        return _outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4b183-a761-47c8-a3a5-957467dd5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run the turtle environment\n",
    "initializeTurtle()\n",
    "\n",
    "# Parameterize the rendering\n",
    "bgcolor(\"lightGray\")\n",
    "penup()\n",
    "goto(window_width() / 2, window_height()/2)\n",
    "face(0)\n",
    "pendown()\n",
    "color(\"green\")\n",
    "speed(10)\n",
    "\n",
    "# Some valences to avoid bumping into walls\n",
    "interactions = [\n",
    "    Interaction(0,0,3),\n",
    "    Interaction(0,1,-3),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,-1),\n",
    "    Interaction(2,0,-2),\n",
    "    Interaction(2,1,-2)\n",
    "]\n",
    "\n",
    "a = Agent5(interactions)\n",
    "e = ColabTurtleEnvironment()\n",
    "\n",
    "outcome = 0\n",
    "for i in range(50):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15a134-34a6-4039-9b43-f8fd76d93b5e",
   "metadata": {},
   "source": [
    "## Report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e661c15-c1ed-4512-a1d9-0fbdb8f91879",
   "metadata": {},
   "source": [
    "Explain what you programmed and what results you observed. Export this document as PDF including your code, the traces you obtained, and your explanations below (no more than a few paragraphs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc0899-eee2-404a-baf6-47741067e7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
