{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f34084-d4b8-4160-89ad-a927a0919615",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/notebooks/agent10.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# AGENT 10 SMELL (En construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Objectifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "L'objectif de ce notebook est d'expérimenter l'impact des valences associées aux intéractions sur le comportements de l'agent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957e7b6-d560-4e4e-a8bf-0a7b62817a7a",
   "metadata": {},
   "source": [
    "# Implémentons l'agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3243d6-1de3-418e-9236-8af0287131da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CompositeInteraction:\n",
    "    \"\"\"A composite interaction is a tuple (pre_interaction, post_interaction) and a weight\"\"\"\n",
    "    def __init__(self, pre_interaction, post_interaction):\n",
    "        self.pre_interaction = pre_interaction\n",
    "        self.post_interaction = post_interaction\n",
    "        self.weight = 1\n",
    "        self._step = 1\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the flatten sequence of intermediary primitive interactions terminated with the final decision\"\"\"\n",
    "        return f\"{self.pre_interaction.sequence()}{self.post_interaction.get_decision()}\"\n",
    "\n",
    "    def get_actions(self):\n",
    "        \"\"\"Return the flat sequence of the decisions of this interaction as a string\"\"\"\n",
    "        return f\"{self.pre_interaction.get_actions()}{self.post_interaction.get_actions()}\"\n",
    "    \n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the primite action\"\"\"\n",
    "        return self.pre_interaction.get_primitive_action()\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the valence of the pre_interaction plus the valence of the post_interaction\"\"\"\n",
    "        return self.pre_interaction.get_valence() + self.post_interaction.get_valence()\n",
    "\n",
    "    def reinforce(self):\n",
    "        \"\"\"Increment the composite interaction's weight\"\"\"\n",
    "        self.weight += 1\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string '<pre_interaction><post_interaction>'. \"\"\"\n",
    "        return f\"({self.pre_interaction.key()},{self.post_interaction.key()})\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key of the pre_interaction\"\"\"\n",
    "        return self.pre_interaction.pre_key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print the interaction in the Newick tree format (pre_interaction, post_interaction: valence) \"\"\"\n",
    "        return f\"({self.pre_interaction}, {self.post_interaction}: {self.weight})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same pre and post interactions \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return (self.pre_interaction == other.pre_interaction) and (self.post_interaction == other.post_interaction)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"Return the length of the number of primitive interactions in this composite interaction\"\"\"\n",
    "        return self.pre_interaction.get_length() + self.post_interaction.get_length()\n",
    "\n",
    "    def increment(self, interaction, interactions):\n",
    "        \"\"\"Increment the step of the appropriate sub-interaction. Return the enacted interaction if it is over, or None if it is ongoing.\"\"\"\n",
    "        # First step \n",
    "        if self._step == 1:\n",
    "            interaction = self.pre_interaction.increment(interaction, interactions)\n",
    "            # Ongoing pre-interaction. Return None\n",
    "            if interaction is None:\n",
    "                return None\n",
    "            # Pre-interaction succeeded. Increment the step and return None\n",
    "            elif interaction == self.pre_interaction:\n",
    "                self._step = 2\n",
    "                return None\n",
    "            # Pre-interaction failed. Reset the step and return the enacted interaction\n",
    "            else:\n",
    "                self._step = 1\n",
    "                return interaction\n",
    "        # Second step\n",
    "        else:\n",
    "            interaction = self.post_interaction.increment(interaction, interactions)\n",
    "            # Ongoing post-interaction. Return None\n",
    "            if interaction is None:\n",
    "                return None\n",
    "            # Post-interaction succeeded. Reset the step and return this interaction\n",
    "            elif interaction == self.post_interaction:\n",
    "                self._step = 1\n",
    "                return self\n",
    "            # Post-interaction failed. Reset the step and return the enacted interaction\n",
    "            else:\n",
    "                self._step = 1\n",
    "                composite_interaction = CompositeInteraction(self.pre_interaction, interaction)\n",
    "                if composite_interaction.key() not in interactions:\n",
    "                    # Add the enacted composite interaction to memory\n",
    "                    interactions[composite_interaction.key()] = composite_interaction\n",
    "                    print(f\"Learning {composite_interaction}\")\n",
    "                    return composite_interaction\n",
    "                else:\n",
    "                    # Reinforce the existing composite interaction and return it\n",
    "                    interactions[composite_interaction.key()].reinforce()\n",
    "                    #print(f\"Reinforcing {interactions[composite_interaction.key()]}\")\n",
    "                    return interactions[composite_interaction.key()]\n",
    "\n",
    "    def current(self):\n",
    "        \"\"\"Return the current intended primitive interaction\"\"\"\n",
    "        # Step 1: the current primitive interaction of the pre-interaction\n",
    "        if self._step == 1:\n",
    "            return self.pre_interaction.current()\n",
    "        # Step 2: The current primitive interaction of the post-interaction\n",
    "        else:\n",
    "            return self.post_interaction.current()\n",
    "\n",
    "    def sequence(self):\n",
    "        \"\"\"Return the flat sequence of primitive interactions of this composite interaction\"\"\"\n",
    "        return f\"{self.pre_interaction.sequence()}{self.post_interaction.sequence()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7fd8bc-9dee-4aef-a217-3ed77844e2f2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, _action, _outcome, _valence):\n",
    "        self._action = _action\n",
    "        self._outcome = _outcome\n",
    "        self._valence = _valence\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_actions(self):\n",
    "        \"\"\"Return the action as a string for compatibilty with CompositeInteraction\"\"\"\n",
    "        return str(self._action)\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the decision key\"\"\"\n",
    "        return f\"{self._action}\"\n",
    "        # return f\"a{self._action}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the action for compatibility with CompositeInteraction\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_outcome(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._outcome\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self._action}{self._outcome}\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key. Used for compatibility with CompositeInteraction\"\"\"\n",
    "        return self.key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self._action}{self._outcome}:{self._valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"The length of the sequence of this interaction\"\"\"\n",
    "        return 1\n",
    "\n",
    "    def increment(self, interaction, interactions):\n",
    "        \"\"\"Return the enacted interaction for compatibility with composite interactions\"\"\"\n",
    "        return interaction\n",
    "\n",
    "    def current(self):\n",
    "        \"\"\"Return itself for compatibility with composite interactions\"\"\"\n",
    "        return self\n",
    "\n",
    "    def sequence(self):\n",
    "        \"\"\"Return the key. Use for compatibility with composite interactions\"\"\"\n",
    "        return self.key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf545ea9-a6b5-4c2a-8179-4145894e26a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize our agent \"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._primitive_intended_interaction = self._interactions[\"00\"]\n",
    "        self._intended_interaction = None\n",
    "\n",
    "        # The context\n",
    "        self._penultimate_interaction = None\n",
    "        self._previous_interaction = None\n",
    "        self._last_interaction = None\n",
    "        self._penultimate_composite_interaction = None\n",
    "        self._previous_composite_interaction = None\n",
    "        self._last_composite_interaction = None\n",
    "        \n",
    "        # Prepare the dataframe of proposed interactions\n",
    "        default_interactions = [interaction for interaction in _interactions if interaction.get_outcome() == 0]\n",
    "        data = {'activated': [\"\"] * len(default_interactions),\n",
    "                'weight': [0] * len(default_interactions),\n",
    "                'action': [i.get_action() for i in default_interactions],\n",
    "                'actions': [i.get_actions() for i in default_interactions],\n",
    "                'intention': [i.key() for i in default_interactions],\n",
    "                'valence': [i.get_valence() for i in default_interactions],\n",
    "                'decision': [i.get_decision() for i in default_interactions],\n",
    "                'length': [1] * len(default_interactions),\n",
    "                'primitive': [i.key() for i in default_interactions]}\n",
    "        self._default_df = pd.DataFrame(data)\n",
    "        self.proposed_df = None\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Implement the agent's policy\"\"\"\n",
    "\n",
    "        # Trace the previous cycle\n",
    "        primitive_enacted_interaction = self._interactions[f\"{self._primitive_intended_interaction.get_action()}{_outcome}\"]\n",
    "        print(\n",
    "           f\"Action: {self._primitive_intended_interaction.get_action()}, Prediction: {self._primitive_intended_interaction.get_outcome()}, \"\n",
    "           f\"Outcome: {_outcome}, Prediction_correct: {self._primitive_intended_interaction.get_outcome() == _outcome}, \"\n",
    "           f\"Valence: {primitive_enacted_interaction.get_valence()}\")\n",
    "\n",
    "        # Follow up the enaction\n",
    "        if self._intended_interaction is None: # First interaction cycle\n",
    "            enacted_interaction = primitive_enacted_interaction\n",
    "        else:\n",
    "            enacted_interaction = self._intended_interaction.increment(primitive_enacted_interaction, self._interactions)\n",
    "\n",
    "        # If the intended interaction is over (completely enacted or aborted)\n",
    "        if enacted_interaction is not None:\n",
    "            # Memorize the context\n",
    "            self._penultimate_composite_interaction = self._previous_composite_interaction\n",
    "            self._previous_composite_interaction = self._last_composite_interaction\n",
    "            self._penultimate_interaction = self._previous_interaction\n",
    "            self._previous_interaction = self._last_interaction\n",
    "            self._last_interaction = enacted_interaction\n",
    "            # Call the learning mechanism\n",
    "            self.learn(enacted_interaction)\n",
    "            # Create the proposed dataframe\n",
    "            self.create_proposed_df()\n",
    "            self.aggregate_propositions()\n",
    "            # Decide the next enaction\n",
    "            self.decide()\n",
    "\n",
    "        # Return the next primitive action\n",
    "        self._primitive_intended_interaction = self._intended_interaction.current()\n",
    "        return self._primitive_intended_interaction.get_action()\n",
    "        \n",
    "    def learn(self, enacted_interaction):\n",
    "        \"\"\"Learn the composite interactions\"\"\"\n",
    "        # First level of composite interactions\n",
    "        self._last_composite_interaction = self.learn_composite_interaction(self._previous_interaction, enacted_interaction)\n",
    "        # Second level of composite interactions\n",
    "        self.learn_composite_interaction(self._previous_composite_interaction, enacted_interaction)\n",
    "        self.learn_composite_interaction(self._penultimate_interaction, self._last_composite_interaction)\n",
    "\n",
    "        # Higher level composite interaction made of two composite interactions\n",
    "        if self._last_composite_interaction is not None:\n",
    "            self.learn_composite_interaction(self._penultimate_composite_interaction, self._last_composite_interaction)\n",
    "\n",
    "    \n",
    "    def learn_composite_interaction(self, pre_interaction, post_interaction):\n",
    "        \"\"\"Record or reinforce the composite interaction made of (pre_interaction, post_interaction)\"\"\"\n",
    "        if pre_interaction is None:\n",
    "            return None\n",
    "        else:\n",
    "            # If the pre-interaction exists\n",
    "            composite_interaction = CompositeInteraction(pre_interaction, post_interaction)\n",
    "            if composite_interaction.key() not in self._interactions:\n",
    "                # Add the composite interaction to memory\n",
    "                self._interactions[composite_interaction.key()] = composite_interaction\n",
    "                # print(f\"Learning {composite_interaction}\")\n",
    "                return composite_interaction\n",
    "            else:\n",
    "                # Reinforce the existing composite interaction and return it\n",
    "                self._interactions[composite_interaction.key()].reinforce()\n",
    "                # print(f\"Reinforcing {self._interactions[composite_interaction.key()]}\")\n",
    "                return self._interactions[composite_interaction.key()]\n",
    "\n",
    "    def create_proposed_df(self):\n",
    "        \"\"\"Create the proposed dataframe from the activated interactions\"\"\"\n",
    "        # The list of activated interaction that match the current context\n",
    "        activated_keys = [composite_interaction.key() for composite_interaction in\n",
    "                          self._interactions.values()\n",
    "                          if composite_interaction.get_length() > 1 and\n",
    "                          (composite_interaction.pre_interaction == self._last_interaction or\n",
    "                          composite_interaction.pre_interaction == self._last_composite_interaction)]\n",
    "        data = {'activated': activated_keys,\n",
    "                'weight': [self._interactions[k].weight for k in activated_keys],\n",
    "                'action': [self._interactions[k].post_interaction.get_primitive_action() for k in activated_keys],\n",
    "                'actions': [self._interactions[k].post_interaction.get_actions() for k in activated_keys],\n",
    "                'intention': [self._interactions[k].post_interaction.key() for k in activated_keys],\n",
    "                'valence': [self._interactions[k].post_interaction.get_valence() for k in activated_keys],\n",
    "                'decision': [self._interactions[k].post_interaction.get_decision() for k in activated_keys],\n",
    "                'primitive': [self._interactions[k].post_interaction.pre_key() for k in activated_keys],\n",
    "                'length': [self._interactions[k].post_interaction.get_length() for k in activated_keys],\n",
    "                }\n",
    "        activated_df = pd.DataFrame(data).astype(self._default_df.dtypes)  # Force the same types for the case it is empty\n",
    "\n",
    "        # Create the proposed dataframe\n",
    "        self.proposed_df = pd.concat([self._default_df, activated_df], ignore_index=True)\n",
    "\n",
    "        # Compute the proclivity for each proposition\n",
    "        self.proposed_df['proclivity'] = self.proposed_df['weight'] * self.proposed_df['valence']\n",
    "\n",
    "    def aggregate_propositions(self):\n",
    "        \"\"\"Aggregate the proclivity\"\"\"\n",
    "        # Aggregate the proclivity for each decision\n",
    "        grouped_df = self.proposed_df.groupby('decision').agg({'proclivity': 'sum', 'actions': 'first', 'action': 'first', 'length': 'first', \n",
    "                                                               'intention': 'first', 'primitive': 'first'}).reset_index()\n",
    "        # For each proposed composite decision \n",
    "        for index, proposed in grouped_df[grouped_df['length'] > 1].iterrows():\n",
    "            # print(f\"Index {index}, actions {proposition['actions']}, intention {proposition['intention']}\")\n",
    "            # Find shorter decisions that start with the same sequence \n",
    "            for _, shorter in self.proposed_df[self.proposed_df.apply(lambda row: proposed['actions'].startswith(row['actions']) \n",
    "                                                                      and row['length'] < proposed['length'], axis=1)].iterrows():\n",
    "                # Add the proclivity of the shorter decisions\n",
    "                grouped_df.loc[index, 'proclivity'] += shorter['proclivity']\n",
    "                # print(f\"Decision {proposition['decision']} recieves {shorter['proclivity']} from partial {shorter['intention']}\")\n",
    "        \n",
    "        # Sort by descending proclivity\n",
    "        self.proposed_df = grouped_df.sort_values(by=['proclivity', 'decision'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    def decide(self):\n",
    "        \"\"\"Selects the intended_interaction that at the top of the proposed dataframe\"\"\"\n",
    "        # The intended interaction is in the first row because it has been sorted by descending proclivity\n",
    "        intended_interaction_key = self.proposed_df.loc[0, 'intention']\n",
    "        # print(\"Intention:\", intended_interaction_key)\n",
    "        self._intended_interaction = self._interactions[intended_interaction_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afad0a0-b639-4168-8a62-c97a323b67e8",
   "metadata": {},
   "source": [
    "# Implémentons l'environnement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e654a53-51f5-460a-9ad5-569ac9240783",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "save_dir = \"sav\"\n",
    "\n",
    "FORWARD = 0\n",
    "TURN_LEFT = 2\n",
    "TURN_RIGHT = 1\n",
    "FEEL_FRONT = 3\n",
    "FEEL_LEFT = 4\n",
    "FEEL_RIGHT = 5\n",
    "\n",
    "STABLE = 0\n",
    "BUMP = 1\n",
    "INCREASE_LEFT = 2\n",
    "INCREASE_RIGHT = 3\n",
    "INCREASE_FRONT = 4\n",
    "DECREASE = 5\n",
    "EAT = 6\n",
    "\n",
    "agent_color = \"#1976D2\"\n",
    "colors = [\"#D6D6D6\", '#5C946E', '#FAE2DB', '#535865', \"#F93943\", \"#E365C1\"]\n",
    "\n",
    "BUMPING = 4\n",
    "TARGET = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15624ba-33e2-4b0c-825c-6a01195d7ad6",
   "metadata": {},
   "source": [
    "On crée l'environnement Smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c153ef60-2a2c-4cfe-9896-92b47ba234e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from ipywidgets import Button, HBox,VBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "# Directions\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "class Environment():\n",
    "    def __init__(self, position, direction):\n",
    "        self.grid = np.array([\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        ])\n",
    "        self.maze = self.grid.copy()\n",
    "        self.position = np.array(position)  # Using NumPy array of shape (2)\n",
    "        self.direction = direction\n",
    "        self.cmap = ListedColormap(colors)\n",
    "        self.norm = BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5], self.cmap.N)\n",
    "        self.marker_size = 400\n",
    "        self.marker_map = {LEFT: '<', DOWN: 'v', RIGHT: '>', UP: '^'}\n",
    "        self.marker_color = agent_color\n",
    "        self.directions = np.array([\n",
    "            [0, -1],  # Left\n",
    "            [1, 0],   # Down\n",
    "            [0, 1],   # Right\n",
    "            [-1, 0]   # Up\n",
    "        ])\n",
    "        self.previous_smell = 0\n",
    "        self.smell_feedback = np.array([\n",
    "            [STABLE,   INCREASE_LEFT, INCREASE_RIGHT, INCREASE_FRONT], \n",
    "            [DECREASE, INCREASE_LEFT, STABLE,         INCREASE_FRONT], \n",
    "            [DECREASE, STABLE,        INCREASE_RIGHT, INCREASE_FRONT], \n",
    "            [DECREASE, DECREASE,      DECREASE,       INCREASE_FRONT] \n",
    "        ])\n",
    "        \n",
    "\n",
    "    def smell(self):\n",
    "        \"\"\"Return the smell feedback: 1: smell left, 2: smell right, 3: smell front\"\"\"\n",
    "        smell_up_left = np.any(self.grid[:self.position[0]+1, :self.position[1]+1] == TARGET) \n",
    "        smell_up_right = np.any(self.grid[:self.position[0]+1, self.position[1]:] == TARGET) \n",
    "        smell_down_left = np.any(self.grid[self.position[0]:, :self.position[1]+1] == TARGET) \n",
    "        smell_down_right = np.any(self.grid[self.position[0]:, self.position[1]:] == TARGET) \n",
    "        # print(f\"Smell up-left:{smell_up_left}, up-right:{smell_up_right}, down-left:{smell_down_left}, down-right:{smell_down_right}\")\n",
    "        smell_left = {LEFT: smell_down_left, DOWN: smell_down_right, RIGHT: smell_up_right, UP: smell_up_left}[self.direction]\n",
    "        smell_right = {LEFT: smell_up_left, DOWN: smell_down_left, RIGHT: smell_down_right, UP: smell_up_right}[self.direction]\n",
    "        smell = smell_left + 2 * smell_right \n",
    "        result = self.smell_feedback[self.previous_smell, smell]\n",
    "        self.previous_smell = smell\n",
    "        return result\n",
    "    \n",
    "    def outcome(self, action):\n",
    "        \"\"\"Update the grid. Return the outcome of the action.\"\"\"\n",
    "        result = STABLE\n",
    "\n",
    "        if action == FORWARD:  \n",
    "            target_position = self.position + self.directions[self.direction]\n",
    "            if self.grid[tuple(target_position)] in [0, TARGET]:  # Don't bump in targets\n",
    "                self.position[:] = target_position\n",
    "            else:\n",
    "                result = BUMP\n",
    "                self.maze[tuple(target_position)] = BUMPING\n",
    "        \n",
    "        elif action == TURN_RIGHT:\n",
    "            self.direction = {LEFT: UP, DOWN: LEFT, RIGHT: DOWN, UP: RIGHT}[self.direction]\n",
    "        \n",
    "        elif action == TURN_LEFT:\n",
    "            self.direction = {LEFT: DOWN, DOWN: RIGHT, RIGHT: UP, UP: LEFT}[self.direction]\n",
    "        \n",
    "        elif action == FEEL_FRONT:\n",
    "            feeling_position = self.position + self.directions[self.direction]\n",
    "            if self.grid[tuple(feeling_position)] == 0:\n",
    "                self.maze[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = BUMP\n",
    "                self.maze[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_LEFT:\n",
    "            feeling_position = self.position + self.directions[(self.direction + 1) % 4]\n",
    "            if self.grid[tuple(feeling_position)] == 0:\n",
    "                self.maze[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = BUMP\n",
    "                self.maze[tuple(feeling_position)] = FEELING_WALL\n",
    "        \n",
    "        elif action == FEEL_RIGHT:\n",
    "            feeling_position = self.position + self.directions[self.direction - 1]\n",
    "            if self.grid[tuple(feeling_position)] == 0:\n",
    "                self.maze[tuple(feeling_position)] = FEELING_EMPTY\n",
    "            else:\n",
    "                result = BUMP\n",
    "                self.maze[tuple(feeling_position)] = FEELING_WALL\n",
    "\n",
    "        # Smell\n",
    "        smell_feedback = self.smell()\n",
    "        if self.grid[self.position[0], self.position[1]] == TARGET:\n",
    "            self.grid[self.position[0], self.position[1]] = 0\n",
    "            self.maze[self.position[0], self.position[1]] = 0\n",
    "            result = EAT\n",
    "        # If not bump then smell_feeback\n",
    "        if not result:\n",
    "            result = smell_feedback\n",
    "        \n",
    "        # print(f\"Line: {self.position[0]}, Column: {self.position[1]}, direction: {self.direction}\")\n",
    "        return result  \n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the grid in the notebook\"\"\"\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "            plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "            plt.show()\n",
    "            def on_click(event):\n",
    "                if event.inaxes is ax and event.button == 1 and event.xdata is not None:\n",
    "                    xi, yi = event.xdata, event.ydata\n",
    "                    if self.grid[round(yi), round(xi)] == TARGET:\n",
    "                        self.grid[round(yi), round(xi)] = 0\n",
    "                        self.maze[round(yi), round(xi)] = 0\n",
    "                    else:\n",
    "                        self.grid[round(yi), round(xi)] = TARGET\n",
    "                        self.maze[round(yi), round(xi)] = TARGET\n",
    "                    ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "        cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "    \n",
    "    def save(self, step):\n",
    "        \"\"\"Save the display as a PNG file\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "        ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "        plt.scatter(self.position[1], self.position[0], s=self.marker_size, marker=self.marker_map[self.direction], c=self.marker_color)\n",
    "        ax.text(self.grid.shape[1]-1.5, 0.2, f\"{step:>3}\", fontsize=12, color='White')\n",
    "        plt.savefig(f\"{save_dir}/{step:03}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def clear(self, clear):\n",
    "        \"\"\"Clear the grid display\"\"\"\n",
    "        if clear:\n",
    "            self.maze[:, :] = self.grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0188a-e490-4c14-b3d1-50868d0ccd3f",
   "metadata": {},
   "source": [
    "# Testons l'agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39217f-9d79-444f-93ba-8d81e2f16470",
   "metadata": {},
   "source": [
    "## Initialisons les valences des interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d22620-c12a-4015-b356-c28dd24fc4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_left_stable_val = 0\n",
    "trn_left_left_val = 10\n",
    "trn_left_right_val = 10\n",
    "trn_left_front_val = 15\n",
    "trn_left_decrease_val = -10\n",
    "\n",
    "fwd_stable_val = -5\n",
    "fwd_bump_val = -10\n",
    "fwd_left_val = 5\n",
    "fwd_right_val = 5\n",
    "fwd_front_val = 10\n",
    "fwd_decrease_val = -10\n",
    "eat_val = 0\n",
    "\n",
    "trn_right_stable_val = 0\n",
    "trn_right_left_val = 10\n",
    "trn_right_right_val = 10\n",
    "trn_right_front_val = 15\n",
    "trn_right_decrease_val = -10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c2ad7a-8dd4-40b6-b448-d14d384e4545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f47a2afb35e4f70a228352536cf4e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, continuous_update=False, description='Trn left stable', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# Définition des curseurs\n",
    "slider_trn_left_stable = widgets.IntSlider(value=trn_left_stable_val, min=-20, max=10, description='Trn left stable', continuous_update=False)\n",
    "slider_trn_left_left = widgets.IntSlider(value=trn_left_left_val, min=-20, max=10, description='Trn left Left', continuous_update=False)\n",
    "slider_trn_left_front = widgets.IntSlider(value=trn_left_front_val, min=-20, max=20, description='Trn left front', continuous_update=False)\n",
    "slider_trn_left_right = widgets.IntSlider(value=trn_left_right_val, min=-20, max=10, description='Trn left right', continuous_update=False)\n",
    "slider_trn_left_decrease = widgets.IntSlider(value=trn_left_decrease_val, min=-20, max=10, description='Trn left decrease', continuous_update=False)\n",
    "vbox1 = widgets.VBox([slider_trn_left_stable, slider_trn_left_left, slider_trn_left_front, slider_trn_left_right, slider_trn_left_decrease])\n",
    "\n",
    "slider_fwd_stable = widgets.IntSlider(value=fwd_stable_val, min=-20, max=10, description='Fwd stable', continuous_update=False)\n",
    "slider_fwd_decrease = widgets.IntSlider(value=fwd_decrease_val, min=-20, max=10, description='Fwd decrease', continuous_update=False)\n",
    "slider_fwd_bump = widgets.IntSlider(value=fwd_bump_val, min=-20, max=10, description='Bump', continuous_update=False)\n",
    "slider_eat = widgets.IntSlider(value=eat_val, min=-20, max=10, description='Eat', continuous_update=False)\n",
    "slider_fwd_left = widgets.IntSlider(value=fwd_left_val, min=-20, max=10, description='Fwd left', continuous_update=False)\n",
    "slider_fwd_front = widgets.IntSlider(value=fwd_front_val, min=-20, max=10, description='Fwd front', continuous_update=False)\n",
    "slider_fwd_right = widgets.IntSlider(value=fwd_right_val, min=-20, max=10, description='Fwd right', continuous_update=False)\n",
    "vbox2 = widgets.VBox([slider_fwd_stable, slider_fwd_left, slider_fwd_front, slider_fwd_right, slider_fwd_decrease, slider_fwd_bump, slider_eat])\n",
    "\n",
    "slider_trn_right_stable = widgets.IntSlider(value=trn_right_stable_val, min=-20, max=10, description='Trn right stable', continuous_update=False)\n",
    "slider_trn_right_left = widgets.IntSlider(value=trn_right_left_val, min=-20, max=10, description='Trn right Left', continuous_update=False)\n",
    "slider_trn_right_front = widgets.IntSlider(value=trn_right_front_val, min=-20, max=20, description='Trn right front', continuous_update=False)\n",
    "slider_trn_right_right = widgets.IntSlider(value=trn_right_right_val, min=-20, max=10, description='Trn right right', continuous_update=False)\n",
    "slider_trn_right_decrease = widgets.IntSlider(value=trn_right_decrease_val, min=-20, max=10, description='Trn right decrease', continuous_update=False)\n",
    "vbox3 = widgets.VBox([slider_trn_right_stable, slider_trn_right_left, slider_trn_right_front, slider_trn_right_right, slider_trn_right_decrease])\n",
    "\n",
    "# Affichage des curseurs\n",
    "display(widgets.HBox([vbox1, vbox2, vbox3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e59db638-c069-4589-ae5f-fe50f0fac89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28240fa2a464922b320d8379cc586b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciate the environment\n",
    "e = Environment([6, 4], UP)\n",
    "\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(FORWARD, STABLE, slider_fwd_stable.value),\n",
    "    Interaction(FORWARD, BUMP, slider_fwd_bump.value),\n",
    "    Interaction(FORWARD, INCREASE_LEFT, slider_fwd_left.value),\n",
    "    Interaction(FORWARD, INCREASE_RIGHT, slider_fwd_right.value),\n",
    "    Interaction(FORWARD, INCREASE_FRONT, slider_fwd_front.value),\n",
    "    Interaction(FORWARD, DECREASE, slider_fwd_decrease.value),\n",
    "    Interaction(FORWARD, EAT, slider_eat.value),\n",
    "    Interaction(TURN_LEFT, STABLE, slider_trn_left_stable.value),\n",
    "    Interaction(TURN_LEFT, INCREASE_LEFT, slider_trn_left_left.value),\n",
    "    Interaction(TURN_LEFT, INCREASE_RIGHT, slider_trn_left_right.value),\n",
    "    Interaction(TURN_LEFT, INCREASE_FRONT, slider_trn_left_front.value),\n",
    "    Interaction(TURN_LEFT, DECREASE, slider_trn_left_decrease.value),\n",
    "    Interaction(TURN_RIGHT, STABLE, slider_trn_right_stable.value),\n",
    "    Interaction(TURN_RIGHT, INCREASE_LEFT, slider_trn_right_left.value),\n",
    "    Interaction(TURN_RIGHT, INCREASE_RIGHT, slider_trn_right_right.value),\n",
    "    Interaction(TURN_RIGHT, INCREASE_FRONT, slider_trn_right_front.value),\n",
    "    Interaction(TURN_RIGHT, DECREASE, slider_trn_right_decrease.value),\n",
    "]\n",
    "a = Agent(interactions)\n",
    "\n",
    "# Initialize the experiment\n",
    "step = 0\n",
    "outcome = 0\n",
    "out = Output()\n",
    "e.display()\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89a45b-36cd-4aac-8108-cc255dee27d6",
   "metadata": {},
   "source": [
    "## On exécute l'agent pas à pas (Ctrl+Entrée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e38a590-b256-433f-a1d9-100cc7b0a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 38\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>actions</th>\n",
       "      <th>action</th>\n",
       "      <th>length</th>\n",
       "      <th>intention</th>\n",
       "      <th>primitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(10,10)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>-5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(10,00)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>020</td>\n",
       "      <td>-15</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(02,05)</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001</td>\n",
       "      <td>-20</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(00,10)</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000</td>\n",
       "      <td>-25</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(00,01)</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  decision  proclivity actions  action  length intention primitive\n",
       "0        1           0       1       1       1        10        10\n",
       "1      101           0      11       1       2   (10,10)        10\n",
       "2        2           0       2       2       1        20        20\n",
       "3      100          -5      10       1       2   (10,00)        10\n",
       "4        0         -10       0       0       1        00        00\n",
       "5      020         -15      00       0       2   (02,05)        02\n",
       "6      001         -20      01       0       2   (00,10)        00\n",
       "7      000         -25      00       0       2   (00,01)        00"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step: {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "e.display()\n",
    "e.clear(True)\n",
    "# e.save(step)  # Sauvegarde le fichier image qui servira au gif\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfa042-98b2-4bee-80fd-8db40b3cfaa1",
   "metadata": {},
   "source": [
    "Insérons une nouvelle cible au choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "id": "c33dcc4d-8d3f-4a32-919a-86a54ecc1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.grid[3,3] = TARGET\n",
    "e.maze[3,3] = TARGET\n",
    "e.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "e1201627-7f88-4d1c-9a07-7f64641769f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.grid[6, 5] = TARGET\n",
    "e.maze[6, 5] = TARGET\n",
    "e.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "213f855a-f389-4a39-b3ac-0350e5d23a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.grid[2, 9] = TARGET\n",
    "e.maze[2, 9] = TARGET\n",
    "e.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106724a7-82e7-4624-9661-e9be6f4cc515",
   "metadata": {},
   "source": [
    "### Choisir le mode Widget ou le mode InLine\n",
    "\n",
    "Le mode widget permet de cliquer dans l'environnement pour ajouter une cible\n",
    "Le mode inline ne le permet pas\n",
    "\n",
    "Choisir le mode en commentant ou décommentant la ligne correspondante ci-dessous et relancer la simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "9a034c32-737a-4a6f-9295-44bd34f703d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode widget pour pouvoir cliquer sur la figure pour insérer une cible\n",
    "%matplotlib widget\n",
    "\n",
    "# Mode inline ne permet pas de cliquer sur la figure\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a8e1b-ffc1-4f89-8a61-e1ec135124e5",
   "metadata": {},
   "source": [
    "# Exécutons l'agent en boucle\n",
    "\n",
    "Choisir les pas de temps et les positions d'insertion d'une nouvelle cible dans `target_steps` et `target_positions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478727ba-f660-499d-8e9f-657b3af255a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the environment\n",
    "e = SmallLoop([6, 4], UP)\n",
    "# Initialize the agent\n",
    "a = Agent(interactions)\n",
    "outcome = 0\n",
    "\n",
    "# Définition les moments et les position d'insertion des cycbles\n",
    "target_steps = [0, 50, 80, 130, 170, 220, 260, 283]\n",
    "target_positions = {0:[3, 6], 50: [4, 11], 80:[2, 2], 130:[7, 2], 170:[2, 4], 220:[6, 7], 260:[1,1], 283:[4,6]}\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display()\n",
    "display(out)\n",
    "for step in range(300):\n",
    "    if step in target_steps:\n",
    "        e.grid[target_positions[step][0], target_positions[step][1]] = TARGET\n",
    "        e.maze[target_positions[step][0], target_positions[step][1]] = TARGET\n",
    "    action = a.action(outcome)\n",
    "    e.display()\n",
    "    e.save(step)  # Sauvegarde le fichier image qui servira au gif\n",
    "    e.clear(True)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2449d-1ae9-495e-a26e-fc6a297c4438",
   "metadata": {},
   "source": [
    "# Créons le film gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "77dd51a7-b14b-42af-b6fc-c015db2ce4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import os\n",
    "\n",
    "img_dir = f\"./{save_dir}\"\n",
    "all_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "images = [imageio.imread(f) for f in all_files]\n",
    "imageio.mimsave(\"movie.gif\", images, fps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "e6e7b6d2-0c7d-4a8d-9133-3dc5ed4f982f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
