{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f34084-d4b8-4160-89ad-a927a0919615",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/notebooks/agent11.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L'AGENT QUI PRENAIT SON TEMPS (EN CONSTRUCTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Objectifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "Ce tutoriel montre comment implémenter un agent qui apprend récursivement et réutilise à bon escient des séquences hiérarchiques de plus en plus haut niveau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7e5da-0188-4924-92f4-3ecbfc2fce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install ipywidgets\n",
    "!pip install IPython.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "# Préparons les classes CompositeInteraction et Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d018f-39ae-471d-9976-0737298bc1a0",
   "metadata": {},
   "source": [
    "Nous conservons les mêmes classes `CompositeInteraction` et `Interaction ` que pour l'Agent10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3243d6-1de3-418e-9236-8af0287131da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeInteraction:\n",
    "    \"\"\"A composite interaction is a tuple (pre_interaction, post_interaction) and a weight\"\"\"\n",
    "    def __init__(self, pre_interaction, post_interaction):\n",
    "        self.pre_interaction = pre_interaction\n",
    "        self.post_interaction = post_interaction\n",
    "        self.weight = 1\n",
    "        self._step = 1\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the flatten sequence of intermediary primitive interactions terminated with the final decision\"\"\"\n",
    "        return f\"{self.pre_interaction.sequence()}{self.post_interaction.get_decision()}\"\n",
    "\n",
    "    def get_actions(self):\n",
    "        \"\"\"Return the flat sequence of the decisions of this interaction as a string\"\"\"\n",
    "        return f\"{self.pre_interaction.get_actions()}{self.post_interaction.get_actions()}\"\n",
    "    \n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the primite action\"\"\"\n",
    "        return self.pre_interaction.get_primitive_action()\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the valence of the pre_interaction plus the valence of the post_interaction\"\"\"\n",
    "        return self.pre_interaction.get_valence() + self.post_interaction.get_valence()\n",
    "\n",
    "    def reinforce(self):\n",
    "        \"\"\"Increment the composite interaction's weight\"\"\"\n",
    "        self.weight += 1\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string '<pre_interaction><post_interaction>'. \"\"\"\n",
    "        return f\"({self.pre_interaction.key()},{self.post_interaction.key()})\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key of the pre_interaction\"\"\"\n",
    "        return self.pre_interaction.pre_key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print the interaction in the Newick tree format (pre_interaction, post_interaction: valence) \"\"\"\n",
    "        return f\"({self.pre_interaction}, {self.post_interaction}: {self.weight})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same pre and post interactions \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return (self.pre_interaction == other.pre_interaction) and (self.post_interaction == other.post_interaction)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"Return the length of the number of primitive interactions in this composite interaction\"\"\"\n",
    "        return self.pre_interaction.get_length() + self.post_interaction.get_length()\n",
    "\n",
    "    def increment(self, interaction, interactions):\n",
    "        \"\"\"Increment the step of the appropriate sub-interaction. Return the enacted interaction if it is over, or None if it is ongoing.\"\"\"\n",
    "        # First step \n",
    "        if self._step == 1:\n",
    "            interaction = self.pre_interaction.increment(interaction, interactions)\n",
    "            # Ongoing pre-interaction. Return None\n",
    "            if interaction is None:\n",
    "                return None\n",
    "            # Pre-interaction succeeded. Increment the step and return None\n",
    "            elif interaction == self.pre_interaction:\n",
    "                self._step = 2\n",
    "                return None\n",
    "            # Pre-interaction failed. Reset the step and return the enacted interaction\n",
    "            else:\n",
    "                self._step = 1\n",
    "                return interaction\n",
    "        # Second step\n",
    "        else:\n",
    "            interaction = self.post_interaction.increment(interaction, interactions)\n",
    "            # Ongoing post-interaction. Return None\n",
    "            if interaction is None:\n",
    "                return None\n",
    "            # Post-interaction succeeded. Reset the step and return this interaction\n",
    "            elif interaction == self.post_interaction:\n",
    "                self._step = 1\n",
    "                return self\n",
    "            # Post-interaction failed. Reset the step and return the enacted interaction\n",
    "            else:\n",
    "                self._step = 1\n",
    "                composite_interaction = CompositeInteraction(self.pre_interaction, interaction)\n",
    "                if composite_interaction.key() not in interactions:\n",
    "                    # Add the enacted composite interaction to memory\n",
    "                    interactions[composite_interaction.key()] = composite_interaction\n",
    "                    print(f\"Learning {composite_interaction}\")\n",
    "                    return composite_interaction\n",
    "                else:\n",
    "                    # Reinforce the existing composite interaction and return it\n",
    "                    interactions[composite_interaction.key()].reinforce()\n",
    "                    print(f\"Reinforcing {interactions[composite_interaction.key()]}\")\n",
    "                    return interactions[composite_interaction.key()]\n",
    "\n",
    "    def current(self):\n",
    "        \"\"\"Return the current intended primitive interaction\"\"\"\n",
    "        # Step 1: the current primitive interaction of the pre-interaction\n",
    "        if self._step == 1:\n",
    "            return self.pre_interaction.current()\n",
    "        # Step 2: The current primitive interaction of the post-interaction\n",
    "        else:\n",
    "            return self.post_interaction.current()\n",
    "\n",
    "    def sequence(self):\n",
    "        \"\"\"Return the flat sequence of primitive interactions of this composite interaction\"\"\"\n",
    "        return f\"{self.pre_interaction.sequence()}{self.post_interaction.sequence()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7fd8bc-9dee-4aef-a217-3ed77844e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, _action, _outcome, _valence):\n",
    "        self._action = _action\n",
    "        self._outcome = _outcome\n",
    "        self._valence = _valence\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_actions(self):\n",
    "        \"\"\"Return the action as a string for compatibilty with CompositeInteraction\"\"\"\n",
    "        return str(self._action)\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the decision key\"\"\"\n",
    "        return f\"{self._action}\"\n",
    "        # return f\"a{self._action}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the action for compatibility with CompositeInteraction\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_outcome(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._outcome\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self._action}{self._outcome}\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key. Used for compatibility with CompositeInteraction\"\"\"\n",
    "        return self.key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self._action}{self._outcome}:{self._valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"The length of the sequence of this interaction\"\"\"\n",
    "        return 1\n",
    "\n",
    "    def increment(self, interaction, interactions):\n",
    "        \"\"\"Return the enacted interaction for compatibility with composite interactions\"\"\"\n",
    "        return interaction\n",
    "\n",
    "    def current(self):\n",
    "        \"\"\"Return itself for compatibility with composite interactions\"\"\"\n",
    "        return self\n",
    "\n",
    "    def sequence(self):\n",
    "        \"\"\"Return the key. Use for compatibility with composite interactions\"\"\"\n",
    "        return self.key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957e7b6-d560-4e4e-a8bf-0a7b62817a7a",
   "metadata": {},
   "source": [
    "# Implémentons l'agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf545ea9-a6b5-4c2a-8179-4145894e26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize our agent \"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._primitive_intended_interaction = self._interactions[\"00\"]\n",
    "        self._intended_interaction = None\n",
    "\n",
    "        # The context\n",
    "        self._penultimate_interaction = None\n",
    "        self._previous_interaction = None\n",
    "        self._last_interaction = None\n",
    "        self._penultimate_composite_interaction = None\n",
    "        self._previous_composite_interaction = None\n",
    "        self._last_composite_interaction = None\n",
    "        \n",
    "        # Prepare the dataframe of proposed interactions\n",
    "        default_interactions = [interaction for interaction in _interactions if interaction.get_outcome() == 0]\n",
    "        data = {'activated': [\"\"] * len(default_interactions),\n",
    "                'weight': [0] * len(default_interactions),\n",
    "                'action': [i.get_action() for i in default_interactions],\n",
    "                'actions': [i.get_actions() for i in default_interactions],\n",
    "                'intention': [i.key() for i in default_interactions],\n",
    "                'valence': [i.get_valence() for i in default_interactions],\n",
    "                'decision': [i.get_decision() for i in default_interactions],\n",
    "                'length': [1] * len(default_interactions),\n",
    "                'primitive': [i.key() for i in default_interactions]}\n",
    "        self._default_df = pd.DataFrame(data)\n",
    "        self.proposed_df = None\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Implement the agent's policy\"\"\"\n",
    "\n",
    "        # Trace the previous cycle\n",
    "        primitive_enacted_interaction = self._interactions[f\"{self._primitive_intended_interaction.get_action()}{_outcome}\"]\n",
    "        print(\n",
    "            f\"Action: {self._primitive_intended_interaction.get_action()}, Prediction: {self._primitive_intended_interaction.get_outcome()}, \"\n",
    "            f\"Outcome: {_outcome}, Prediction_correct: {self._primitive_intended_interaction.get_outcome() == _outcome}, \"\n",
    "            f\"Valence: {primitive_enacted_interaction.get_valence()}\")\n",
    "\n",
    "        # Follow up the enaction\n",
    "        if self._intended_interaction is None: # First interaction cycle\n",
    "            enacted_interaction = primitive_enacted_interaction\n",
    "        else:\n",
    "            enacted_interaction = self._intended_interaction.increment(primitive_enacted_interaction, self._interactions)\n",
    "\n",
    "        # If the intended interaction is over (completely enacted or aborted)\n",
    "        if enacted_interaction is not None:\n",
    "            # Memorize the context\n",
    "            self._penultimate_composite_interaction = self._previous_composite_interaction\n",
    "            self._previous_composite_interaction = self._last_composite_interaction\n",
    "            self._penultimate_interaction = self._previous_interaction\n",
    "            self._previous_interaction = self._last_interaction\n",
    "            self._last_interaction = enacted_interaction\n",
    "            # Call the learning mechanism\n",
    "            self.learn(enacted_interaction)\n",
    "            # Create the proposed dataframe\n",
    "            self.create_proposed_df()\n",
    "            self.aggregate_propositions()\n",
    "            # Decide the next enaction\n",
    "            self.decide()\n",
    "\n",
    "        # Return the next primitive action\n",
    "        self._primitive_intended_interaction = self._intended_interaction.current()\n",
    "        return self._primitive_intended_interaction.get_action()\n",
    "        \n",
    "    def learn(self, enacted_interaction):\n",
    "        \"\"\"Learn the composite interactions\"\"\"\n",
    "        # First level of composite interactions\n",
    "        self._last_composite_interaction = self.learn_composite_interaction(self._previous_interaction, enacted_interaction)\n",
    "        # Second level of composite interactions\n",
    "        self.learn_composite_interaction(self._previous_composite_interaction, enacted_interaction)\n",
    "        self.learn_composite_interaction(self._penultimate_interaction, self._last_composite_interaction)\n",
    "\n",
    "        # Higher level composite interaction made of two composite interactions\n",
    "        if self._last_composite_interaction is not None:\n",
    "            self.learn_composite_interaction(self._penultimate_composite_interaction, self._last_composite_interaction)\n",
    "\n",
    "    \n",
    "    def learn_composite_interaction(self, pre_interaction, post_interaction):\n",
    "        \"\"\"Record or reinforce the composite interaction made of (pre_interaction, post_interaction)\"\"\"\n",
    "        if pre_interaction is None:\n",
    "            return None\n",
    "        else:\n",
    "            # If the pre-interaction exists\n",
    "            composite_interaction = CompositeInteraction(pre_interaction, post_interaction)\n",
    "            if composite_interaction.key() not in self._interactions:\n",
    "                # Add the composite interaction to memory\n",
    "                self._interactions[composite_interaction.key()] = composite_interaction\n",
    "                print(f\"Learning {composite_interaction}\")\n",
    "                return composite_interaction\n",
    "            else:\n",
    "                # Reinforce the existing composite interaction and return it\n",
    "                self._interactions[composite_interaction.key()].reinforce()\n",
    "                print(f\"Reinforcing {self._interactions[composite_interaction.key()]}\")\n",
    "                return self._interactions[composite_interaction.key()]\n",
    "\n",
    "    def create_proposed_df(self):\n",
    "        \"\"\"Create the proposed dataframe from the activated interactions\"\"\"\n",
    "        # The list of activated interaction that match the current context\n",
    "        activated_keys = [composite_interaction.key() for composite_interaction in self._interactions.values()\n",
    "                          if composite_interaction.get_length() > 1 \n",
    "                          and (composite_interaction.pre_interaction == self._last_interaction \n",
    "                               or composite_interaction.pre_interaction == self._last_composite_interaction\n",
    "                               or (self._last_interaction.get_length() > 1\n",
    "                                  and composite_interaction.pre_interaction == self._last_interaction.pre_interaction))]\n",
    "        data = {'activated': activated_keys,\n",
    "                'weight': [self._interactions[k].weight for k in activated_keys],\n",
    "                'action': [self._interactions[k].post_interaction.get_primitive_action() for k in activated_keys],\n",
    "                'actions': [self._interactions[k].post_interaction.get_actions() for k in activated_keys],\n",
    "                'intention': [self._interactions[k].post_interaction.key() for k in activated_keys],\n",
    "                'valence': [self._interactions[k].post_interaction.get_valence() for k in activated_keys],\n",
    "                'decision': [self._interactions[k].post_interaction.get_decision() for k in activated_keys],\n",
    "                'primitive': [self._interactions[k].post_interaction.pre_key() for k in activated_keys],\n",
    "                'length': [self._interactions[k].post_interaction.get_length() for k in activated_keys],\n",
    "                }\n",
    "        activated_df = pd.DataFrame(data).astype(self._default_df.dtypes)  # Force the same types for the case it is empty\n",
    "\n",
    "        # Create the proposed dataframe\n",
    "        self.proposed_df = pd.concat([self._default_df, activated_df], ignore_index=True)\n",
    "\n",
    "        # Compute the proclivity for each proposition\n",
    "        self.proposed_df['proclivity'] = self.proposed_df['weight'] * self.proposed_df['valence']\n",
    "\n",
    "    def aggregate_propositions(self):\n",
    "        \"\"\"Aggregate the proclivity\"\"\"\n",
    "        # Aggregate the proclivity for each decision\n",
    "        grouped_df = self.proposed_df.groupby('decision').agg({'proclivity': 'sum', 'actions': 'first', 'action': 'first', 'length': 'first', \n",
    "                                                               'intention': 'first', 'primitive': 'first'}).reset_index()\n",
    "        # For each proposed composite decision \n",
    "        for index, proposed in grouped_df[grouped_df['length'] > 1].iterrows():\n",
    "            # print(f\"Index {index}, actions {proposition['actions']}, intention {proposition['intention']}\")\n",
    "            # Find shorter decisions that start with the same sequence \n",
    "            for _, shorter in self.proposed_df[self.proposed_df.apply(lambda row: proposed['actions'].startswith(row['actions']) \n",
    "                                                                      and row['length'] < proposed['length'], axis=1)].iterrows():\n",
    "                # Add the proclivity of the shorter decisions\n",
    "                grouped_df.loc[index, 'proclivity'] += shorter['proclivity']\n",
    "                # print(f\"Decision {proposition['decision']} recieves {shorter['proclivity']} from partial {shorter['intention']}\")\n",
    "        \n",
    "        # Sort by descending proclivity\n",
    "        self.proposed_df = grouped_df.sort_values(by=['proclivity', 'decision'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    def decide(self):\n",
    "        \"\"\"Selects the intended_interaction that at the top of the proposed dataframe\"\"\"\n",
    "        # The intended interaction is in the first row because it has been sorted by descending proclivity\n",
    "        intended_interaction_key = self.proposed_df.loc[0, 'intention']\n",
    "        print(\"Intention:\", intended_interaction_key)\n",
    "        self._intended_interaction = self._interactions[intended_interaction_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afad0a0-b639-4168-8a62-c97a323b67e8",
   "metadata": {},
   "source": [
    "# Implémentons l'environnement SmallLoop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "id": "3e654a53-51f5-460a-9ad5-569ac9240783",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"sav\"\n",
    "\n",
    "FEEL_FRONT = 0\n",
    "FORWARD = 1\n",
    "FEEL_LEFT = 2\n",
    "FEEL_RIGHT = 3\n",
    "TURN_RIGHT = 4\n",
    "TURN_LEFT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15624ba-33e2-4b0c-825c-6a01195d7ad6",
   "metadata": {},
   "source": [
    "On crée l'environnement Small Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "id": "c153ef60-2a2c-4cfe-9896-92b47ba234e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from ipywidgets import Button, HBox,VBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "FEELING = 2\n",
    "BUMPING = 3\n",
    "\n",
    "class SmallLoop():\n",
    "    def __init__(self, poX, poY, direction):\n",
    "        self.grid = np.array([\n",
    "            [1, 1, 1, 1, 1, 1], \n",
    "            [1, 0, 0, 0, 1, 1],\n",
    "            [1, 0, 1, 0, 0, 1],\n",
    "            [1, 0, 1, 1, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 1, 1, 1]\n",
    "        ])\n",
    "        self.maze = self.grid.copy()\n",
    "        self.poX = poX\n",
    "        self.poY = poY\n",
    "        self.direction = direction\n",
    "        self.cmap = ListedColormap(['white', 'green', 'yellow', 'red'])\n",
    "        self.norm = BoundaryNorm([-0.5, 0.5, 1.5, 2.5, 3.5], self.cmap.N)\n",
    "\n",
    "    def outcome(self, action):\n",
    "        # print('before:', self.agent_position.strPosition(), action_dcit[action])\n",
    "        self.maze[:,:] = self.grid\n",
    "        result = 0\n",
    "        \n",
    "        if action == FORWARD:  # move forward\n",
    "            # print('the action is move forward')\n",
    "            # print(str(self.position.pointX)+': '+ str(self.position.pointY)+ ' ' +self.direction, action)\n",
    "        \n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX][self.poY - 1] == 0:\n",
    "                    self.poY -= 1\n",
    "                else:\n",
    "                    self.maze[self.poX][self.poY - 1] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX + 1][self.poY] == 0:\n",
    "                    self.poX += 1\n",
    "                else:\n",
    "                    self.maze[self.poX + 1][self.poY] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX][self.poY + 1] == 0:\n",
    "                    self.poY += 1\n",
    "                else:\n",
    "                    self.maze[self.poX][self.poY + 1] = BUMPING\n",
    "                    result = 1\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX - 1][self.poY] == 0:\n",
    "                    self.poX -= 1\n",
    "                else:\n",
    "                    self.maze[self.poX - 1][self.poY] = BUMPING\n",
    "                    result = 1\n",
    "            # print(str(self.position.pointX)+': '+ str(self.position.pointY)+ ' ' +self.direction, action)\n",
    "        elif action == TURN_RIGHT:\n",
    "            if self.direction == LEFT:\n",
    "                self.direction = UP\n",
    "            elif self.direction == DOWN:\n",
    "                self.direction = LEFT\n",
    "            elif self.direction == RIGHT:\n",
    "                self.direction = DOWN\n",
    "            elif self.direction == UP:\n",
    "                self.direction = RIGHT\n",
    "        elif action == TURN_LEFT:\n",
    "            if self.direction == LEFT:\n",
    "                self.direction = DOWN  # RIGHT  # DOWN\n",
    "            elif self.direction == DOWN:\n",
    "                self.direction = RIGHT\n",
    "            elif self.direction == RIGHT:\n",
    "                self.direction = UP  # LEFT  # UP\n",
    "            elif self.direction == UP:\n",
    "                self.direction = LEFT\n",
    "        elif action == FEEL_FRONT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "        elif action == FEEL_LEFT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "        elif action == FEEL_RIGHT:\n",
    "            if self.direction == LEFT:\n",
    "                if self.maze[self.poX - 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX - 1][self.poY] = FEELING\n",
    "            elif self.direction == DOWN:\n",
    "                if self.maze[self.poX][self.poY - 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY - 1] = FEELING\n",
    "            elif self.direction == RIGHT:\n",
    "                if self.maze[self.poX + 1][self.poY] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX + 1][self.poY] = FEELING\n",
    "            elif self.direction == UP:\n",
    "                if self.maze[self.poX][self.poY + 1] != 0:\n",
    "                    result = 1\n",
    "                self.maze[self.poX][self.poY + 1] = FEELING\n",
    "        print(f\"Line: {self.poX}, Column: {self.poY}, direction: {self.direction}\")\n",
    "        # return self.position,\n",
    "\n",
    "        return result  \n",
    "    \n",
    "    def display(self):\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            # ax.set_xticks([])\n",
    "            # ax.set_yticks([])\n",
    "            # ax.axis('off')\n",
    "            # ax.imshow(self.maze, cmap='Greens', vmin=0, vmax=2)\n",
    "            ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "            if self.direction == LEFT:\n",
    "                # Y is column and X is line\n",
    "                plt.scatter(self.poY, self.poX, s=400, marker='<')\n",
    "            elif self.direction == DOWN:\n",
    "                plt.scatter(self.poY, self.poX, s=400, marker='v')\n",
    "            elif self.direction == RIGHT:\n",
    "                plt.scatter(self.poY, self.poX, s=400, marker='>')\n",
    "            else: # UP\n",
    "                plt.scatter(self.poY, self.poX, s=400, marker='^')\n",
    "            plt.show()\n",
    "\n",
    "    def save(self, step):\n",
    "        \"\"\"\n",
    "        save the display as png file\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "        ax.imshow(self.maze, cmap='Greens', vmin=0, vmax=2)\n",
    "        ax.imshow(self.maze, cmap=self.cmap, norm=self.norm)\n",
    "        if self.direction == LEFT:\n",
    "            # Y is column and X is line\n",
    "            plt.scatter(self.poY, self.poX, s=400, marker='<')\n",
    "        elif self.direction == DOWN:\n",
    "            plt.scatter(self.poY, self.poX, s=400, marker='v')\n",
    "        elif self.direction == RIGHT:\n",
    "            plt.scatter(self.poY, self.poX, s=400, marker='>')\n",
    "        else: # UP\n",
    "            plt.scatter(self.poY, self.poX, s=400, marker='^')\n",
    "\n",
    "        # Add number in plot\n",
    "        ax.text(4, 0, f\"{step:>3}\", fontsize=12, color='White')\n",
    "        plt.savefig(f\"{save_dir}/{step:03}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0188a-e490-4c14-b3d1-50868d0ccd3f",
   "metadata": {},
   "source": [
    "# Testons l'agent dans le Small Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "id": "e59db638-c069-4589-ae5f-fe50f0fac89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa7ea6a29304319b774fbbec8197edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciate the small loop environment\n",
    "e = SmallLoop(1, 1, 1)\n",
    "\n",
    "# Instanciate the agent \n",
    "interactions = [\n",
    "    Interaction(FORWARD,0,5),\n",
    "    Interaction(FORWARD,1,-10),\n",
    "    Interaction(TURN_LEFT,0,-3),\n",
    "    Interaction(TURN_LEFT,1,-3),\n",
    "    Interaction(TURN_RIGHT,0,-3),\n",
    "    Interaction(TURN_RIGHT,1,-3),\n",
    "    Interaction(FEEL_FRONT,0,-1),\n",
    "    Interaction(FEEL_FRONT,1,-1),\n",
    "    Interaction(FEEL_LEFT,0,-1),\n",
    "    Interaction(FEEL_LEFT,1,-1),\n",
    "    Interaction(FEEL_RIGHT,0,-1),\n",
    "    Interaction(FEEL_RIGHT,1,-1)\n",
    "]\n",
    "a = Agent(interactions)\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0\n",
    "\n",
    "# Display\n",
    "out = Output()\n",
    "e.display()\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1622,
   "id": "6e38a590-b256-433f-a1d9-100cc7b0a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 68\n",
      "Action: 3, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1\n",
      "Learning (11:-10, 30:-1: 1)\n",
      "Learning (((00:-1, ((10:5, 00:-1: 2), (10:5, 01:-1: 3): 2): 2), 11:-10: 1), 30:-1: 1)\n",
      "Learning ((00:-1, ((10:5, 00:-1: 2), (10:5, 01:-1: 3): 2): 2), (11:-10, 30:-1: 1): 1)\n",
      "Learning ((21:-1, (00:-1, ((10:5, 00:-1: 2), (10:5, 01:-1: 3): 2): 2): 1), (11:-10, 30:-1: 1): 1)\n",
      "Intention: 20\n",
      "Line: 1, Column: 3, direction: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>actions</th>\n",
       "      <th>action</th>\n",
       "      <th>length</th>\n",
       "      <th>intention</th>\n",
       "      <th>primitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>010</td>\n",
       "      <td>-3</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(01,01)</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>112</td>\n",
       "      <td>-21</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(11,21)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  decision  proclivity actions  action  length intention primitive\n",
       "0        2           0       2       2       1        20        20\n",
       "1        3           0       3       3       1        30        30\n",
       "2        4           0       4       4       1        40        40\n",
       "3        5           0       5       5       1        50        50\n",
       "4        0          -1       0       0       1        00        00\n",
       "5      010          -3      00       0       2   (01,01)        01\n",
       "6        1         -10       1       1       1        10        10\n",
       "7      112         -21      12       1       2   (11,21)        11"
      ]
     },
     "execution_count": 1622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step: {step}\")\n",
    "step += 1\n",
    "action = a.action(outcome)\n",
    "e.display()\n",
    "e.save(step)  # Sauvegarde le fichier image qui servira au gif\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de658523-2d93-4b3d-bab3-5197d239a85d",
   "metadata": {},
   "source": [
    "Nous observons que l'agent construit rapidement des interactions composites très longues qui ont une bonne valeur de proclivité car elles contiennent plusieurs interactions avancer, mais qui échouent la plupart du temps. \n",
    "\n",
    "Attendre que les interactions composites aient fait leur preuve en étant énactée entièrement avant de baser des interactions de plus haut niveau sur elles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2449d-1ae9-495e-a26e-fc6a297c4438",
   "metadata": {},
   "source": [
    "# Créons le film gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4666,
   "id": "77dd51a7-b14b-42af-b6fc-c015db2ce4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import os\n",
    "\n",
    "img_dir = f\"./{save_dir}\"\n",
    "all_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "images = [imageio.imread(f) for f in all_files]\n",
    "imageio.mimsave(\"movie.gif\", images, fps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a034c32-737a-4a6f-9295-44bd34f703d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
