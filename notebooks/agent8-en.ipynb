{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f34084-d4b8-4160-89ad-a927a0919615",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PetiteIA/schema_mechanism/blob/master/notebooks/agent8.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# THE AGENT WHO REVERSED HIS DECISION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "Upon completing this lab, you will be able to implement a developmental agent that selects an action based on the anticipation of the two next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cca763-7c87-40ff-a39f-e12357996c98",
   "metadata": {},
   "source": [
    "# Adapt the decision mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746fb19-9f54-4ec6-baf8-3a44121c31f7",
   "metadata": {},
   "source": [
    "Let's include the decision in the composite interaction. \n",
    "A composite interaction becomes a tuple (pre-interaction, decision, post-interaction).\n",
    "\n",
    "At the end of time step $t$, the agent records or reinforces the interactions:\n",
    "\n",
    "* $(i_{t-2}, d_{t-1}, i_{t-1})$\n",
    "* $((i_{t-3}, d_{t-2}, i_{t-2}), d_{t-1}, i_{t-1})$\n",
    "* $(i_{t-3}, d^2, (i_{t-2}, d_{t-1}, i_{t-1}))$\n",
    "* $((i_{t-4}, d_{t-3}, i_{t-3}), d^2, (i_{t-2}, d_{t-1}, i_{t-1}))$\n",
    "\n",
    "If it does not yet exist, the new decision $d^2$ is constructed different from the decision $d_{t-2}$ that was actually made at time $t-2$. \r\n",
    "For example, if the agent made decision $d_{t-2} = a0$ and enacted interaction $i_{t-2}=i00$, and then made decision $d_{t-1} = a0$, and enacted interaction $i_{t-1}=i01$, the agent learns the new decision $d^2=i00a0$ consisting of trying to enact the interaction $i_t=i00$ and then do action $a_{t+1}=a0.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6146dc4-9f72-4323-99d6-025e853b5a56",
   "metadata": {},
   "source": [
    "![Agent5](img/Figure_1_Agent8.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aef117-bd08-4333-93e6-e201a38d06b0",
   "metadata": {},
   "source": [
    "The purpose of including the decision in the composite interaction is to learn that the agent may fail to enact a decision. \n",
    "\n",
    "For example, in the context of having enacted interaction $i01$, the agent may select decision $i10a0$ but may fail to enat $i10$ and enact $i11$ instead. In this case, the agent learns the composite interaction $(i01, i10a0, i11)$.\n",
    "\n",
    "When the agent encounters the context $i01$ again, it will have a better assessment of the expected valence of decision $i10a0$ by taking its probabilities of success and failure into account. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "# Define the necessary classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e17704e-ca60-417b-8d7e-b8f77cfa09a0",
   "metadata": {},
   "source": [
    "Ensure the required packages are installed if they aren't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a7e5da-0188-4924-92f4-3ecbfc2fce5f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (8.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: backcall in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ogeorgeon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b7d02-9727-4ec5-96f3-baaf55ea9c2a",
   "metadata": {},
   "source": [
    "## The primitive interaction class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44155c4a-d038-40b3-be33-e8cf77c5f976",
   "metadata": {},
   "source": [
    "A primitive interaction's decision is its action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96c3637-4161-49aa-9f1d-0d3342de92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, _action, _outcome, _valence):\n",
    "        self._action = _action\n",
    "        self._outcome = _outcome\n",
    "        self._valence = _valence\n",
    "\n",
    "    def get_action(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the decision key\"\"\"\n",
    "        return f\"a{self._action}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the action for compatibility with CompositeInteraction\"\"\"\n",
    "        return self._action\n",
    "\n",
    "    def get_outcome(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._outcome\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the action\"\"\"\n",
    "        return self._valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self._action}{self._outcome}\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key. Used for compatibility with CompositeInteraction\"\"\"\n",
    "        return self.key()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self._action}{self._outcome}:{self._valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f8a31-55b2-4302-827a-59d7341295f0",
   "metadata": {},
   "source": [
    "## The composite interaction class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff56a5-e408-431c-bd93-c681b730cb24",
   "metadata": {},
   "source": [
    "A composite interaction is initialized with a tuple (pre_interaction, decision, post_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3243d6-1de3-418e-9236-8af0287131da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeInteraction:\n",
    "    \"\"\"A composite interaction is a tuple (pre_interaction, decision, post_interaction) and a weight\"\"\"\n",
    "    def __init__(self, pre_interaction, decision, post_interaction):\n",
    "        self.pre_interaction = pre_interaction\n",
    "        self.decision = decision\n",
    "        self.post_interaction = post_interaction\n",
    "        self.weight = 1\n",
    "        self.isActivated = False\n",
    "\n",
    "    def get_decision(self):\n",
    "        \"\"\"Return the sequence of decisions\"\"\"\n",
    "        return self.decision\n",
    "        return f\"{self.pre_interaction.key()}{self.post_interaction.get_decision()}\"\n",
    "\n",
    "    def get_primitive_action(self):\n",
    "        \"\"\"Return the primitive action\"\"\"\n",
    "        return self.pre_interaction.get_primitive_action()\n",
    "\n",
    "    def get_valence(self):\n",
    "        \"\"\"Return the valence of the pre_interaction plus the valence of the post_interaction\"\"\"\n",
    "        return self.pre_interaction.get_valence() + self.post_interaction.get_valence()\n",
    "\n",
    "    def reinforce(self):\n",
    "        \"\"\"Increment the composite interaction's weight\"\"\"\n",
    "        self.weight += 1\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictionary is the string\n",
    "        '<pre_interaction>,<decision>,<post_interaction>'. \"\"\"\n",
    "        # return f\"({self.pre_interaction.key()},{self.post_interaction.key()})\"\n",
    "        return f\"({self.pre_interaction.key()},{self.decision},{self.post_interaction.key()})\"\n",
    "\n",
    "    def pre_key(self):\n",
    "        \"\"\"Return the key of the pre_interaction\"\"\"\n",
    "        return self.pre_interaction.pre_key()\n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\" Print the interaction in the Newick tree format (pre_interaction, post_interaction: valence) \"\"\"\n",
    "        return f\"({self.pre_interaction}, {self.decision}, {self.post_interaction}: {self.weight})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same keys \"\"\"\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.key() == other.key()\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152512a3-ef97-473a-91a7-9a36fe70ba33",
   "metadata": {},
   "source": [
    "## Define the Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0bf369-48ef-48d7-a92b-3c7ef8dc1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize our agent \"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._composite_interactions = {}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "        self._decision = None  # \"0\"\n",
    "        self._last_interaction = None\n",
    "        self._previous_interaction = None\n",
    "        self._penultimate_interaction = None\n",
    "        self._last_composite_interaction = None\n",
    "        self._previous_composite_interaction = None\n",
    "        self._penultimate_composite_interaction = None\n",
    "        # Create a dataframe of default primitive interactions\n",
    "        default_interactions = [interaction for interaction in _interactions if interaction.get_outcome() == 0]\n",
    "        data = {'activated': [np.nan] * len(default_interactions),\n",
    "                'weight': [0] * len(default_interactions),\n",
    "                # 'action': [i.get_primitive_action() for i in default_interactions],\n",
    "                'post_interaction': [i.key() for i in default_interactions],\n",
    "                'valence': [i.get_valence() for i in default_interactions],\n",
    "                'decision': [i.get_decision() for i in default_interactions],\n",
    "                'proclivity': [0] * len(default_interactions),\n",
    "                'primitive': [i.key() for i in default_interactions]\n",
    "               }\n",
    "        self.primitive_df = pd.DataFrame(data)\n",
    "        # Store the selection dataframe as a class attribute so we can display it in the notebook\n",
    "        self.proposed_df = None\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Implement the agent's policy\"\"\"\n",
    "        # Memorize the context\n",
    "        self._penultimate_composite_interaction = self._previous_composite_interaction\n",
    "        self._previous_composite_interaction = self._last_composite_interaction\n",
    "        self._penultimate_interaction = self._previous_interaction\n",
    "        self._previous_interaction = self._last_interaction\n",
    "        self._last_interaction = self._interactions[f\"{self._intended_interaction.get_action()}{_outcome}\"]\n",
    "\n",
    "        # tracing the previous cycle\n",
    "        print(\n",
    "            f\"Action: {self._intended_interaction.get_action()}, Prediction: {self._intended_interaction.get_outcome()}, \"\n",
    "            f\"Outcome: {_outcome}, Prediction_correct: {self._intended_interaction.get_outcome() == _outcome}, \"\n",
    "            f\"Valence: {self._last_interaction.get_valence()}\")\n",
    "\n",
    "        # Call the learning mechanism\n",
    "        self.learn()\n",
    "\n",
    "        # Create the proposed dataframe\n",
    "        self.create_proposed_df()\n",
    "        self.aggregate_propositions()\n",
    "\n",
    "        # Select the intended primitive interaction\n",
    "        self.decide()\n",
    "\n",
    "        return self._intended_interaction.get_action()\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"Learn the composite interactions\"\"\"\n",
    "        # First level of composite interactions using the last primitive decision\n",
    "        self._last_composite_interaction = self.learn_composite_interaction(\n",
    "            self._previous_interaction, self._last_interaction.get_decision(), self._last_interaction)\n",
    "        # self._last_composite_interaction = self.learn_composite_interaction(\n",
    "        #     self._previous_interaction, self._decision, self._last_interaction)\n",
    "\n",
    "        # Second level of composite interactions \n",
    "        self.learn_composite_interaction(self._previous_composite_interaction, self._last_interaction.get_decision(),\n",
    "                                         self._last_interaction)\n",
    "        # self.learn_composite_interaction(\n",
    "        #     self._previous_composite_interaction, self._decision, self._last_interaction)\n",
    "\n",
    "        if self._last_composite_interaction is not None:\n",
    "            # Possibly create a new composite decision\n",
    "            decision = f\"{self._last_composite_interaction.pre_interaction.key()}{self._last_composite_interaction.post_interaction.get_decision()}\"\n",
    "            self.learn_composite_interaction(self._penultimate_interaction, decision, self._last_composite_interaction)\n",
    "            # self.learn_composite_interaction(self._penultimate_interaction, self._decision, self._last_composite_interaction)\n",
    "            self.learn_composite_interaction(self._penultimate_composite_interaction, decision, self._last_composite_interaction)\n",
    "\n",
    "    def learn_composite_interaction(self, pre_interaction, decision, post_interaction):\n",
    "        \"\"\"Record or reinforce the composite interaction made of (pre_interaction, post_interaction)\"\"\"\n",
    "        if pre_interaction is None:\n",
    "            return None\n",
    "        else:\n",
    "            # If the pre interaction exist\n",
    "            composite_interaction = CompositeInteraction(pre_interaction, decision, post_interaction)\n",
    "            if composite_interaction.key() not in self._composite_interactions:\n",
    "                # Add the composite interaction to memory\n",
    "                self._composite_interactions[composite_interaction.key()] = composite_interaction\n",
    "                print(f\"Learning {composite_interaction}\")\n",
    "                return composite_interaction\n",
    "            else:\n",
    "                # Reinforce the existing composite interaction and return it\n",
    "                self._composite_interactions[composite_interaction.key()].reinforce()\n",
    "                print(f\"Reinforcing {self._composite_interactions[composite_interaction.key()]}\")\n",
    "                return self._composite_interactions[composite_interaction.key()]\n",
    "\n",
    "    def create_proposed_df(self):\n",
    "        \"\"\"Create the proposed dataframe from the activated interactions\"\"\"\n",
    "        # The list of activated interaction that match the current context\n",
    "        activated_keys = [composite_interaction.key() for composite_interaction in\n",
    "                          self._composite_interactions.values()\n",
    "                          if composite_interaction.pre_interaction == self._last_interaction or\n",
    "                          composite_interaction.pre_interaction == self._last_composite_interaction]\n",
    "        data = {'activated': activated_keys,\n",
    "                'weight': [self._composite_interactions[k].weight for k in activated_keys],\n",
    "                # 'action': [self._composite_interactions[k].post_interaction.get_primitive_action() for k in\n",
    "                #            activated_keys],\n",
    "                'post_interaction': [self._composite_interactions[k].post_interaction.key() for k in activated_keys],\n",
    "                'valence': [self._composite_interactions[k].post_interaction.get_valence() for k in activated_keys],\n",
    "                'decision': [self._composite_interactions[k].get_decision() for k in activated_keys],\n",
    "                'primitive': [self._composite_interactions[k].post_interaction.pre_key() for k in activated_keys]\n",
    "                }\n",
    "        activated_df = pd.DataFrame(data)\n",
    "\n",
    "        # Create the selection dataframe from the primitive and the activated dataframes\n",
    "        self.proposed_df = pd.concat([self.primitive_df, activated_df], ignore_index=True)\n",
    "\n",
    "        # # Compute the proclivity for each proposition\n",
    "        self.proposed_df['proclivity'] = self.proposed_df['weight'] * self.proposed_df['valence']\n",
    "\n",
    "    def aggregate_propositions(self):\n",
    "        \"\"\"Aggregate the proclivity\"\"\"\n",
    "        # Compute the proclivity for each action\n",
    "        grouped_df = self.proposed_df.groupby('decision').agg({'proclivity': 'sum'}).reset_index()\n",
    "        self.proposed_df = self.proposed_df.merge(grouped_df, on='decision', suffixes=('', '_agg'))\n",
    "        # Sort by descending order of proclivity\n",
    "        self.proposed_df = self.proposed_df.sort_values(by=['proclivity_agg', 'decision'], ascending=[False, False])\n",
    "\n",
    "        # Find the most probable primitive interaction for each action\n",
    "        max_weight_df = self.proposed_df.loc[\n",
    "            self.proposed_df.groupby('decision')['weight'].idxmax(), ['decision', 'primitive']].reset_index(\n",
    "            drop=True)\n",
    "        max_weight_df.columns = ['decision', 'intended']\n",
    "        self.proposed_df = self.proposed_df.merge(max_weight_df, on='decision')\n",
    "\n",
    "    def decide(self):\n",
    "        \"\"\"Selects the intended interaction from the proposed dataframe\"\"\"\n",
    "        # Find the first row that has the highest proclivity\n",
    "        max_index = self.proposed_df['proclivity_agg'].idxmax()\n",
    "        self._decision = self.proposed_df.loc[max_index, ['decision']].values[0]\n",
    "\n",
    "        # Find the intended interaction corresponding to the action that has the highest proclivity\n",
    "        intended_interaction_key = self.proposed_df.loc[max_index, ['intended']].values[0]\n",
    "        self._intended_interaction = self._interactions[intended_interaction_key]\n",
    "        print(f\"Decision {self._decision}, Intended {self._intended_interaction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019f138-a218-44b2-964a-8095fbe891a7",
   "metadata": {},
   "source": [
    "# PRELIMINARY EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b09ce5-b4df-487d-9342-9daa7a77f4d4",
   "metadata": {},
   "source": [
    "## Test the agent in Environment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006e9d5c-9145-4b5a-9cf9-1a38b8374299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "class Environment6:\n",
    "    \"\"\" The grid \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize the grid \"\"\"\n",
    "        self.grid = np.array([[1, 0, 0, 1]])\n",
    "        self.position = 1\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        \"\"\"Take the action and generate the next outcome \"\"\"\n",
    "        if _action == 0:\n",
    "            # Move left\n",
    "            if self.position > 1:\n",
    "                # No bump\n",
    "                self.position -= 1\n",
    "                self.grid[0, -1] = 1\n",
    "                _outcome = 0\n",
    "            elif self.grid[0, 0] == 1:\n",
    "                # First bump\n",
    "                _outcome = 1\n",
    "                self.grid[0, 0] = 2\n",
    "            else:\n",
    "                # Subsequent bumps\n",
    "                _outcome = 0\n",
    "        else:\n",
    "            # Move right\n",
    "            if self.position < self.grid.shape[1] - 2:\n",
    "                # No bump\n",
    "                self.position += 1\n",
    "                self.grid[0, 0] = 1\n",
    "                _outcome = 0\n",
    "            elif self.grid[0, -1] == 1:\n",
    "                # First bump\n",
    "                _outcome = 1\n",
    "                self.grid[0, -1] = 2\n",
    "            else:\n",
    "                # Subsequent bumps\n",
    "                _outcome = 0\n",
    "        return _outcome\n",
    "        \n",
    "    def display(self):\n",
    "        \"\"\"Display the grid\"\"\"\n",
    "        out.clear_output(wait=True)\n",
    "        cmap = ListedColormap(['white', 'lightgreen', 'green'])\n",
    "        # Set up boundaries for color mapping (adjusts range for each value)\n",
    "        norm = BoundaryNorm([-0.5, 0.5, 1.5, 2.5], cmap.N)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            # Hide the ticks\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # Display the grid\n",
    "            ax.imshow(self.grid, cmap=cmap, norm=norm)\n",
    "            # ax.imshow(self.grid, cmap=cmap.N, vmin=0, vmax=3)\n",
    "            plt.scatter(self.position, 0, s=1000)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c423e8-de20-479c-84f7-8d64b3985433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate a new agent\n",
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1)\n",
    "]\n",
    "a = Agent(interactions)\n",
    "e = Environment6()\n",
    "\n",
    "# Output widget for displaying the plot\n",
    "out = Output()\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf97eb-7aca-4157-ba8e-3e97f2b85ae1",
   "metadata": {},
   "source": [
    "Run the simulation step by step to see the environment and the proposed DataFrame. Use `Ctrl+Enter` to run the cell bellow and stay on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0159e4d4-f851-432b-8127-63403d7a45c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad5b75d2ada40158180b95baac9fc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 640x480 with 1 Axes>', 'i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 1, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1\n",
      "Reinforcing (01:1, a1, 10:-1: 4)\n",
      "Reinforcing ((00:-1, a0, 01:1: 5), a1, 10:-1: 4)\n",
      "Reinforcing (00:-1, 01a1, (01:1, a1, 10:-1: 4): 4)\n",
      "Reinforcing ((11:1, a0, 00:-1: 4), 01a1, (01:1, a1, 10:-1: 4): 3)\n",
      "Decision a1, Intended 11:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activated</th>\n",
       "      <th>weight</th>\n",
       "      <th>post_interaction</th>\n",
       "      <th>valence</th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>primitive</th>\n",
       "      <th>proclivity_agg</th>\n",
       "      <th>intended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10,a1,11)</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>a1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10,a1,10)</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((01,a1,10),a1,11)</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>a1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10,11a1,(11,a1,10))</td>\n",
       "      <td>1</td>\n",
       "      <td>(11,a1,10)</td>\n",
       "      <td>0</td>\n",
       "      <td>11a1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(10,11a0,(11,a0,00))</td>\n",
       "      <td>4</td>\n",
       "      <td>(11,a0,00)</td>\n",
       "      <td>0</td>\n",
       "      <td>11a0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((01,a1,10),11a0,(11,a0,00))</td>\n",
       "      <td>3</td>\n",
       "      <td>(11,a0,00)</td>\n",
       "      <td>0</td>\n",
       "      <td>11a0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(10,00a0,(00,a0,01))</td>\n",
       "      <td>1</td>\n",
       "      <td>(00,a0,01)</td>\n",
       "      <td>0</td>\n",
       "      <td>00a0</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(10,a0,00)</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>-1</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(10,10a1,(10,a1,10))</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,a1,10)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(10,10a0,(10,a0,00))</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,a0,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a0</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       activated  weight post_interaction  valence decision  \\\n",
       "0                            NaN       0               10       -1       a1   \n",
       "1                     (10,a1,11)       5               11        1       a1   \n",
       "2                     (10,a1,10)       2               10       -1       a1   \n",
       "3             ((01,a1,10),a1,11)       3               11        1       a1   \n",
       "4           (10,11a1,(11,a1,10))       1       (11,a1,10)        0     11a1   \n",
       "5           (10,11a0,(11,a0,00))       4       (11,a0,00)        0     11a0   \n",
       "6   ((01,a1,10),11a0,(11,a0,00))       3       (11,a0,00)        0     11a0   \n",
       "7           (10,00a0,(00,a0,01))       1       (00,a0,01)        0     00a0   \n",
       "8                            NaN       0               00       -1       a0   \n",
       "9                     (10,a0,00)       1               00       -1       a0   \n",
       "10          (10,10a1,(10,a1,10))       1       (10,a1,10)       -2     10a1   \n",
       "11          (10,10a0,(10,a0,00))       1       (10,a0,00)       -2     10a0   \n",
       "\n",
       "    proclivity primitive  proclivity_agg intended  \n",
       "0            0        10               6       11  \n",
       "1            5        11               6       11  \n",
       "2           -2        10               6       11  \n",
       "3            3        11               6       11  \n",
       "4            0        11               0       11  \n",
       "5            0        11               0       11  \n",
       "6            0        11               0       11  \n",
       "7            0        00               0       00  \n",
       "8            0        00              -1       00  \n",
       "9           -1        00              -1       00  \n",
       "10          -2        10              -2       10  \n",
       "11          -2        10              -2       10  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "e.display()\n",
    "display(out)\n",
    "action = a.action(outcome)\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deac769-3595-4417-a3d8-f32c5de7afad",
   "metadata": {},
   "source": [
    "Observe that the agent learns to enact the positive interaction every second step, which is the best it can get in Environment6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f2924-f597-4d34-bc96-3602dc4460b7",
   "metadata": {},
   "source": [
    "## Let's Create Environment7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df34091-10a5-4566-9903-2ab263e48afd",
   "metadata": {},
   "source": [
    "Environment7 is similar to Environment6 but one cell wider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "122fdb10-7c6c-403a-9b9c-49f8a449bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment7(Environment6):\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize the grid \"\"\"\n",
    "        self.grid = np.array([[1, 0, 0, 0, 1]])\n",
    "        self.position = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1ad6b2a-bd8c-4209-a48b-8585e074b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate a new agent\n",
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1)\n",
    "]\n",
    "a = Agent(interactions)\n",
    "e = Environment7()\n",
    "\n",
    "# Output widget for displaying the plot\n",
    "out = Output()\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885f5dc1-da62-45bc-8685-1d2966659cdb",
   "metadata": {},
   "source": [
    "Run the simulation step by step to see Environment7 and the proposed DataFrame. Use Ctrl+Enter to run the cell bellow and stay on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc004733-e2af-4c06-9522-2ef57b8220ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bb6f41d516494f9a5937c9f1af3d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 640x480 with 1 Axes>', 'i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 1, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1\n",
      "Learning (10:-1, a1, 10:-1: 1)\n",
      "Learning ((00:-1, a1, 10:-1: 1), a1, 10:-1: 1)\n",
      "Learning (00:-1, 10a1, (10:-1, a1, 10:-1: 1): 1)\n",
      "Decision a0, Intended 00:-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activated</th>\n",
       "      <th>weight</th>\n",
       "      <th>post_interaction</th>\n",
       "      <th>valence</th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>primitive</th>\n",
       "      <th>proclivity_agg</th>\n",
       "      <th>intended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10,a1,10)</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    activated  weight post_interaction  valence decision  proclivity  \\\n",
       "0         NaN       0               00       -1       a0           0   \n",
       "1         NaN       0               10       -1       a1           0   \n",
       "2  (10,a1,10)       1               10       -1       a1          -1   \n",
       "\n",
       "  primitive  proclivity_agg intended  \n",
       "0        00               0       00  \n",
       "1        10              -1       10  \n",
       "2        10              -1       10  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "e.display()\n",
    "display(out)\n",
    "action = a.action(outcome)\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b5d18-c8c0-4dfd-bc60-a5c2bfe5fbdc",
   "metadata": {},
   "source": [
    "# Assignment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38d5b2-8837-42b5-b61f-d910d8a2806e",
   "metadata": {},
   "source": [
    "# Create Agent 8\n",
    "\n",
    "Modify the `learn()` method to record composite interaction from previous composite decisions\n",
    "\n",
    "It must keeps track of decisions that failed to enact and take them into account in making the next decision.\r\n",
    "\r\n",
    "\r\n",
    "When the post_interaction is a primitive interaction, the decision is always this post_interaction's action. When the post_interaction is a composite interaction, however, the decision may be a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855d0f1e-66ac-4ea5-80ce-a1309a203d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent8(Agent):\n",
    "    def learn(self):\n",
    "        \"\"\"Learn the composite interactions\"\"\"\n",
    "        # First level of composite interactions using the last primitive decision\n",
    "        # self._last_composite_interaction = self.learn_composite_interaction(\n",
    "        #     self._previous_interaction, self._last_interaction.get_decision(), self._last_interaction)\n",
    "        self._last_composite_interaction = self.learn_composite_interaction(\n",
    "            self._previous_interaction, self._decision, self._last_interaction)\n",
    "\n",
    "        # Second level of composite interactions \n",
    "        # self.learn_composite_interaction(self._previous_composite_interaction, self._last_interaction.get_decision(),\n",
    "        #                                  self._last_interaction)\n",
    "        self.learn_composite_interaction(\n",
    "            self._previous_composite_interaction, self._decision, self._last_interaction)\n",
    "\n",
    "        if self._last_composite_interaction is not None:\n",
    "            # Possibly create a new composite decision\n",
    "            decision = f\"{self._last_composite_interaction.pre_interaction.key()}{self._last_composite_interaction.post_interaction.get_decision()}\"\n",
    "            self.learn_composite_interaction(self._penultimate_interaction, decision, self._last_composite_interaction)\n",
    "            # self.learn_composite_interaction(self._penultimate_interaction, self._decision, self._last_composite_interaction)\n",
    "            self.learn_composite_interaction(self._penultimate_composite_interaction, decision, self._last_composite_interaction)\n",
    "\n",
    "    def decide(self):\n",
    "        \"\"\"Selects the intended interaction from the proposed dataframe\"\"\"\n",
    "\n",
    "        # Remove the proposed post_interaction that have a low weight\n",
    "        to_remove = set()\n",
    "        for i, k in self.proposed_df[\"post_interaction\"].items():\n",
    "            if k in self._composite_interactions and self._composite_interactions[k].weight <= 4:\n",
    "                to_remove.add(i)\n",
    "        self.proposed_df = self.proposed_df.drop(index=to_remove)\n",
    "\n",
    "        # Find the first row that has the highest proclivity\n",
    "        max_index = self.proposed_df['proclivity_agg'].idxmax()\n",
    "        self._decision = self.proposed_df.loc[max_index, ['decision']].values[0]\n",
    "\n",
    "        # Find the intended interaction corresponding to the action that has the highest proclivity\n",
    "        intended_interaction_key = self.proposed_df.loc[max_index, ['intended']].values[0]\n",
    "        self._intended_interaction = self._interactions[intended_interaction_key]\n",
    "        print(f\"Decision {self._decision}, Intended {self._intended_interaction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b63d0c-021d-4763-bd43-a15dfe24925d",
   "metadata": {},
   "source": [
    "## Test Agent8 in Environment7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "b06b1f2a-5d83-49b3-97ff-c88e391bf378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate a new agent\n",
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1)\n",
    "]\n",
    "a = Agent8(interactions)\n",
    "e = Environment7()\n",
    "\n",
    "# Output widget for displaying the plot\n",
    "out = Output()\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "id": "b4e2b69c-e7fd-4bd1-8591-0eb2450ee9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1f68ae310c43d192a83621f861d9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 640x480 with 1 Axes>', 'i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1\n",
      "Reinforcing (00:-1, a0, 01:1: 4)\n",
      "Reinforcing ((00:-1, a0, 00:-1: 7), a0, 01:1: 3)\n",
      "Reinforcing (00:-1, 00a0, (00:-1, a0, 01:1: 4): 3)\n",
      "Learning ((10:-1, 00a0, 00:-1: 1), 00a0, (00:-1, a0, 01:1: 4): 1)\n",
      "Decision a0, Intended 00:-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activated</th>\n",
       "      <th>weight</th>\n",
       "      <th>post_interaction</th>\n",
       "      <th>valence</th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>primitive</th>\n",
       "      <th>proclivity_agg</th>\n",
       "      <th>intended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-2</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(01,a0,00)</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>-1</td>\n",
       "      <td>00</td>\n",
       "      <td>-2</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((00,a0,01),a0,00)</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>-1</td>\n",
       "      <td>00</td>\n",
       "      <td>-2</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(01,a1,10)</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((00,a0,01),a1,10)</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(01,10a1,(10,a1,10))</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,a1,10)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((00,a0,01),10a1,(10,a1,10))</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,a1,10)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(01,10a0,(10,a0,00))</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,a0,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a0</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((00,a0,01),10a0,(10,a0,00))</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,a0,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a0</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(01,00a0,(00,a0,00))</td>\n",
       "      <td>1</td>\n",
       "      <td>(00,a0,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>00a0</td>\n",
       "      <td>-2</td>\n",
       "      <td>00</td>\n",
       "      <td>-4</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>((00,a0,01),00a0,(00,a0,00))</td>\n",
       "      <td>1</td>\n",
       "      <td>(00,a0,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>00a0</td>\n",
       "      <td>-2</td>\n",
       "      <td>00</td>\n",
       "      <td>-4</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       activated  weight post_interaction  valence decision  \\\n",
       "0                            NaN       0               00       -1       a0   \n",
       "1                     (01,a0,00)       1               00       -1       a0   \n",
       "2             ((00,a0,01),a0,00)       1               00       -1       a0   \n",
       "3                            NaN       0               10       -1       a1   \n",
       "4                     (01,a1,10)       2               10       -1       a1   \n",
       "5             ((00,a0,01),a1,10)       2               10       -1       a1   \n",
       "6           (01,10a1,(10,a1,10))       1       (10,a1,10)       -2     10a1   \n",
       "7   ((00,a0,01),10a1,(10,a1,10))       1       (10,a1,10)       -2     10a1   \n",
       "8           (01,10a0,(10,a0,00))       1       (10,a0,00)       -2     10a0   \n",
       "9   ((00,a0,01),10a0,(10,a0,00))       1       (10,a0,00)       -2     10a0   \n",
       "10          (01,00a0,(00,a0,00))       1       (00,a0,00)       -2     00a0   \n",
       "11  ((00,a0,01),00a0,(00,a0,00))       1       (00,a0,00)       -2     00a0   \n",
       "\n",
       "    proclivity primitive  proclivity_agg intended  \n",
       "0            0        00              -2       00  \n",
       "1           -1        00              -2       00  \n",
       "2           -1        00              -2       00  \n",
       "3            0        10              -4       10  \n",
       "4           -2        10              -4       10  \n",
       "5           -2        10              -4       10  \n",
       "6           -2        10              -4       10  \n",
       "7           -2        10              -4       10  \n",
       "8           -2        10              -4       10  \n",
       "9           -2        10              -4       10  \n",
       "10          -2        00              -4       00  \n",
       "11          -2        00              -4       00  "
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "e.display()\n",
    "display(out)\n",
    "action = a.action(outcome)\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6efd8c-c698-4136-a12c-23ec0e7134db",
   "metadata": {},
   "source": [
    "## Environment8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e97036e2-275d-4643-8965-038479a18894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "\n",
    "class Environment8:\n",
    "    \"\"\" The grid \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize the grid and the agent's pose \"\"\"\n",
    "        self.grid = np.array([[1, 0, 0, 1]])\n",
    "        self.position = 1\n",
    "        self.direction = 0\n",
    "\n",
    "    def outcome(self, action):\n",
    "        \"\"\"Take the action and generate the next outcome \"\"\"\n",
    "        if action == 0:\n",
    "            # Move forward\n",
    "            if self.direction == 0:\n",
    "                # Move to the left\n",
    "                if self.position > 1:\n",
    "                    # No bump\n",
    "                    self.position -= 1\n",
    "                    self.grid[0, 3] = 1\n",
    "                    outcome = 0\n",
    "                elif self.grid[0, 0] == 1:\n",
    "                    # First bump\n",
    "                    outcome = 1\n",
    "                    self.grid[0, 0] = 2\n",
    "                else:\n",
    "                    # Subsequent bumps\n",
    "                    outcome = 0\n",
    "            else:\n",
    "                # Move to the right\n",
    "                if self.position < 2:\n",
    "                    # No bump\n",
    "                    self.position += 1\n",
    "                    self.grid[0, 0] = 1\n",
    "                    outcome = 0\n",
    "                elif self.grid[0, 3] == 1:\n",
    "                    # First bump\n",
    "                    outcome = 1\n",
    "                    self.grid[0, 3] = 2\n",
    "                else:\n",
    "                    # Subsequent bumps\n",
    "                    outcome = 0\n",
    "        else:\n",
    "            # Turn 180°\n",
    "            outcome = 0\n",
    "            if self.direction == 0:\n",
    "                self.direction = 1\n",
    "            else:\n",
    "                self.direction = 0\n",
    "        return outcome  \n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display the grid\"\"\"\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots()\n",
    "            # Hide the ticks\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # Display the grid\n",
    "            ax.imshow(self.grid, cmap='Greens', vmin=0, vmax=2)\n",
    "            if self.direction == 0:\n",
    "                # Display agent to the left\n",
    "                plt.scatter(self.position, 0, s=1000, marker='<')\n",
    "            else:\n",
    "                # Display agent to the right\n",
    "                plt.scatter(self.position, 0, s=1000, marker='>')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82801853-2aef-44a7-8acd-ae2d621048bb",
   "metadata": {},
   "source": [
    "## Run the agent in Environment8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0a601-4268-4757-8bdb-8ffb93a559a2",
   "metadata": {},
   "source": [
    "In Environment7, the agent has two possible actions: move forward or turn 180°.\n",
    "Like Environment6, Environment7 return 1 only when the agent bumps into a wall once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6d76df-89e4-4ab3-a327-afa813a27325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the agent in Environment7\n",
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1)\n",
    "]\n",
    "a = Agent8(interactions)\n",
    "e = Environment8()\n",
    "\n",
    "# Output widget for displaying the plot\n",
    "out = Output()\n",
    "\n",
    "# Run the interaction loop\n",
    "step = 0\n",
    "outcome = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b044b4d-162e-4491-929c-a73eb584dcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aebeff772654d0580e75f430968b2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 640x480 with 1 Axes>', 'i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1\n",
      "Reinforcing (10:-1, 01a1, 00:-1: 5)\n",
      "Learning ((00:-1, 10a1, 10:-1: 2), 01a1, 00:-1: 1)\n",
      "Reinforcing (00:-1, 10a0, (10:-1, 01a1, 00:-1: 5): 2)\n",
      "Reinforcing ((00:-1, 01a1, 00:-1: 11), 10a0, (10:-1, 01a1, 00:-1: 5): 2)\n",
      "Decision 01a1, Intended 00:-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activated</th>\n",
       "      <th>weight</th>\n",
       "      <th>post_interaction</th>\n",
       "      <th>valence</th>\n",
       "      <th>decision</th>\n",
       "      <th>proclivity</th>\n",
       "      <th>primitive</th>\n",
       "      <th>proclivity_agg</th>\n",
       "      <th>intended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(00,01a1,(01,a1,10))</td>\n",
       "      <td>5</td>\n",
       "      <td>(01,a1,10)</td>\n",
       "      <td>0</td>\n",
       "      <td>01a1</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>-3</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(00,01a1,01)</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01a1</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>-3</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((10,01a1,00),01a1,01)</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01a1</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>-3</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(00,01a1,00)</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>01a1</td>\n",
       "      <td>-11</td>\n",
       "      <td>00</td>\n",
       "      <td>-3</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((10,01a1,00),01a1,(01,a1,10))</td>\n",
       "      <td>1</td>\n",
       "      <td>(01,a1,10)</td>\n",
       "      <td>0</td>\n",
       "      <td>01a1</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>-3</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(00,01a0,(01,a0,00))</td>\n",
       "      <td>6</td>\n",
       "      <td>(01,a0,00)</td>\n",
       "      <td>0</td>\n",
       "      <td>01a0</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>-6</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((10,01a1,00),01a0,(01,a0,00))</td>\n",
       "      <td>2</td>\n",
       "      <td>(01,a0,00)</td>\n",
       "      <td>0</td>\n",
       "      <td>01a0</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>-6</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(00,01a0,00)</td>\n",
       "      <td>6</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>01a0</td>\n",
       "      <td>-6</td>\n",
       "      <td>00</td>\n",
       "      <td>-6</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-9</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(00,a0,01)</td>\n",
       "      <td>9</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>a0</td>\n",
       "      <td>9</td>\n",
       "      <td>01</td>\n",
       "      <td>-9</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(00,a0,00)</td>\n",
       "      <td>18</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>a0</td>\n",
       "      <td>-18</td>\n",
       "      <td>00</td>\n",
       "      <td>-9</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(00,a1,10)</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>a1</td>\n",
       "      <td>-10</td>\n",
       "      <td>10</td>\n",
       "      <td>-10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(00,10a1,(10,a1,10))</td>\n",
       "      <td>3</td>\n",
       "      <td>(10,a1,10)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a1</td>\n",
       "      <td>-6</td>\n",
       "      <td>10</td>\n",
       "      <td>-10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(00,10a1,10)</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>10a1</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>-10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(00,10a0,(10,a0,00))</td>\n",
       "      <td>2</td>\n",
       "      <td>(10,a0,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a0</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "      <td>-16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(00,10a0,(10,00a1,00))</td>\n",
       "      <td>3</td>\n",
       "      <td>(10,00a1,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a0</td>\n",
       "      <td>-6</td>\n",
       "      <td>10</td>\n",
       "      <td>-16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(00,10a0,(10,01a1,00))</td>\n",
       "      <td>2</td>\n",
       "      <td>(10,01a1,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>10a0</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "      <td>-16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(00,00a1,(00,a1,10))</td>\n",
       "      <td>8</td>\n",
       "      <td>(00,a1,10)</td>\n",
       "      <td>-2</td>\n",
       "      <td>00a1</td>\n",
       "      <td>-16</td>\n",
       "      <td>00</td>\n",
       "      <td>-20</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(00,00a0,(00,a0,00))</td>\n",
       "      <td>10</td>\n",
       "      <td>(00,a0,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>00a0</td>\n",
       "      <td>-20</td>\n",
       "      <td>00</td>\n",
       "      <td>-53</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(00,00a0,00)</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>-1</td>\n",
       "      <td>00a0</td>\n",
       "      <td>-1</td>\n",
       "      <td>00</td>\n",
       "      <td>-53</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(00,00a0,(00,01a1,00))</td>\n",
       "      <td>9</td>\n",
       "      <td>(00,01a1,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>00a0</td>\n",
       "      <td>-18</td>\n",
       "      <td>00</td>\n",
       "      <td>-53</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(00,00a0,(00,01a0,00))</td>\n",
       "      <td>6</td>\n",
       "      <td>(00,01a0,00)</td>\n",
       "      <td>-2</td>\n",
       "      <td>00a0</td>\n",
       "      <td>-12</td>\n",
       "      <td>00</td>\n",
       "      <td>-53</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         activated  weight post_interaction  valence decision  \\\n",
       "0             (00,01a1,(01,a1,10))       5       (01,a1,10)        0     01a1   \n",
       "2                     (00,01a1,01)       4               01        1     01a1   \n",
       "3           ((10,01a1,00),01a1,01)       4               01        1     01a1   \n",
       "4                     (00,01a1,00)      11               00       -1     01a1   \n",
       "7   ((10,01a1,00),01a1,(01,a1,10))       1       (01,a1,10)        0     01a1   \n",
       "8             (00,01a0,(01,a0,00))       6       (01,a0,00)        0     01a0   \n",
       "9   ((10,01a1,00),01a0,(01,a0,00))       2       (01,a0,00)        0     01a0   \n",
       "10                    (00,01a0,00)       6               00       -1     01a0   \n",
       "11                             NaN       0               00       -1       a0   \n",
       "12                      (00,a0,01)       9               01        1       a0   \n",
       "13                      (00,a0,00)      18               00       -1       a0   \n",
       "14                             NaN       0               10       -1       a1   \n",
       "15                      (00,a1,10)      10               10       -1       a1   \n",
       "16            (00,10a1,(10,a1,10))       3       (10,a1,10)       -2     10a1   \n",
       "17                    (00,10a1,10)       2               10       -1     10a1   \n",
       "19            (00,10a0,(10,a0,00))       2       (10,a0,00)       -2     10a0   \n",
       "21          (00,10a0,(10,00a1,00))       3     (10,00a1,00)       -2     10a0   \n",
       "22          (00,10a0,(10,01a1,00))       2     (10,01a1,00)       -2     10a0   \n",
       "23            (00,00a1,(00,a1,10))       8       (00,a1,10)       -2     00a1   \n",
       "25            (00,00a0,(00,a0,00))      10       (00,a0,00)       -2     00a0   \n",
       "26                    (00,00a0,00)       1               00       -1     00a0   \n",
       "28          (00,00a0,(00,01a1,00))       9     (00,01a1,00)       -2     00a0   \n",
       "29          (00,00a0,(00,01a0,00))       6     (00,01a0,00)       -2     00a0   \n",
       "\n",
       "    proclivity primitive  proclivity_agg intended  \n",
       "0            0        01              -3       00  \n",
       "2            4        01              -3       00  \n",
       "3            4        01              -3       00  \n",
       "4          -11        00              -3       00  \n",
       "7            0        01              -3       00  \n",
       "8            0        01              -6       01  \n",
       "9            0        01              -6       01  \n",
       "10          -6        00              -6       01  \n",
       "11           0        00              -9       00  \n",
       "12           9        01              -9       00  \n",
       "13         -18        00              -9       00  \n",
       "14           0        10             -10       10  \n",
       "15         -10        10             -10       10  \n",
       "16          -6        10             -10       10  \n",
       "17          -2        10             -10       10  \n",
       "19          -4        10             -16       10  \n",
       "21          -6        10             -16       10  \n",
       "22          -4        10             -16       10  \n",
       "23         -16        00             -20       00  \n",
       "25         -20        00             -53       00  \n",
       "26          -1        00             -53       00  \n",
       "28         -18        00             -53       00  \n",
       "29         -12        00             -53       00  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Step {step}\")\n",
    "step += 1\n",
    "e.display()\n",
    "display(out)\n",
    "action = a.action(outcome)\n",
    "outcome = e.outcome(action)\n",
    "a.proposed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ee7cb-e6ff-4350-ac5b-064f5c5e14b2",
   "metadata": {},
   "source": [
    "Observe that the agent gets stuck and keeps bumping into the right wall from Step 11 on.\n",
    "\n",
    "This is because the proposed decision 01a0 is never counter balanced by the fact that the first action `0` retuns outcome `0`.\n",
    "\n",
    "Let's implement Agent8 that can reverse its decision!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50d96e-4f12-4531-a122-9d13d8bd8639",
   "metadata": {},
   "source": [
    "# ASSIGNMENT (UNDER CONSTRUCTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abf06ea-5925-4590-80dd-f9284f4306a6",
   "metadata": {},
   "source": [
    "We will create Agent8 who keeps track of decisions that failed to enact and take them into account in making the next decision.\n",
    "\n",
    "We modify the definition of composite interaction to become a triple (pre_interaction, decision, post_interaction)\n",
    "\n",
    "When the post_interaction is a primitive interaction, the decision is always this post_interaction's action. \n",
    "When the post_interaction is a composite interaction, however, the decision may be a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "2e150c60-5315-4a49-822f-2681fb22a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent8(Agent):\n",
    "    # *** Modify to aggregate by decision rather than by action***\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad29cd9d-c2a3-411a-b9ce-8f56fc023add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAGiCAYAAACVsa6/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAorklEQVR4nO3de3xU9Z3/8fckmAm0TCBiLkC4GQXkEu4hWCGu0QisSh8tRbQlIODaTVogPsomroKAbeoVaqFFl0qKwgpWLiuysJAQWCSA3FauWUEEZEmAIolESCBzfn/4Y9qRBMmQMxe+r+fjcR6PnDPf7/d8vp2O5805Z+Y4LMuyBAAAjBQW6AIAAEDgEAQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADAYQQAAAIMRBAAAMJhtQeDs2bN6/PHH5XK51KxZM40dO1bnz5+/Zp/U1FQ5HA6v5amnnrKrRAAAjOew61kDgwcP1smTJ/XGG2/o0qVLGjNmjPr27atFixbV2Sc1NVV33nmnpk+f7tnWpEkTuVwuO0oEAMB4jewY9MCBA1q9erU+/vhj9enTR5L0+9//XkOGDNErr7yili1b1tm3SZMmiouLs6MsAADwLbYEgeLiYjVr1swTAiQpLS1NYWFh2rp1q374wx/W2XfhwoV65513FBcXp4ceekjPPfecmjRpUmf7qqoqVVVVedbdbrfOnj2rW2+9VQ6Ho2EmBADwG8uy9NVXX6lly5YKC7PvVraLFy+qurr6hseJiIhQZGRkA1QUGLYEgdLSUsXExHjvqFEjRUdHq7S0tM5+jz32mNq2bauWLVvqk08+0b/8y7+opKRES5curbNPXl6epk2b1mC1AwCCw/Hjx9W6dWtbxr548aLaN26suo9I18/lcik+Pl5hYWHKzMxUZmZmA4zqP/UKAjk5OXrxxRev2ebAgQM+F/Pkk096/u7WrZvi4+N133336fDhw7r99ttr7ZObm6vs7GzPenl5udq0aaPn9zyvyKahm9BwfXKm5AS6BPhR+YJAVwB/qJCUIKlp06a27aO6ulqlko5LupG70CokJVRU6Pjx4yF7P1u9gsDTTz+t0aNHX7NNhw4dFBcXp1OnTnltv3z5ss6ePVuv6//JycmSpEOHDtUZBJxOp5xO51XbI5tGKtJFELjpRQS6APhTaP5nFr7yx+Vdl/j/Vb2CwG233abbbrvtO9ulpKTo3Llz2rFjh3r37i1JKiwslNvt9hzcr8fu3bslSfHx8fUpEwAAXCdb7sLo3LmzHnzwQY0fP17btm3TRx99pKysLD366KOebwycOHFCnTp10rZt2yRJhw8f1owZM7Rjxw59/vnn+o//+A+NGjVKAwcOVPfu3e0oEwAA49l2O+bChQvVqVMn3XfffRoyZIh+8IMf6M033/S8funSJZWUlOjrr7+W9M1dl+vWrdMDDzygTp066emnn9aPfvQjffDBB3aVCACA8Wz51oAkRUdHX/PHg9q1a6e//y2jhIQEbdiwwa5yAABALXjWAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGsz0IzJkzR+3atVNkZKSSk5O1bdu2a7Z/77331KlTJ0VGRqpbt25atWqV3SUCAOAXeXl56tu3r5o2baqYmBgNGzZMJSUlAa3J1iCwePFiZWdna+rUqdq5c6eSkpKUnp6uU6dO1dp+8+bNGjlypMaOHatdu3Zp2LBhGjZsmPbu3WtnmQAA+MWGDRuUmZmpLVu2aO3atbp06ZIeeOABVVZWBqwmh2VZll2DJycnq2/fvpo9e7Ykye12KyEhQb/4xS+Uk5NzVfsRI0aosrJSK1eu9Gzr37+/evTooblz59a6j6qqKlVVVXnWKyoqlJCQoN9+/ltFuiIbeEYINhMnTwx0CfAja16gK4A/VEiKklReXi6Xy2XPPioqFBUVpXJJN7KHK7UeP37cq1an0ymn0/md/U+fPq2YmBht2LBBAwcOvIFKfGfbGYHq6mrt2LFDaWlpf9tZWJjS0tJUXFxca5/i4mKv9pKUnp5eZ3vpm9MsUVFRniUhIaFhJgAAwHVKSEjwOhbl5eVdV7/y8nJJUnR0tJ3lXVMjuwY+c+aMampqFBsb67U9NjZWBw8erLVPaWlpre1LS0vr3E9ubq6ys7M961fOCAAA4C+1nRH4Lm63WxMnTtTdd9+trl272lneNdkWBPzlek+/AABgF5fLVe/LGJmZmdq7d682bdpkU1XXx7Yg0KJFC4WHh6usrMxre1lZmeLi4mrtExcXV6/2AACEoqysLK1cuVIbN25U69atA1qLbfcIREREqHfv3iooKPBsc7vdKigoUEpKSq19UlJSvNpL0tq1a+tsDwBAKLEsS1lZWVq2bJkKCwvVvn37QJdk76WB7OxsZWRkqE+fPurXr59mzZqlyspKjRkzRpI0atQotWrVynNTxYQJEzRo0CC9+uqrGjp0qN59911t375db775pp1lAgDgF5mZmVq0aJFWrFihpk2beu6Bi4qKUuPGjQNSk61BYMSIETp9+rSmTJmi0tJS9ejRQ6tXr/bcEHjs2DGFhf3tpMSAAQO0aNEiPfvss3rmmWd0xx13aPny5QG9iQIAgIbyxz/+UZKUmprqtX3+/PkaPXq0/wuSzb8jEAhXvhvK7wiYgd8RMAu/I2CGUPwdATtrtRvPGgAAwGAEAQAADEYQAADAYAQBAAAMRhAAAMBgBAEAAAxGEAAAwGAEAQAADEYQAADAYAQBAAAMRhAAAMBgBAEAAAxGEAAAwGAEAQAADEYQAADAYAQBAAAMRhAAAMBgBAEAAAxGEAAAwGAEAQAADEYQAADAYAQBAAAMRhAAAMBgBAEAAAxGEAAAwGAEAQAADEYQAADAYAQBAAAMRhAAAMBgBAEAAAxGEAAAwGAEAQAADEYQAADAYAQBAAAMRhAAAMBgBAEAAAxGEAAAwGAEAQAADEYQAADAYAQBAAAMRhAAAMBgBAEAAAxGEAAAwGAEAQAADEYQAADAYAQBAAAMRhAAAMBgBAEAAAxGEAAAwGAEAQAADGZ7EJgzZ47atWunyMhIJScna9u2bXW2zc/Pl8Ph8FoiIyPtLhEAAGPZGgQWL16s7OxsTZ06VTt37lRSUpLS09N16tSpOvu4XC6dPHnSsxw9etTOEgEAMJqtQeC1117T+PHjNWbMGN11112aO3eumjRporfeeqvOPg6HQ3FxcZ4lNjbWzhIBADBaI7sGrq6u1o4dO5Sbm+vZFhYWprS0NBUXF9fZ7/z582rbtq3cbrd69eql3/zmN+rSpUud7auqqlRVVeVZr6iokCT9vF2OXA0wDwS3ieMCXQH86XdnZwW6BPjBxYqLUrucQJdhDNuCwJkzZ1RTU3PVv+hjY2N18ODBWvt07NhRb731lrp3767y8nK98sorGjBggPbt26fWrVvX2icvL0/Tpk1r8PoBADe/qFGSIm5ggGpJC6S+ffsqPDxcmZmZyszMbKDq/MO2IOCLlJQUpaSkeNYHDBigzp0764033tCMGTNq7ZObm6vs7GzPekVFhRISEmyvFQCAKz7++GO5XKF5Htq2INCiRQuFh4errKzMa3tZWZni4uKua4xbbrlFPXv21KFDh+ps43Q65XQ6b6hWAABMZdvNghEREerdu7cKCgo829xutwoKCrz+1X8tNTU12rNnj+Lj4+0qEwAAo9l6aSA7O1sZGRnq06eP+vXrp1mzZqmyslJjxoyRJI0aNUqtWrVSXl6eJGn69Onq37+/EhMTde7cOb388ss6evSoxo3jjjAAAOxgaxAYMWKETp8+rSlTpqi0tFQ9evTQ6tWrPTcQHjt2TGFhfzsp8eWXX2r8+PEqLS1V8+bN1bt3b23evFl33XWXnWUCAGAsh2VZVqCLaEgVFRWKiopSucTXBw3g4GSRUWa9NCvQJcAPLlZcVE67HJWXl9t2A96VY4Ua6FsDdtZqN541AACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAhKCamhrt3r1bX3755Q2NQxAAACAETJw4UX/6058kfRMCBg0apF69eikhIUFFRUU+j0sQAAAgBPzlL39RUlKSJOmDDz7QkSNHdPDgQU2aNEn/+q//6vO4BAEAAELAmTNnFBcXJ0latWqVhg8frjvvvFNPPPGE9uzZ4/O4BAEAAEJAbGys9u/fr5qaGq1evVr333+/JOnrr79WeHi4z+M2aqgCAQCAfcaMGaOf/OQnio+Pl8PhUFpamiRp69at6tSpk8/jEgQAAAgBzz//vLp27arjx49r+PDhcjqdkqTw8HDl5OT4PC5BAACAEPHjH/9YknTx4kXPtoyMjBsak3sEAAAIATU1NZoxY4ZatWql73//+/rss88kSc8995zna4W+IAgAABACfv3rXys/P18vvfSSIiIiPNu7du2qefPm+TwuQQAAgBCwYMECvfnmm3r88ce9viWQlJSkgwcP+jwuQQAAgBBw4sQJJSYmXrXd7Xbr0qVLPo9LEAAAIATcdddd+u///u+rtv/lL39Rz549fR6Xbw0AABACpkyZooyMDJ04cUJut1tLly5VSUmJFixYoJUrV/o8LmcEAAAIAY888og++OADrVu3Tt/73vc0ZcoUHThwQB988IHnVwZ9wRkBAABCxD333KO1a9c26JicEQAAwGCcEQAAIASEhYXJ4XDU+XpNTY1P4xIEAAAIAcuWLfNav3Tpknbt2qU///nPmjZtms/jEgQAAAgBjzzyyFXbfvzjH6tLly5avHixxo4d69O43CMAAEAI69+/vwoKCnzuTxAAACBEXbhwQa+//rpatWrl8xhcGgAAIAQ0b97c62ZBy7L01VdfqUmTJnrnnXd8HpcgAABACJg5c6ZXEAgLC9Ntt92m5ORkNW/e3OdxCQIAAISA0aNH2zIuQQAAgCD1ySefXHfb7t27+7QPggAAAEGqR48ecjgcsizrmu0cDgc/KAQAwM3myJEjtu+DIAAAQJBq27at7fsgCAAAEEL279+vY8eOqbq62mv7ww8/7NN4BAEAAELAZ599ph/+8Ifas2eP130DV75S6Os9AvyyIAAAIWDChAlq3769Tp06pSZNmmjfvn3auHGj+vTpo6KiIp/H5YwAAAAhoLi4WIWFhWrRooXCwsIUFhamH/zgB8rLy9Mvf/lL7dq1y6dxOSMAAEAIqKmpUdOmTSVJLVq00P/93/9J+uaGwpKSEp/HtTUIbNy4UQ899JBatmwph8Oh5cuXf2efoqIi9erVS06nU4mJicrPz7ezRAAA/MaX4+IVXbt21f/8z/9IkpKTk/XSSy/po48+0vTp09WhQwefa7I1CFRWViopKUlz5sy5rvZHjhzR0KFDde+992r37t2aOHGixo0bpzVr1thZJgAAflHf4+Lfe/bZZ+V2uyVJ06dP15EjR3TPPfdo1apVev31132uydZ7BAYPHqzBgwdfd/u5c+eqffv2evXVVyVJnTt31qZNmzRz5kylp6fX2qeqqkpVVVWe9YqKihsrGgCAevr2scfpdMrpdF7Vrr7HRUnq06ePxo0bp8cee0wul0uSlJiYqIMHD+rs2bNXPZWwvoLqHoHi4mKlpaV5bUtPT1dxcXGdffLy8hQVFeVZEhIS7C4TAAAvCQkJXseivLy8Bhs7KSlJkydPVnx8vEaNGuX1DYHo6OgbCgFSkAWB0tJSxcbGem2LjY1VRUWFLly4UGuf3NxclZeXe5bjx4/7o1QAADyOHz/udSzKzc1tsLH/9Kc/qbS0VHPmzNGxY8d03333KTExUb/5zW904sSJGx4/qIKAL5xOp1wul9cCAIA/ffs4VNtlgRvRpEkTjR49WkVFRfrf//1fPfroo3rjjTfUrl07DR06VEuXLvV57KAKAnFxcSorK/PaVlZWJpfLpcaNGweoKgAAgsftt9+uF154QZ9//rn+/d//XVu2bNHw4cN9Hi+oflAoJSVFq1at8tq2du1apaSkBKgiAACCT1FRkebPn6/3339fjRo10vjx430ey9YgcP78eR06dMizfuTIEe3evVvR0dFq06aNcnNzdeLECS1YsECS9NRTT2n27NmaPHmynnjiCRUWFmrJkiX68MMP7SwTAAC/+K7j4rV88cUXys/PV35+vj777DPdc889+sMf/qDhw4ff0FlzW4PA9u3bde+993rWs7OzJUkZGRnKz8/XyZMndezYMc/r7du314cffqhJkybpd7/7nVq3bq158+bV+dVBAABCyXcdF2uzZMkSvfXWWyooKFBMTIwyMjL0xBNPKDExsUFqsjUIpKamep6OVJvaJp2amurz7yUDABDMvuu4WJuf/vSnGjp0qJYtW6YhQ4YoLKxhb+8LqnsEAACAty+++EIxMTG2jR9U3xoAAADe7AwBEkEAAACjEQQAADAYQQAAAIMRBAAAMBjfGgAAIEjV5xHDZ8+e9WkfBAEAAILUrFmzPH//9a9/1QsvvKD09HTPT+8XFxdrzZo1eu6553zeB0EAAIAglZGR4fn7Rz/6kaZPn66srCzPtl/+8peaPXu21q1bp0mTJvm0D+4RAAAgBKxZs0YPPvjgVdsffPBBrVu3zudxCQIAAISAW2+9VStWrLhq+4oVK3Trrbf6PC6XBgAACAHTpk3TuHHjVFRUpOTkZEnS1q1btXr1av3bv/2bz+MSBAAACAGjR49W586d9frrr2vp0qWSpM6dO2vTpk2eYOALggAAACEiOTlZCxcubNAxCQIAAASpiooKuVwuz9/XcqVdfREEAAAIUs2bN9fJkycVExOjZs2a1frjQpZlyeFwqKamxqd9EAQAAAhShYWFio6OliStX7/eln0QBAAACFKDBg2SJF2+fFkbNmzQE088odatWzfoPvgdAQAAglyjRo308ssv6/Llyw0+NkEAAIAQ8A//8A/asGFDg4/LpQEAAELA4MGDlZOToz179qh379763ve+5/X6ww8/7NO4BAEAAELAP//zP0uSXnvttate41sDAADc5Nxuty3jco8AAAAG44wAAABB7MKFCyooKNA//uM/SpJyc3NVVVXleT08PFwzZsxQZGSkT+MTBAAACGJ//vOf9eGHH3qCwOzZs9WlSxc1btxYknTw4EG1bNlSkyZN8ml8Lg0AABDEFi5cqCeffNJr26JFi7R+/XqtX79eL7/8spYsWeLz+AQBAACC2KFDh9StWzfPemRkpMLC/nb47tevn/bv3+/z+FwaAAAgiJ07d87rnoDTp097ve52u71ery/OCAAAEMRat26tvXv31vn6J598ckPPHyAIAAAQxIYMGaIpU6bo4sWLV7124cIFTZs2TUOHDvV5fC4NAAAQxJ555hktWbJEHTt2VFZWlu68805JUklJiWbPnq3Lly/rmWee8Xl8ggAAAEEsNjZWmzdv1s9//nPl5OTIsixJ3/ys8P33368//OEPio2N9Xl8ggAAAEGuffv2Wr16tc6ePatDhw5JkhITExUdHX3DYxMEAAAIEdHR0erXr1+DjsnNggAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYzNYgsHHjRj300ENq2bKlHA6Hli9ffs32RUVFcjgcVy2lpaV2lgkAgLFsDQKVlZVKSkrSnDlz6tWvpKREJ0+e9CwxMTE2VQgAgNka2Tn44MGDNXjw4Hr3i4mJUbNmzRq+IAAA4MXWIOCrHj16qKqqSl27dtXzzz+vu+++u862VVVVqqqq8qxXVFRIkqJGSYqwu1IEmjUv0BXAnxyaGOgS4A/VgS7ALEEVBOLj4zV37lz16dNHVVVVmjdvnlJTU7V161b16tWr1j55eXmaNm2anysFANwMfjv9t4p0Rfrc/2LFReUsyFHfvn0VHh6uzMxMZWZmNmCF9guqINCxY0d17NjRsz5gwAAdPnxYM2fO1Ntvv11rn9zcXGVnZ3vWKyoqlJCQYHutAABc8fHHH8vlcgW6DJ8EVRCoTb9+/bRp06Y6X3c6nXI6nX6sCACAm0fQ/47A7t27FR8fH+gyAAC4Kdl6RuD8+fM6dOiQZ/3IkSPavXu3oqOj1aZNG+Xm5urEiRNasGCBJGnWrFlq3769unTpoosXL2revHkqLCzUf/3Xf9lZJgAAxrI1CGzfvl333nuvZ/3KtfyMjAzl5+fr5MmTOnbsmOf16upqPf300zpx4oSaNGmi7t27a926dV5jAACAhmNrEEhNTZVlWXW+np+f77U+efJkTZ482c6SAADA3wn6ewQAAIB9CAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMEIAgAAGIwgAACAwQgCAAAYjCAAAIDBCAIAABiMIAAAgMFsDQJ5eXnq27evmjZtqpiYGA0bNkwlJSXf2e+9995Tp06dFBkZqW7dumnVqlV2lgkAgF/NmTNH7dq1U2RkpJKTk7Vt27aA1WJrENiwYYMyMzO1ZcsWrV27VpcuXdIDDzygysrKOvts3rxZI0eO1NixY7Vr1y4NGzZMw4YN0969e+0sFQAAv1i8eLGys7M1depU7dy5U0lJSUpPT9epU6cCUo/DsizLXzs7ffq0YmJitGHDBg0cOLDWNiNGjFBlZaVWrlzp2da/f3/16NFDc+fO/c59VFRUKCoqSholKaKhKkewsuYFugL4k2NcoCuAX1RLWiCVl5fL5XLZsosrx4rffv5bRboifR7nYsVF5bTLqVetycnJ6tu3r2bPni1JcrvdSkhI0C9+8Qvl5OT4XIuv/HqPQHl5uSQpOjq6zjbFxcVKS0vz2paenq7i4uJa21dVVamiosJrAQDAn759HKqqqqq1XXV1tXbs2OF1nAsLC1NaWlqdxzm7+S0IuN1uTZw4UXfffbe6du1aZ7vS0lLFxsZ6bYuNjVVpaWmt7fPy8hQVFeVZEhISGrRuAAC+S0JCgtexKC8vr9Z2Z86cUU1NTb2Oc3Zr5K8dZWZmau/evdq0aVODjpubm6vs7GzPekVFBWEAAOBXx48f97o04HQ6A1hN/fglCGRlZWnlypXauHGjWrdufc22cXFxKisr89pWVlamuLi4Wts7nc6Q+h8cAHDzcblc13WPQIsWLRQeHl6v45zdbL00YFmWsrKytGzZMhUWFqp9+/bf2SclJUUFBQVe29auXauUlBS7ygQAwC8iIiLUu3dvr+Oc2+1WQUFBwI5ztp4RyMzM1KJFi7RixQo1bdrUc/0jKipKjRs3liSNGjVKrVq18lxPmTBhggYNGqRXX31VQ4cO1bvvvqvt27frzTfftLNUAAD8Ijs7WxkZGerTp4/69eunWbNmqbKyUmPGjAlIPbYGgT/+8Y+SpNTUVK/t8+fP1+jRoyVJx44dU1jY305MDBgwQIsWLdKzzz6rZ555RnfccYeWL19+zRsMAQAIFSNGjNDp06c1ZcoUlZaWqkePHlq9evVVNxD6i61B4Hp+oqCoqOiqbcOHD9fw4cNtqAgAgMDLyspSVlZWoMuQxLMGAAAwGkEAAACDEQQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADAYQQAAAIMRBAAAMBhBAAAAgxEEAAAwGEEAAACDEQQAADCYrUEgLy9Pffv2VdOmTRUTE6Nhw4appKTkmn3y8/PlcDi8lsjISDvLBADAWLYGgQ0bNigzM1NbtmzR2rVrdenSJT3wwAOqrKy8Zj+Xy6WTJ096lqNHj9pZJgAAxmpk5+CrV6/2Ws/Pz1dMTIx27NihgQMH1tnP4XAoLi7uuvZRVVWlqqoqz3p5efk3f1TXv16EnopAFwD/4nNthv//PluWZfuuLn51MaD9g4LlR59++qklydqzZ0+dbebPn2+Fh4dbbdq0sVq3bm09/PDD1t69e+tsP3XqVEsSCwsLC8tNthw+fNiOQ5FlWZZ14cIFKy4urkHqdLlcVseOHa3OnTtbs2fPtq1muzgsyw+RS5Lb7dbDDz+sc+fOadOmTXW2Ky4u1qeffqru3burvLxcr7zyijZu3Kh9+/apdevWV7X/9hmBc+fOqW3btjp27JiioqJsmUswqqioUEJCgo4fPy6XyxXocvzCxDlLzNukeZs4Z+mbM7tt2rTRl19+qWbNmtm2n4sXL6q6+sZPM0VERIT0vWy2Xhr4e5mZmdq7d+81Q4AkpaSkKCUlxbM+YMAAde7cWW+88YZmzJhxVXun0ymn03nV9qioKKM+OFe4XC7j5m3inCXmbRIT5yxJYWH2frEtMjIypA/gDcUvQSArK0srV67Uxo0ba/1X/bXccsst6tmzpw4dOmRTdQAAmMvWuGVZlrKysrRs2TIVFhaqffv29R6jpqZGe/bsUXx8vA0VAgBgNlvPCGRmZmrRokVasWKFmjZtqtLSUknfnLZv3LixJGnUqFFq1aqV8vLyJEnTp09X//79lZiYqHPnzunll1/W0aNHNW7cuOvap9Pp1NSpU2u9XHAzM3HeJs5ZYt4mzdvEOUvmzjtQbL1Z0OFw1Lp9/vz5Gj16tCQpNTVV7dq1U35+viRp0qRJWrp0qUpLS9W8eXP17t1bL7zwgnr27GlXmQAAGMtv3xoAAADBh2cNAABgMIIAAAAGIwgAAGAwggAAAAa7KYLA2bNn9fjjj8vlcqlZs2YaO3aszp8/f80+qampVz3u+KmnnvJTxb6ZM2eO2rVrp8jISCUnJ2vbtm3XbP/ee++pU6dOioyMVLdu3bRq1So/Vdpw6jPnm+UR1hs3btRDDz2kli1byuFwaPny5d/Zp6ioSL169ZLT6VRiYqLnWzihor5zLioquuq9djgcnq8ohwJfHtMuhf7nmsfTB5+bIgg8/vjj2rdvn9auXev5BcMnn3zyO/uNHz/e63HHL730kh+q9c3ixYuVnZ2tqVOnaufOnUpKSlJ6erpOnTpVa/vNmzdr5MiRGjt2rHbt2qVhw4Zp2LBh2rt3r58r91195yzdHI+wrqysVFJSkubMmXNd7Y8cOaKhQ4fq3nvv1e7duzVx4kSNGzdOa9assbnShlPfOV9RUlLi9X7HxMTYVGHD8+Ux7TfD55rH0wehAD7wqEHs37/fkmR9/PHHnm3/+Z//aTkcDuvEiRN19hs0aJA1YcIEP1TYMPr162dlZmZ61mtqaqyWLVtaeXl5tbb/yU9+Yg0dOtRrW3JysvVP//RPttbZkOo75/nz51tRUVF+qs4/JFnLli27ZpvJkydbXbp08do2YsQIKz093cbK7HM9c16/fr0lyfryyy/9UpM/nDp1ypJkbdiwoc42N8Pn+tuuZ94342c7mIT8GYHi4mI1a9ZMffr08WxLS0tTWFiYtm7des2+CxcuVIsWLdS1a1fl5ubq66+/trtcn1RXV2vHjh1KS0vzbAsLC1NaWpqKi4tr7VNcXOzVXpLS09PrbB9sfJmzJJ0/f15t27ZVQkKCHnnkEe3bt88f5QZUqL/XN6JHjx6Kj4/X/fffr48++ijQ5dyQ8vJySVJ0dHSdbW7G9/p65i2Z+dn2l5APAqWlpVedDmzUqJGio6Oveb3wscce0zvvvKP169crNzdXb7/9tn7605/aXa5Pzpw5o5qaGsXGxnptj42NrXOOpaWl9WofbHyZc8eOHfXWW29pxYoVeuedd+R2uzVgwAB98cUX/ig5YOp6rysqKnThwoUAVWWv+Ph4zZ07V++//77ef/99JSQkKDU1VTt37gx0aT5xu92aOHGi7r77bnXt2rXOdqH+uf626523qZ9tf/HbY4jrKycnRy+++OI12xw4cMDn8f/+HoJu3bopPj5e9913nw4fPqzbb7/d53EROPV9hDVCV8eOHdWxY0fP+oABA3T48GHNnDlTb7/9dgAr8831Pqb9ZmPX4+lRP0EbBJ5++mnP8wjq0qFDB8XFxV1189jly5d19uxZxcXFXff+kpOTJUmHDh0KuiDQokULhYeHq6yszGt7WVlZnXOMi4urV/tg48ucv82UR1jX9V67XC7Pw71M0K9fv5A8kNbnMe2h/rn+ezyePngE7aWB2267TZ06dbrmEhERoZSUFJ07d047duzw9C0sLJTb7fYc3K/H7t27JSkoH3ccERGh3r17q6CgwLPN7XaroKDAKyX/vZSUFK/2krR27do62wcbX+b8baY8wjrU3+uGsnv37pB6ry0fHtN+M7zXvsz720z5bPtNoO9WbAgPPvig1bNnT2vr1q3Wpk2brDvuuMMaOXKk5/UvvvjC6tixo7V161bLsizr0KFD1vTp063t27dbR44csVasWGF16NDBGjhwYKCm8J3effddy+l0Wvn5+db+/futJ5980mrWrJlVWlpqWZZl/exnP7NycnI87T/66COrUaNG1iuvvGIdOHDAmjp1qnXLLbdYe/bsCdQU6q2+c542bZq1Zs0a6/Dhw9aOHTusRx991IqMjLT27dsXqCn45KuvvrJ27dpl7dq1y5Jkvfbaa9auXbuso0ePWpZlWTk5OdbPfvYzT/vPPvvMatKkifWrX/3KOnDggDVnzhwrPDzcWr16daCmUG/1nfPMmTOt5cuXW59++qm1Z88ea8KECVZYWJi1bt26QE2h3n7+859bUVFRVlFRkXXy5EnP8vXXX3va3Iyfa1/mfbN8toPVTREE/vrXv1ojR460vv/971sul8saM2aM9dVXX3leP3LkiCXJWr9+vWVZlnXs2DFr4MCBVnR0tOV0Oq3ExETrV7/6lVVeXh6gGVyf3//+91abNm2siIgIq1+/ftaWLVs8rw0aNMjKyMjwar9kyRLrzjvvtCIiIqwuXbpYH374oZ8rvnH1mfPEiRM9bWNjY60hQ4ZYO3fuDEDVN+bKV+O+vVyZa0ZGhjVo0KCr+vTo0cOKiIiwOnToYM2fP9/vdd+I+s75xRdftG6//XYrMjLSio6OtlJTU63CwsLAFO+j2uYryeu9uxk/177M+2b5bAcrHkMMAIDBgvYeAQAAYD+CAAAABiMIAABgMIIAAAAGIwgAAGAwggAAAAYjCAAAYDCCAAAABiMIAABgMIIAAAAGIwgAAGCw/weUoZpS9KOU9gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Create a sample grid with values\n",
    "grid = np.array([\n",
    "    [0, 1, 2],\n",
    "    [2, 1, 0],\n",
    "    [1, 2, 1]\n",
    "])\n",
    "\n",
    "# Define custom colors for each value, e.g., 0 = light green, 1 = dark green, 2 = red\n",
    "colors = ['lightgreen', 'darkgreen', 'red']\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Set up boundaries for color mapping (adjusts range for each value)\n",
    "bounds = [-0.5, 0.5, 1.5, 2.5]  # Boundaries for values 0, 1, and 2\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Plot using imshow with custom colormap and normalization\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(grid, cmap=cmap, norm=norm)\n",
    "\n",
    "# Add a colorbar to see the mapping\n",
    "plt.colorbar(im, ticks=[0, 1, 2], label=\"Grid Values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77593530-0598-474e-9bf4-bf19e2568d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
